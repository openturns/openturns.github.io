
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_meta_modeling/polynomial_chaos_metamodel/plot_chaos_draw_validation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_draw_validation.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_draw_validation.py:


Validate a polynomial chaos
===========================

.. GENERATED FROM PYTHON SOURCE LINES 6-7

In this example, we show how to perform the draw validation of a polynomial chaos for the :ref:`Ishigami function <use-case-ishigami>`.

.. GENERATED FROM PYTHON SOURCE LINES 10-17

.. code-block:: Python

    from openturns.usecases import ishigami_function
    import openturns as ot
    import openturns.viewer as viewer
    from matplotlib import pylab as plt

    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 18-20

Model description
-----------------

.. GENERATED FROM PYTHON SOURCE LINES 22-23

We load the Ishigami test function from the usecases module :

.. GENERATED FROM PYTHON SOURCE LINES 23-25

.. code-block:: Python

    im = ishigami_function.IshigamiModel()








.. GENERATED FROM PYTHON SOURCE LINES 26-28

The `IshigamiModel` data class contains the input distribution :math:`X=(X_1, X_2, X_3)` in `im.distributionX` and the Ishigami function in `im.model`.
We also have access to the input variable names with

.. GENERATED FROM PYTHON SOURCE LINES 28-30

.. code-block:: Python

    input_names = im.distributionX.getDescription()








.. GENERATED FROM PYTHON SOURCE LINES 31-35

.. code-block:: Python

    N = 100
    inputTrain = im.distributionX.getSample(N)
    outputTrain = im.model(inputTrain)








.. GENERATED FROM PYTHON SOURCE LINES 36-38

Create the chaos
----------------

.. GENERATED FROM PYTHON SOURCE LINES 40-41

We could use only the input and output training samples: in this case, the distribution of the input sample is computed by selecting the best distribution that fits the data.

.. GENERATED FROM PYTHON SOURCE LINES 43-45

.. code-block:: Python

    chaosalgo = ot.FunctionalChaosAlgorithm(inputTrain, outputTrain)








.. GENERATED FROM PYTHON SOURCE LINES 46-47

Since the input distribution is known in our particular case, we instead create the multivariate basis from the distribution, that is three independent variables X1, X2 and X3.

.. GENERATED FROM PYTHON SOURCE LINES 49-55

.. code-block:: Python

    multivariateBasis = ot.OrthogonalProductPolynomialFactory([im.X1, im.X2, im.X3])
    totalDegree = 8
    enumfunc = multivariateBasis.getEnumerateFunction()
    P = enumfunc.getStrataCumulatedCardinal(totalDegree)
    adaptiveStrategy = ot.FixedStrategy(multivariateBasis, P)








.. GENERATED FROM PYTHON SOURCE LINES 56-61

.. code-block:: Python

    selectionAlgorithm = ot.LeastSquaresMetaModelSelectionFactory()
    projectionStrategy = ot.LeastSquaresStrategy(
        inputTrain, outputTrain, selectionAlgorithm
    )








.. GENERATED FROM PYTHON SOURCE LINES 62-66

.. code-block:: Python

    chaosalgo = ot.FunctionalChaosAlgorithm(
        inputTrain, outputTrain, im.distributionX, adaptiveStrategy, projectionStrategy
    )








.. GENERATED FROM PYTHON SOURCE LINES 67-71

.. code-block:: Python

    chaosalgo.run()
    result = chaosalgo.getResult()
    metamodel = result.getMetaModel()








.. GENERATED FROM PYTHON SOURCE LINES 72-74

Validation of the metamodel
---------------------------

.. GENERATED FROM PYTHON SOURCE LINES 76-77

In order to validate the metamodel, we generate a test sample.

.. GENERATED FROM PYTHON SOURCE LINES 79-87

.. code-block:: Python

    n_valid = 1000
    inputTest = im.distributionX.getSample(n_valid)
    outputTest = im.model(inputTest)
    prediction = metamodel(inputTest)
    val = ot.MetaModelValidation(outputTest, prediction)
    R2 = val.computeR2Score()[0]
    R2





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    0.9993670411085883



.. GENERATED FROM PYTHON SOURCE LINES 88-89

The R2 is very close to 1: the metamodel is excellent.

.. GENERATED FROM PYTHON SOURCE LINES 91-96

.. code-block:: Python

    graph = val.drawValidation()
    graph.setTitle("R2=%.2f%%" % (R2 * 100))
    view = viewer.View(graph)
    plt.show()




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_draw_validation_001.png
   :alt: R2=99.94%
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_draw_validation_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 97-98

The metamodel has a good predictivity, since the points are almost on the first diagonal.


.. _sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_draw_validation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_chaos_draw_validation.ipynb <plot_chaos_draw_validation.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_chaos_draw_validation.py <plot_chaos_draw_validation.py>`
