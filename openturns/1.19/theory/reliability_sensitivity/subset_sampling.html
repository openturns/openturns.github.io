
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Subset sampling method &#8212; OpenTURNS 1.19 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/openturns.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/mysearchtools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Numerical methods" href="../numerical_methods/numerical_methods.html" />
    <link rel="prev" title="Quasi Monte Carlo" href="qmc_simulation.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://gitter.im/openturns/community">Chat</a></li>
    <li><a href="https://github.com/openturns/openturns/wiki/Modules">Modules</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../numerical_methods/numerical_methods.html" title="Numerical methods"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="qmc_simulation.html" title="Quasi Monte Carlo"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.19 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="reliability_sensitivity.html" accesskey="U">Reliability, sensitivity</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Subset sampling method</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Subset sampling method</a><ul>
<li><a class="reference internal" href="#acknowledgement">Acknowledgement</a></li>
<li><a class="reference internal" href="#presentation">Presentation</a></li>
<li><a class="reference internal" href="#formulation">Formulation</a></li>
<li><a class="reference internal" href="#advantages-and-drawbacks">Advantages and drawbacks</a></li>
<li><a class="reference internal" href="#remarks">Remarks</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="qmc_simulation.html"
                          title="previous chapter">Quasi Monte Carlo</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="../numerical_methods/numerical_methods.html"
                          title="next chapter">Numerical methods</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/reliability_sensitivity/subset_sampling.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="subset-sampling-method">
<h1>Subset sampling method<a class="headerlink" href="#subset-sampling-method" title="Permalink to this headline">¶</a></h1>
<div class="section" id="acknowledgement">
<h2>Acknowledgement<a class="headerlink" href="#acknowledgement" title="Permalink to this headline">¶</a></h2>
<p>The text and the figures thereafter come from Vincent Chabridon’s PhD thesis, <strong>Reliability-oriented sensitivity analysis under probabilistic model uncertainty, Application to aerospace systems</strong> (2018) in the chapter 3: <em>Rare event probability estimation</em>.
This paragraph has been edited with the kind permission of its author.</p>
</div>
<div class="section" id="presentation">
<h2>Presentation<a class="headerlink" href="#presentation" title="Permalink to this headline">¶</a></h2>
<p><em>Subset sampling</em> (abbreviated to SS) belongs to the family of variance
reduction techniques. However, due to its mathematical formulation,
several variants have been proposed in different scientific
communities. For example, one can cite, among others, the pioneering
work of Kahn and Harris (1951) (called <em>splitting</em>) in the field of
neutronics physics, the study of Glasserman <em>et al.</em> (1999) (called <em>multilevel splitting</em>) from the branching processes point of view, the development
by Au and Beck (2001) (called <em>subset simulation</em>) for reliability assessment purpose or finally,
the theoretical studies from the Markov processes point of view by Cérou and Guyader (2007)
(called <em>adaptive multilevel splitting</em>) and Cérou et al. (2012) from the sequential Monte Carlo point
of view.</p>
<p>All in all, these splitting techniques rely on the same idea: a rare event should be “split” into
several less rare events, these events corresponding to some “subsets” containing the true failure
set. Thus, the probability associated to each subset should be stronger, and consequently, easier
to estimate. As an example, on can illustrate this by considering that a failure probability <img class="math" src="../../_images/math/94a00f8dae57db9d61fdf0e023109d7854627a61.svg" alt="p_f"/> of the order of <img class="math" src="../../_images/math/2a2178bd26bc7b7f88a8bd0811130b961ec767cf.svg" alt="10^{-m}"/> can be split into a product of <img class="math" src="../../_images/math/2f6d6292800bff652850ddd85bc4d6c2e83fa513.svg" alt="m"/> terms of probability <img class="math" src="../../_images/math/c12a0e7b3b84030e0d9d805bca19791112b47972.svg" alt="1/10"/>. In the following, for the sake of conciseness, only the formulation proposed by Au and Beck (2001) is discussed.</p>
</div>
<div class="section" id="formulation">
<h2>Formulation<a class="headerlink" href="#formulation" title="Permalink to this headline">¶</a></h2>
<p>The formulation of SS proposed by Au and Beck (2001) is
derived in the <img class="math" src="../../_images/math/dde698f62484e21d931e7a80e20bc700c319680b.svg" alt="\mathbf{u}"/> -space (standard space) and is the one presented hereafter.</p>
<p>Let <img class="math" src="../../_images/math/c2f691ee1b5e0801d9cde8a3d87ac347cab512d3.svg" alt="E = \{ \overset{\circ}{g}(u) \leq 0 \}"/> denote a failure event sufficiently rare, where <img class="math" src="../../_images/math/b265642ee5d78300a102cccf9e84d2366eac03ef.svg" alt="\overset{\circ}{g}"/> is the <em>limit state function</em> (LSF) in the standard space.</p>
<p>One can consider a set of <em>intermediate nested events</em> <img class="math" src="../../_images/math/bec92798274273a4cb0ba0cab9519da4be8acce9.svg" alt="E_s"/> with <img class="math" src="../../_images/math/1aca28593922b368bec95408c3d2d5a9a0f8fef1.svg" alt="s = 1, \hdots, m"/> such that <img class="math" src="../../_images/math/e97b61b992a957ef9e984e69a1bf6755a08fe12e.svg" alt="E = E_m \subset E_{m-1} \subset \hdots \subset E_2 \subset E_1"/>. Applying chain rule for conditional probabilities, one gets:</p>
<div class="math">
<p><img src="../../_images/math/9f25216db99c6110952647b15d766a21f1f21ec4.svg" alt="\begin{aligned}
   p_f {} &amp; =  \mathbb{P}(E_m) \\
       {} &amp; =   \mathbb{P}(E_m | E_{m-1}) \mathbb{P}(E_{m-1})  \\
       {} &amp; =   \mathbb{P}(E_m | E_{m-1}) \mathbb{P}(E_{m-1})  \\
       {} &amp; =   \prod_{s=1}^m p_s
\end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/b6ffcae762788ad4c598180c9bb20f07e463e281.svg" alt="p_1 = \mathbb{P}(E_1)"/> and <img class="math" src="../../_images/math/c2dbcf21e9742623823ec41bc7f0390a099a50d0.svg" alt="p_s = \mathbb{P}(E_s | E_{s-1})"/> for <img class="math" src="../../_images/math/e1f4e9a048960c38aade6a0fcbef5ec99b44f9b8.svg" alt="s = 2, \hdots, m"/>. From this collection of nested failure events, one can define a set of <em>intermediate nested failure domains</em> (which are the so-called “subsets”) such that:</p>
<div class="math">
<p><img src="../../_images/math/d6d663097049da8fe75d3f85cfe0186294601d93.svg" alt="\mathcal{F}_{u,s} = \{ u \in \mathbb{R}^d | \overset{\circ}{g}(u) \leq y_s   \}, s=1,\hdots,m"/></p>
</div><p>where <img class="math" src="../../_images/math/ec693b7bb053c138debd84b9ea787b75ead0f02e.svg" alt="y_s"/> belongs to a set of decreasing intermediate thresholds such that <img class="math" src="../../_images/math/7ee96809d4cf8a0e61ba6ffca5db17ff0c0d6966.svg" alt="y_m = 0"/> (i.e., corresponding to the true LSF) and</p>
<div class="math">
<p><img src="../../_images/math/02cc1f84295d02c22a98a0db51f8ec79de2a1dc0.svg" alt="y_1 &gt; y_2 &gt; \hdots &gt; y_{m-1} &gt; y_m"/></p>
</div><p>These thresholds are estimated as <img class="math" src="../../_images/math/8e1ca1db8b4000f78a0ea7d7f5b34f350f4c27d8.svg" alt="\alpha_{SS}"/> quantiles from the set of <img class="math" src="../../_images/math/6bed8a44f63e1eb8e61608a5c93374a505943eec.svg" alt="N"/> samples of LSF outputs <img class="math" src="../../_images/math/378e90fdaa4bd4a8dcf87442fea382b0327ffa59.svg" alt="\mathcal{G}_{u,s} = \{ \overset{\circ}{g}(U^{(j)}) \}_{j=1}^N"/> with <img class="math" src="../../_images/math/ef251a3f288dc0cb3440cf8472ad00e0ccb53ac8.svg" alt="\alpha_{SS} \in ]0, 1["/> the <em>rarity parameter</em>. Consequently, one can notice that</p>
<div class="math">
<p><img src="../../_images/math/7d408cea14a9306d157bdd3f2ddbfe5b9e350999.svg" alt="\mathcal{F}_{u} = \mathcal{F}_{u,m} \subset \mathcal{F}_{u,m-1} \subset \hdots \subset \mathcal{F}_{u,2} \subset \mathcal{F}_{u,1}"/></p>
</div><p>The underlying mechanism of the SS is illustrated on a two-dimensional example in the following figure.</p>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="../../_images/tab.png"><img alt="../../_images/tab.png" src="../../_images/tab.png" style="width: 625.5px; height: 606.0px;" /></a>
<p class="caption"><span class="caption-text">Illustration on a two-dimensional example of the SS mechanism in the standard space.
(Top left) The true but unknown <em>limit state surface</em> ; (Top right) First intermediate failure domain <img class="math" src="../../_images/math/32fa11c2e0b1e905e91fab04f836c23c2b4c622b.svg" alt="\mathcal{F}_{u,1}"/>.
(Bottom left) Second intermediate failure domain <img class="math" src="../../_images/math/47dacb9b9375a68493cc524bd85ede3f28eda3a9.svg" alt="\mathcal{F}_{u,2}"/> ; (Bottom right) Third intermediate failure domain <img class="math" src="../../_images/math/8943d3428e57efc4bdaac4c36f1d2d08f33976cc.svg" alt="\mathcal{F}_{u,3}"/>.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>In the first figure (top left), the true, but unknown, <em>limit state surface</em> (LSS) is sketched. Then, one considers successive intermediate nested failure domains
which adaptively evolve towards the true failure LSS (first, second and third intermediate failure domains).
Thus, the rare event estimation problem can be split into a sequence of <img class="math" src="../../_images/math/2f6d6292800bff652850ddd85bc4d6c2e83fa513.svg" alt="m"/> subproblems with larger probabilities to estimate. For the first level <img class="math" src="../../_images/math/518147532d0f643704ee9694722da81d72d93a6f.svg" alt="s=1"/>, the probability reads :</p>
<div class="math">
<p><img src="../../_images/math/36ba1c629a3e7f60fc9659fdf7170b11c89be619.svg" alt="p_1 = \mathbb{P}(E_1) = \mathbb{E}_{\Phi_d} [ \mathbf{1}_{ \mathcal{F}_{u,1}  }(U) ]"/></p>
</div><p>and for <img class="math" src="../../_images/math/7e3b04f7467185ea555fbf4789997faa7e32362e.svg" alt="s=2,\hdots,m"/> :</p>
<div class="math">
<p><img src="../../_images/math/0b3f723c5e8bc773e832a2f3b2c96b32016c41ab.svg" alt="p_s = \mathbb{P}(E_s | E_{s-1}) = \mathbb{E}_{\Phi_d(.|E_{s-1})} [ \mathbf{1}_{ \mathcal{F}_{u,s}  }(U) ]."/></p>
</div><p>where <img class="math" src="../../_images/math/c9b932a2243bd6b15a929ba73c4bf94785eb70ff.svg" alt="\Phi_d"/> is the usual standard unit Gaussian PDF in dimension <img class="math" src="../../_images/math/5da6e6d65e4ae3032c58fe8c94955247fc4ebe22.svg" alt="d"/>.</p>
<p>The associated estimators are given, respectively for <img class="math" src="../../_images/math/2289d214e200f2d81febef88dbecf0da8b8b6454.svg" alt="\{ U_1^{(j)} \}_{j=1}^N \overset{i.i.d.}{\sim} \Phi_d"/> by:</p>
<div class="math">
<p><img src="../../_images/math/dfdad89d7aa2755b8e2fee1ffa02deeea4adf154.svg" alt="\hat{p_1} = \frac{1}{N} \sum_{j=1}^N \mathbf{1}_{ \mathcal{F}_{u,1} }(U_1^{(j)})"/></p>
</div><p>and, for <img class="math" src="../../_images/math/c0b4ccf0b674e2e2700f6135f06ede43439114ec.svg" alt="\{ U_s^{(j)} \}_{j=1}^N \overset{i.i.d.}{\sim} \Phi_d(.|E_{s-1})"/>, <img class="math" src="../../_images/math/59fe0548c61b2a89d7fbb2992c0927726c16666c.svg" alt="s \geq 2"/>, by:</p>
<div class="math">
<p><img src="../../_images/math/3458eb5bbb4e8aa34bdda45b7e0e09a9f4ca80be.svg" alt="\hat{p_s} = \frac{1}{N} \sum_{j=1}^N \mathbf{1}_{ \mathcal{F}_{u,s} }(U_s^{(j)})"/></p>
</div><p>where <img class="math" src="../../_images/math/6bed8a44f63e1eb8e61608a5c93374a505943eec.svg" alt="N"/> denotes the number of samples, supposed to be a constant for each level <img class="math" src="../../_images/math/ec693b7bb053c138debd84b9ea787b75ead0f02e.svg" alt="y_s"/>, and the indicator function satisfies <img class="math" src="../../_images/math/cde3ac6bdb83b77638ffd850abd72fe7cc3603a7.svg" alt="\mathbf{1}_{\mathcal{F}_{u,s-1}}(u) = 1"/> if <img class="math" src="../../_images/math/6ccf20615f1adef9669e9b70e8c2da7ca688ceee.svg" alt="\overset{\circ}{g}(u) \leq y_{s-1}"/> and <img class="math" src="../../_images/math/efb78051c00ef448dc6204384045fc49454ba123.svg" alt="\mathbf{1}_{\mathcal{F}_{u,s-1}}(u) = 0"/> otherwise.</p>
<p>Basically, the SS estimator for <img class="math" src="../../_images/math/94a00f8dae57db9d61fdf0e023109d7854627a61.svg" alt="p_f"/> is given by:</p>
<div class="math">
<p><img src="../../_images/math/f360403ce6e8eb7a00697b7608aabea1687f7fea.svg" alt="\hat{p}_f^{SS} = \hat{p_1} \prod_{s=2}^m \hat{p_s} \qquad \text{ (estimator) }."/></p>
</div><p>Moreover, it appears that the conditional sampling PDF <img class="math" src="../../_images/math/94823dfb60667c6f2277febc444342e7da34a2fa.svg" alt="\Phi_d(.|E_{s-1})"/> takes the form:</p>
<div class="math">
<p><img src="../../_images/math/f3b900e12bc31194b168e60bc911515dfe9c321e.svg" alt="\begin{aligned}
\Phi_d(u|E_{s-1}) {} &amp; = \frac{\Phi_d(u) \mathbf{1}_{\mathcal{F}_{u,s-1}}(u) }{ \mathbb{P}(E_{s-1}) } \\
                  {} &amp; = \frac{\Phi_d(u) \mathbf{1}_{\mathcal{F}_{u,s-1}}(u) }{p_{s-1}}, s=2,\hdots,m \qquad \text{ (auxiliary PDF)  }
\end{aligned}"/></p>
</div><p>As a consequence, if one does want to achieve variance reduction with SS compared to Crude MonteCarlo
(and thus, to decrease the computational cost in context of very low failure probability), one
should be able to sample sequentially from a quasi-optimal auxiliary PDF.</p>
<p>Such a problem can be adressed by using dedicated algorithms based on the <em>Markov Chain Monte
Carlo</em> (MCMC) sampling technique (see, e.g., Robert and Casella, 2004; Asmussen and Glynn,
2007).</p>
<p>For instance, dedicated algorithms such as the standard <em>Metropolis-Hastings</em> (MH) sampler (Metropolis et al., 1953; Hastings, 1970) can be used. In the specific context of SS, the <em>modified
Metropolis-Hastings</em> (m-MH) sampler originally proposed by Au and Beck (2001) has been proposed to deal with possible higher-dimensional reliability problems than the ones standard MH algorithm traditionally used.</p>
<p>Concerning the statistical properties of the estimator of <img class="math" src="../../_images/math/5b2488afbe5704c234501622d9515851c4ca2962.svg" alt="p_f^{SS}"/>, Au and Beck (2001) point out the fact that this estimator is biased due to the correlation between the intermediate
probability estimators <img class="math" src="../../_images/math/d41550f505f763b655b2149a62cd60d68951f01e.svg" alt="\hat{p}_s"/> for <img class="math" src="../../_images/math/df2fb1a6f81862648cae888951fcb16efdf37b44.svg" alt="s=1,\hdots,m"/>. Such a correlation comes from the way the m-MH sampler is seeded at each step (see, e.g., Bourinet (2018) or Dubourg (2011) for more details). It is also proved that the estimator <img class="math" src="../../_images/math/5b2488afbe5704c234501622d9515851c4ca2962.svg" alt="p_f^{SS}"/> is asymptotically unbiased (Au and Beck, 2001). As for the c.v. <img class="math" src="../../_images/math/b558382359f50f057950042ff3515468b1559bd4.svg" alt="\delta_{\hat{p}_f^{SS}}"/>, Au and Beck (2001) show that it is bounded such that:</p>
<div class="math">
<p><img src="../../_images/math/32c2cba1d81532c018fd915c5c617d0ac6231e68.svg" alt="\sum_{s=1}^m \delta_{s} \leq  \delta^2_{\hat{p}_f^{SS}}  \leq  \sum_{s_1=1}^m \sum_{s_2=1}^m \delta_{s_1} \delta_{s_2} \qquad \text {(3)}"/></p>
</div><p>where <img class="math" src="../../_images/math/4c4ef2e709f8b1aeca848e532df1ca159f19c1cf.svg" alt="\delta^2_{\hat{p}_f^{SS}} = \mathbb{E} \left[ \left( \frac{\hat{p}_f^{SS} -p_f  }{p_f} \right)^2 \right]"/> and <img class="math" src="../../_images/math/a3e33dfb37b16e07c290d3352a2b05f8ee478210.svg" alt="\delta_s"/> are the c.v. of <img class="math" src="../../_images/math/b0c1e7a579405d3fd39c7ba0acee04db737a60ab.svg" alt="\hat{p_s}"/>, for <img class="math" src="../../_images/math/df2fb1a6f81862648cae888951fcb16efdf37b44.svg" alt="s=1,\hdots,m"/>. For the sake of concisness, formulas for computing these quantities can be found in Au and Beck (2001) or Bourinet (2018).</p>
<p>The upper bound is established under the assumption of fully-correlated intermediate probability estimators <img class="math" src="../../_images/math/d41550f505f763b655b2149a62cd60d68951f01e.svg" alt="\hat{p}_s"/>. Instead of using this upper bound, one can use the lower bound, established
under the assumption of independent probability estimators <img class="math" src="../../_images/math/d41550f505f763b655b2149a62cd60d68951f01e.svg" alt="\hat{p}_s"/>. Indeed, although it underestimates the true c.v., it appears that,in practice (see, e.g., Au <em>et al.</em>, 2007), it may give a reasonable approximation and approaches the empirical c.v. obtained by repetitions of the SS algorithm.</p>
</div>
<div class="section" id="advantages-and-drawbacks">
<h2>Advantages and drawbacks<a class="headerlink" href="#advantages-and-drawbacks" title="Permalink to this headline">¶</a></h2>
<p>On the one hand, the main advantages of SS in rare event probability estimation are its
ability to handle complex LSFs (e.g., highly nonlinear, with possibly
multiple failure regions) and to behave better than other techniques
regarding the input dimension. Moreover, SS may present some
interesting features concerning possible parallelization as exposed in
Bourinet (2018). However, in its traditional formulation, SS is not a
fully parallel multilevel splitting (Walter, 2015).</p>
<p>On the other hand, SS also presents some potential drawbacks. Firstly, even if SS
provides a variance reduction compared to CMC, the number of samples
required to achieve convergence may be, in some cases, larger than
that required with other <em>Importance Sampling</em> techniques. Secondly, the estimation
error is not directly given by an analytical formula (e.g., variance
estimators for CMC and IS) but has to be estimated using the bounds
provided in the previous inequalities or by repetition.</p>
<p>Thirdly, another intrinsic difficulty of SS is the tuning of parameters (e.g., the fixed
vs. adaptive levels <img class="math" src="../../_images/math/18d2a1d0ab2cfe9adcfa7f940ef9b0b2a886c253.svg" alt="\{ y_s \}_{s=1}^m"/> , the number of samples <img class="math" src="../../_images/math/6bed8a44f63e1eb8e61608a5c93374a505943eec.svg" alt="N"/> per step
and other related parameters in the MCMC algorithm) which can be, in
some cases, very influential on the efficiency of the
algorithm. Fourthly, as proved in Au and Beck (2001) and recalled by
Walter (2016, Chap. 1), the SS formulation leads to a biased estimator of <img class="math" src="../../_images/math/94a00f8dae57db9d61fdf0e023109d7854627a61.svg" alt="p_f"/>.</p>
<p>Other algorithms such as the <em>Last Particle Algorithm</em> (LPA) by
Guyader et al. (2011) or the <em>Moving Particles algorithm</em> (MP) by
Walter (2015) can be used. A numerical investigation about relative
efficiencies of both SS and LPA/MP through the tuning of MCMC
parameters has been recently proposed by Proppe (2017).</p>
<p>Fourthly, when input dimension <img class="math" src="../../_images/math/5da6e6d65e4ae3032c58fe8c94955247fc4ebe22.svg" alt="d"/> is large, SS may be indirectly affected if the
traditional MH sampler is used as it becomes inefficient in high dimension. Using the m-MH sampler introduced by Au and Beck (2001)
allows one to overcome this difficulty. As an alternative, one could
also use another variant of m-MH as proposed in Zuev and Katafygiotis
(2011).</p>
<p>Finally, as mentioned in Au and Wang (2014) and Breitung
(2019), counterexamples (e.g., specific shapes of LSS) can be found
to invalidate SS convergence towards the true failure
probability. This remark highlights the fact that any insight
regarding the physical behavior of the system or about the LSF can be
useful for the analyst to avoid dramatic errors in terms of rare event
probability estimation.</p>
</div>
<div class="section" id="remarks">
<h2>Remarks<a class="headerlink" href="#remarks" title="Permalink to this headline">¶</a></h2>
<p>As a remark, one can notice that <em>Subset Sampling</em>
can be efficiently coupled with surrogate models (Bourinet et al.,
2011; Bourinet, 2016; Bect et al., 2017) to assess reliability
regarding <em>expensive-to-evaluate</em> computer models. In such a case,
possible limiting properties of the surrogate model (e.g., limits
concerning the input dimensionality and the smoothness of the LSF) may
impact the usual properties of <em>Subset Sampling</em>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>For any further information about subset/splitting techniques for rare event simulation, the
interested reader could refer to the following references</p>
<blockquote>
<div><ul class="simple">
<li><p>Asmussen and Glynn, 2007, <em>Stochastic Simulation: Algorithms and Analysis</em></p></li>
<li><p>Au and Beck, 2001, <em>Estimation of small failure probabilities in high dimensions by subset simulation</em></p></li>
<li><p>Au <em>et al.</em>, 2007, <em>Application of subset simulation methods to reliability benchmark problems</em></p></li>
<li><p>Au and Wang, 2014, <em>Engineering Risk Assessment with Subset Simulation</em></p></li>
<li><p>Bect <em>et al.</em>, 2017, <em>Bayesian Subset Simulation</em></p></li>
<li><p>Bourinet <em>et al.</em>, 2011, <em>Assessing small failure probabilities by combined subset simulation and Support Vector Machines</em></p></li>
<li><p>Bourinet, 2016, <em>Rare-event probability estimation with adaptive support vector regression surrogates</em></p></li>
<li><p>Bourinet (2018), <em>Reliability analysis and optimal design under uncertainty – Focus on adaptive surrogate-based approaches</em></p></li>
<li><p>Breitung, 2019, <em>The geometry of limit state function graphs and subset simulation: Counterexamples</em></p></li>
<li><p>Caron <em>et al.</em>, 2014, <em>Some recent results in rare event estimation</em></p></li>
<li><p>Cérou and Guyader, 2007, <em>Adaptive Multilevel Splitting for Rare Event Analysis</em></p></li>
<li><p>Cérou <em>et al.</em>, 2012, <em>Sequential Monte Carlo for rare event estimation</em></p></li>
<li><p>Chabridon, 2018, <em>Reliability-oriented sensitivity analysis under probabilistic model uncertainty, Application to aerospace systems</em></p></li>
<li><p>Dubourg, 2011, <em>Adaptive surrogate models for reliability analysis and reliability-based design optimization</em></p></li>
<li><p>Glasserman <em>et al.</em>, 1999 , <em>Multilevel splitting for estimating rare event probabilities</em></p></li>
<li><p>Guyader <em>et al.</em>, 2011, <em>Simulation and Estimation of Extreme Quantiles and Extreme Probabilities</em></p></li>
<li><p>Hastings, 1970, <em>Monte Carlo sampling methods using Markov chains and their applications</em></p></li>
<li><p>Kahn and Harris, 1951, <em>Estimation of particle transmission by random sampling</em></p></li>
<li><p>Lagnoux, 2006, <em>Rare event simulation</em></p></li>
<li><p>Metropolis <em>et al.</em>, 1953, <em>Equation of state calculations by fast computing machines</em></p></li>
<li><p>Morio <em>et al.</em>, 2014, <em>A survey of rare event simulation methods for static input-output models</em></p></li>
<li><p>Proppe, 2017, <em>Markov chain methods for reliability estimation</em></p></li>
<li><p>Robert and Casella, 2004, <em>Monte Carlo Statistical Methods</em></p></li>
<li><p>Walter, 2015, <em>Moving particles: A parallel optimal multilevel splitting method with application in quantiles estimation and meta-model based algorithms</em></p></li>
<li><p>Walter, 2016, <em>Using Poisson processes for rare event simulation</em></p></li>
<li><p>Zuev and Katafygiotis, 2011, <em>Modified Metropolis-Hastings algorithm with delayed rejection</em></p></li>
</ul>
</div></blockquote>
<div class="topic">
<p class="topic-title">API:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../user_manual/_generated/openturns.SubsetSampling.html#openturns.SubsetSampling" title="openturns.SubsetSampling"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubsetSampling</span></code></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Examples:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../auto_reliability_sensitivity/reliability/plot_subset_sampling.html"><span class="doc">Subset Sampling</span></a></p></li>
</ul>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../numerical_methods/numerical_methods.html" title="Numerical methods"
             >next</a> |</li>
        <li class="right" >
          <a href="qmc_simulation.html" title="Quasi Monte Carlo"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.19 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="reliability_sensitivity.html" >Reliability, sensitivity</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Subset sampling method</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2022 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on May 10, 2022.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    </div>
  </body>
</html>