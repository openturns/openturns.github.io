
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Kriging: metamodel with continuous and categorical variables &#8212; OpenTURNS 1.22 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/openturns.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/mysearchtools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fields metamodels" href="../fields_metamodels/index.html" />
    <link rel="prev" title="Kriging : draw covariance models" href="plot_draw_covariance_models.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://gitter.im/openturns/community">Chat</a></li>
    <li><a href="https://github.com/openturns/openturns/wiki/Modules">Modules</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../fields_metamodels/index.html" title="Fields metamodels"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_draw_covariance_models.html" title="Kriging : draw covariance models"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.22 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Meta modeling</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" accesskey="U">Kriging metamodel</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Kriging: metamodel with continuous and categorical variables</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="plot_draw_covariance_models.html"
                          title="previous chapter">Kriging : draw covariance models</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="../fields_metamodels/index.html"
                          title="next chapter">Fields metamodels</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/auto_meta_modeling/kriging_metamodel/plot_kriging_categorical.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-meta-modeling-kriging-metamodel-plot-kriging-categorical-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="kriging-metamodel-with-continuous-and-categorical-variables">
<span id="sphx-glr-auto-meta-modeling-kriging-metamodel-plot-kriging-categorical-py"></span><h1>Kriging: metamodel with continuous and categorical variables<a class="headerlink" href="#kriging-metamodel-with-continuous-and-categorical-variables" title="Permalink to this heading">Â¶</a></h1>
<p>We consider here the surrogate modeling of an analytical function characterized by
continuous and categorical variables</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openturns</span> <span class="k">as</span> <span class="nn">ot</span>
<span class="kn">import</span> <span class="nn">openturns.experimental</span> <span class="k">as</span> <span class="nn">otexp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Seed chosen in order to obtain a visually nice plot</span>
<span class="n">ot</span><span class="o">.</span><span class="n">RandomGenerator</span><span class="o">.</span><span class="n">SetSeed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>We first show the advantage of modeling the various levels of a mixed
continuous / categorical function through a single surrogate model
on a simple test-case taken from <a class="reference internal" href="../../bibliography.html#pelamatti2020" id="id1"><span>[pelamatti2020]</span></a>, defined below.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">illustrativeFunc</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">inp</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>


<span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">fun</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">PythonFunction</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">illustrativeFunc</span><span class="p">)</span>
<span class="n">numberOfZLevels</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Number of categorical levels for z</span>
<span class="c1"># Input distribution</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span>
    <span class="p">[</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">)))]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In this example, we compare the performances of the <a class="reference internal" href="../../user_manual/_generated/openturns.experimental.LatentVariableModel.html#openturns.experimental.LatentVariableModel" title="openturns.experimental.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a>
with a naive approach, which would consist in modeling each combination of categorical
variables through a separate and independent Gaussian process.</p>
<p>In order to deal with mixed continuous / categorical problems we can rely on the
<a class="reference internal" href="../../user_manual/_generated/openturns.ProductCovarianceModel.html#openturns.ProductCovarianceModel" title="openturns.ProductCovarianceModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProductCovarianceModel</span></code></a> class. We start here by defining the product kernel,
which combines <a class="reference internal" href="../../user_manual/_generated/openturns.SquaredExponential.html#openturns.SquaredExponential" title="openturns.SquaredExponential"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquaredExponential</span></code></a> kernels for the continuous variables, and
<a class="reference internal" href="../../user_manual/_generated/openturns.experimental.LatentVariableModel.html#openturns.experimental.LatentVariableModel" title="openturns.experimental.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a> for the categorical ones.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">latDim</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Dimension of the latent space</span>
<span class="n">activeCoord</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span>
    <span class="n">numberOfZLevels</span> <span class="o">-</span> <span class="mi">2</span>
<span class="p">)</span>  <span class="c1"># Nb of active coordinates in the latent space</span>
<span class="n">kx</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kz</span> <span class="o">=</span> <span class="n">otexp</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ProductCovarianceModel</span><span class="p">([</span><span class="n">kx</span><span class="p">,</span> <span class="n">kz</span><span class="p">])</span>
<span class="n">kLV</span><span class="o">.</span><span class="n">setNuggetFactor</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="c1"># Bounds for the hyperparameter optimization</span>
<span class="n">lowerBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">upperBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">boundsLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Interval</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">,</span> <span class="n">upperBoundLV</span><span class="p">)</span>
<span class="c1"># Distribution for the hyperparameters initialization</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">)):</span>
    <span class="n">initDistLV</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span><span class="n">initDistLV</span><span class="p">)</span>
</pre></div>
</div>
<p>As a reference, we consider a purely continuous kernel for independent Gaussian processes.
One for each combination of categorical variables levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">kIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lowerBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span>
<span class="n">upperBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">20.0</span><span class="p">]</span>
<span class="n">boundsInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Interval</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">,</span> <span class="n">upperBoundInd</span><span class="p">)</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">)):</span>
    <span class="n">initDistInd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span><span class="n">initDistInd</span><span class="p">)</span>
<span class="n">initSampleInd</span> <span class="o">=</span> <span class="n">initDistInd</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optAlgInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">NLopt</span><span class="p">(</span><span class="s2">&quot;LN_COBYLA&quot;</span><span class="p">),</span> <span class="n">initSampleInd</span><span class="p">)</span>
</pre></div>
</div>
<p>Generate the training data set</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># And the plotting data set</span>
<span class="n">xPlt</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">xPlt</span> <span class="o">=</span> <span class="n">xPlt</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">yPlt</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">xPlt</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize  and parameterize the optimization algorithm</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">initSampleLV</span> <span class="o">=</span> <span class="n">initDistLV</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">optAlgLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">NLopt</span><span class="p">(</span><span class="s2">&quot;LN_COBYLA&quot;</span><span class="p">),</span> <span class="n">initSampleLV</span><span class="p">)</span>
</pre></div>
</div>
<p>Create and train the Gaussian process models</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">algoLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">KrigingAlgorithm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kLV</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
<span class="n">algoLV</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgLV</span><span class="p">)</span>
<span class="n">algoLV</span><span class="o">.</span><span class="n">setOptimizationBounds</span><span class="p">(</span><span class="n">boundsLV</span><span class="p">)</span>
<span class="n">algoLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">resLV</span> <span class="o">=</span> <span class="n">algoLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

<span class="n">algoIndependentList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># Select the training samples corresponding to the correct combination</span>
    <span class="c1"># of categorical levels</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Create and train the Gaussian process models</span>
    <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">algoIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">KrigingAlgorithm</span><span class="p">(</span><span class="n">xLoc</span><span class="p">,</span> <span class="n">yLoc</span><span class="p">,</span> <span class="n">kIndependent</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
    <span class="n">algoIndependent</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgInd</span><span class="p">)</span>
    <span class="n">algoIndependent</span><span class="o">.</span><span class="n">setOptimizationBounds</span><span class="p">(</span><span class="n">boundsInd</span><span class="p">)</span>
    <span class="n">algoIndependent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">algoIndependentList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">algoIndependent</span><span class="o">.</span><span class="n">getResult</span><span class="p">())</span>
</pre></div>
</div>
<p>Plot the prediction of the mixed continuous / categorical GP,
as well as the one of the two separate continuous GPs</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">):</span>
    <span class="c1"># Select the training samples corresponding to the correct combination</span>
    <span class="c1"># of categorical levels</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Compute the models predictive performances on a validation data set.</span>
    <span class="c1"># The predictions are computed independently for each level of z,</span>
    <span class="c1"># i.e., by only considering the values of z corresponding to the</span>
    <span class="c1"># target level.</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xPlt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xPltInd</span> <span class="o">=</span> <span class="n">xPlt</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="n">yPltInd</span> <span class="o">=</span> <span class="n">yPlt</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="n">predMeanLV</span> <span class="o">=</span> <span class="n">resLV</span><span class="o">.</span><span class="n">getConditionalMean</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">)</span>
    <span class="n">predMeanInd</span> <span class="o">=</span> <span class="n">algoIndependentList</span><span class="p">[</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">getConditionalMean</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">predSTDLV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">resLV</span><span class="o">.</span><span class="n">getConditionalMarginalVariance</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">))</span>
    <span class="n">predSTDInd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">algoIndependentList</span><span class="p">[</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">getConditionalMarginalVariance</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="p">)</span>

    <span class="p">(</span><span class="n">trainingData</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xLoc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yLoc</span><span class="p">,</span> <span class="s2">&quot;r*&quot;</span><span class="p">)</span>
    <span class="p">(</span><span class="n">trueFunction</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yPltInd</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="p">(</span><span class="n">prediction</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">predMeanLV</span><span class="p">,</span> <span class="s2">&quot;b-&quot;</span><span class="p">)</span>
    <span class="n">stdPred</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanLV</span> <span class="o">-</span> <span class="n">predSTDLV</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanLV</span> <span class="o">+</span> <span class="n">predSTDLV</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xLoc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yLoc</span><span class="p">,</span> <span class="s2">&quot;r*&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yPltInd</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">predMeanInd</span><span class="p">,</span> <span class="s2">&quot;b-&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanInd</span> <span class="o">-</span> <span class="n">predSTDInd</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanInd</span> <span class="o">+</span> <span class="n">predSTDInd</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
    <span class="p">[</span><span class="n">trainingData</span><span class="p">,</span> <span class="n">trueFunction</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">stdPred</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Training data&quot;</span><span class="p">,</span> <span class="s2">&quot;True function&quot;</span><span class="p">,</span> <span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="s2">&quot;Prediction standard deviation&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Mixed continuous-categorical modeling&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Separate modeling&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_kriging_categorical_001.png" srcset="../../_images/sphx_glr_plot_kriging_categorical_001.png" alt="Mixed continuous-categorical modeling, Separate modeling" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Text(138.47222222222223, 0.5, &#39;y&#39;)
</pre></div>
</div>
<p>It can be seen that the joint modeling of categorical and continuous variables
improves the overall prediction accuracy, as the Gaussian process model is
able to exploit the information provided by the entire training data set.</p>
<p>We now consider a more complex function which is a modified version of the Goldstein function,
taken from <a class="reference internal" href="../../bibliography.html#pelamatti2020" id="id2"><span>[pelamatti2020]</span></a>. This function depends on 2 continuous variables and 2 categorical ones.
Each categorical variable is characterized by 3 levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">h</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mf">53.3108</span>
        <span class="o">+</span> <span class="mf">0.184901</span> <span class="o">*</span> <span class="n">x1</span>
        <span class="o">-</span> <span class="mf">5.02914</span> <span class="o">*</span> <span class="n">x1</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">7.72522</span> <span class="o">*</span> <span class="n">x1</span><span class="o">**</span><span class="mi">4</span> <span class="o">*</span> <span class="mf">1e-8</span>
        <span class="o">-</span> <span class="mf">0.0870775</span> <span class="o">*</span> <span class="n">x2</span>
        <span class="o">-</span> <span class="mf">0.106959</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">+</span> <span class="mf">7.98772</span> <span class="o">*</span> <span class="n">x3</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">0.00242482</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">1.32851</span> <span class="o">*</span> <span class="n">x4</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="mf">0.00146393</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span>
        <span class="o">-</span> <span class="mf">0.00301588</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">-</span> <span class="mf">0.00272291</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">0.0017004</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">+</span> <span class="mf">0.0038428</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">-</span> <span class="mf">0.000198969</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">1.86025</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="mf">1e-5</span>
        <span class="o">-</span> <span class="mf">1.88719</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">2.50923</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-5</span>
        <span class="o">-</span> <span class="mf">5.62199</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-5</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">Goldstein</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">inp</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">x2</span>

    <span class="k">if</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="k">elif</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="k">elif</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error, no matching category z1&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="k">elif</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="k">elif</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error, no matching category z2&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">h</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">)]</span>


<span class="n">dim</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">fun</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">PythonFunction</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Goldstein</span><span class="p">)</span>
<span class="n">numberOfZLevels1</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Number of categorical levels for z1</span>
<span class="n">numberOfZLevels2</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Number of categorical levels for z2</span>
<span class="c1"># Input distribution</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">))),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">))),</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As in the previous example, we start here by defining the product kernel,
which combines <a class="reference internal" href="../../user_manual/_generated/openturns.SquaredExponential.html#openturns.SquaredExponential" title="openturns.SquaredExponential"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquaredExponential</span></code></a> kernels for the continuous variables, and
<a class="reference internal" href="../../user_manual/_generated/openturns.experimental.LatentVariableModel.html#openturns.experimental.LatentVariableModel" title="openturns.experimental.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a> for the categorical ones.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">latDim</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Dimension of the latent space</span>
<span class="n">activeCoord</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">2</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span><span class="n">numberOfZLevels1</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span><span class="n">numberOfZLevels2</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># Nb ative coordinates in the latent space</span>
<span class="n">kx1</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kx2</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kz1</span> <span class="o">=</span> <span class="n">otexp</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kz2</span> <span class="o">=</span> <span class="n">otexp</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ProductCovarianceModel</span><span class="p">([</span><span class="n">kx1</span><span class="p">,</span> <span class="n">kx2</span><span class="p">,</span> <span class="n">kz1</span><span class="p">,</span> <span class="n">kz2</span><span class="p">])</span>
<span class="n">kLV</span><span class="o">.</span><span class="n">setNuggetFactor</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="c1"># Bounds for the hyperparameter optimization</span>
<span class="n">lowerBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">upperBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">boundsLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Interval</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">,</span> <span class="n">upperBoundLV</span><span class="p">)</span>
<span class="c1"># Distribution for the hyperparameters initialization</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">)):</span>
    <span class="n">initDistLV</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span><span class="n">initDistLV</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, we consider a purely continuous kernel for independent Gaussian processes.
one for each combination of categorical variables levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">kIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">lowerBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">]</span>
<span class="n">upperBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<span class="n">boundsInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Interval</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">,</span> <span class="n">upperBoundInd</span><span class="p">)</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">)):</span>
    <span class="n">initDistInd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ComposedDistribution</span><span class="p">(</span><span class="n">initDistInd</span><span class="p">)</span>
<span class="n">initSampleInd</span> <span class="o">=</span> <span class="n">initDistInd</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optAlgInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">NLopt</span><span class="p">(</span><span class="s2">&quot;LN_COBYLA&quot;</span><span class="p">),</span> <span class="n">initSampleInd</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to assess their respective robustness with regards to the training data set,
we repeat the experiments 10 times with different training of size 72,
and compute each time the normalized prediction Root Mean Squared Error (RMSE) on a
test data set of size 1000.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">rmseLVList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">rmseIndList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># Generate the normalized training data set</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">72</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">yMax</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">getMax</span><span class="p">()</span>
    <span class="n">yMin</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">getMin</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yMin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">yMin</span> <span class="o">-</span> <span class="n">yMax</span><span class="p">)</span>

    <span class="c1"># Initialize  and parameterize the optimization algorithm</span>
    <span class="n">initSampleLV</span> <span class="o">=</span> <span class="n">initDistLV</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">optAlgLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">NLopt</span><span class="p">(</span><span class="s2">&quot;LN_COBYLA&quot;</span><span class="p">),</span> <span class="n">initSampleLV</span><span class="p">)</span>

    <span class="c1"># Create and train the Gaussian process models</span>
    <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">algoLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">KrigingAlgorithm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kLV</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
    <span class="n">algoLV</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgLV</span><span class="p">)</span>
    <span class="n">algoLV</span><span class="o">.</span><span class="n">setOptimizationBounds</span><span class="p">(</span><span class="n">boundsLV</span><span class="p">)</span>
    <span class="n">algoLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">resLV</span> <span class="o">=</span> <span class="n">algoLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

    <span class="c1"># Compute the models predictive performances on a validation data set</span>
    <span class="n">xVal</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">yVal</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">xVal</span><span class="p">)</span>
    <span class="n">yVal</span> <span class="o">=</span> <span class="p">(</span><span class="n">yVal</span> <span class="o">-</span> <span class="n">yMin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">yMin</span> <span class="o">-</span> <span class="n">yMax</span><span class="p">)</span>

    <span class="n">valLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MetaModelValidation</span><span class="p">(</span><span class="n">xVal</span><span class="p">,</span> <span class="n">yVal</span><span class="p">,</span> <span class="n">resLV</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">())</span>
    <span class="n">rmseLV</span> <span class="o">=</span> <span class="n">valLV</span><span class="o">.</span><span class="n">getResidualSample</span><span class="p">()</span><span class="o">.</span><span class="n">computeStandardDeviation</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rmseLVList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmseLV</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">z1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">z2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">):</span>
            <span class="c1"># Select the training samples corresponding to the correct combination</span>
            <span class="c1"># of categorical levels</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span> <span class="o">==</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

            <span class="c1"># Create and train the Gaussian process models</span>
            <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="n">algoIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">KrigingAlgorithm</span><span class="p">(</span><span class="n">xLoc</span><span class="p">,</span> <span class="n">yLoc</span><span class="p">,</span> <span class="n">kIndependent</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
            <span class="n">algoIndependent</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgInd</span><span class="p">)</span>
            <span class="n">algoIndependent</span><span class="o">.</span><span class="n">setOptimizationBounds</span><span class="p">(</span><span class="n">boundsInd</span><span class="p">)</span>
            <span class="n">algoIndependent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="n">resInd</span> <span class="o">=</span> <span class="n">algoIndependent</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

            <span class="c1"># Compute the models predictive performances on a validation data set</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xVal</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span> <span class="o">==</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">xValInd</span> <span class="o">=</span> <span class="n">xVal</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">yValInd</span> <span class="o">=</span> <span class="n">yVal</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
            <span class="n">valInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MetaModelValidation</span><span class="p">(</span><span class="n">xValInd</span><span class="p">,</span> <span class="n">yValInd</span><span class="p">,</span> <span class="n">resInd</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">())</span>
            <span class="n">error</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">valInd</span><span class="o">.</span><span class="n">getResidualSample</span><span class="p">())</span>
    <span class="n">rmseInd</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">computeStandardDeviation</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rmseIndList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmseInd</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">([</span><span class="n">rmseLVList</span><span class="p">,</span> <span class="n">rmseIndList</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Mixed continuous-categorical GP&quot;</span><span class="p">,</span> <span class="s2">&quot;Independent GPs&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;RMSE&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_kriging_categorical_002.png" srcset="../../_images/sphx_glr_plot_kriging_categorical_002.png" alt="plot kriging categorical" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Text(33.722222222222214, 0.5, &#39;RMSE&#39;)
</pre></div>
</div>
<p>The obtained results show, for this test-case, a better modeling performance
when modeling the function as a mixed categorical/continuous function, rather
than relying on multiple purely continuous Gaussian processes.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 10.165 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-meta-modeling-kriging-metamodel-plot-kriging-categorical-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/cd1d2b1dd40611fd8ac29789bd8b32df/plot_kriging_categorical.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_kriging_categorical.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/770403037745ed5ae8864d0aaf68cc1c/plot_kriging_categorical.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_kriging_categorical.py</span></code></a></p>
</div>
</div>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../fields_metamodels/index.html" title="Fields metamodels"
             >next</a> |</li>
        <li class="right" >
          <a href="plot_draw_covariance_models.html" title="Kriging : draw covariance models"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.22 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Meta modeling</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" >Kriging metamodel</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Kriging: metamodel with continuous and categorical variables</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2023 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Jan 13, 2024.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    </div>
  </body>
</html>