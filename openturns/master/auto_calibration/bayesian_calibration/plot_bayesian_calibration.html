
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bayesian calibration of a computer code &#8212; OpenTURNS 1.19dev documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/openturns.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/mysearchtools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Bayesian calibration of the flooding model" href="plot_bayesian_calibration_flooding.html" />
    <link rel="prev" title="Gibbs sampling of the posterior distribution" href="plot_gibbs.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://gitter.im/openturns/community">Chat</a></li>
    <li><a href="https://github.com/openturns/openturns/wiki/Modules">Modules</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="plot_bayesian_calibration_flooding.html" title="Bayesian calibration of the flooding model"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_gibbs.html" title="Gibbs sampling of the posterior distribution"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.19dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" accesskey="U">Calibration</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Bayesian calibration of a computer code</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Bayesian calibration of a computer code</a><ul>
<li><a class="reference internal" href="#test-the-metropolis-hastings-sampler">Test the Metropolis-Hastings sampler</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="plot_gibbs.html"
                          title="previous chapter">Gibbs sampling of the posterior distribution</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="plot_bayesian_calibration_flooding.html"
                          title="next chapter">Bayesian calibration of the flooding model</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/auto_calibration/bayesian_calibration/plot_bayesian_calibration.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-calibration-bayesian-calibration-plot-bayesian-calibration-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="bayesian-calibration-of-a-computer-code">
<span id="sphx-glr-auto-calibration-bayesian-calibration-plot-bayesian-calibration-py"></span><h1>Bayesian calibration of a computer code<a class="headerlink" href="#bayesian-calibration-of-a-computer-code" title="Permalink to this headline">¶</a></h1>
<p>In this example we are going to compute the parameters of a computer model thanks to Bayesian estimation.</p>
<p>Let us denote <img class="math" src="../../_images/math/7fd44f72cad4b434a1aa5ce85dbacda0cc1a98bc.svg" alt="(y_1, \dots, y_n)"/> the observation sample,
<img class="math" src="../../_images/math/79a21fbcafd530c70a18c70b467bb063890bd910.svg" alt="(\vect z_1, \ldots, \vect z_n) = (f(x_1|\vect\theta), \ldots, f(x_n|\vect\theta))"/> the model prediction,
<img class="math" src="../../_images/math/b50da57beee9984d401dcf291d6a75ebb09959a9.svg" alt="p(y |\vect z)"/> the density function of observation <img class="math" src="../../_images/math/7887520f8387f92cf22143f7bdce04904c79e3ef.svg" alt="y"/>
conditional on model prediction <img class="math" src="../../_images/math/bbc52dd89a8b2f1566b6f6ff8cac6683272372fe.svg" alt="\vect z"/>,
and <img class="math" src="../../_images/math/85f35bfc67e661f483c88eecae94d58db1b995cc.svg" alt="\vect\theta \in \mathbb{R}^p"/> the calibration parameters we wish to estimate.</p>
<p>The posterior distribution is given by Bayes theorem:</p>
<p>where <img class="math" src="../../_images/math/49dad8e1fd5f532b753e026d008944450a94e4da.svg" alt="\propto"/> means “proportional to”, regarded as a function of <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/>.</p>
<p>The posterior distribution is approximated here by the empirical distribution of the sample <img class="math" src="../../_images/math/0547c027bef267bff7addd70371be48fe80c0291.svg" alt="\vect\theta^1, \ldots, \vect\theta^N"/> generated by the Metropolis-Hastings algorithm. This means that any quantity characteristic of the posterior distribution (mean, variance, quantile, …) is approximated by its empirical counterpart.</p>
<p>Our model (i.e. the compute code to calibrate) is a standard normal linear regression, where</p>
<div class="math">
<p><img src="../../_images/math/40084435e3576c08f6051f4c918fe787f1d85f7a.svg" alt="y_i = \theta_1 + x_i \theta_2 + x_i^2 \theta_3 + \varepsilon_i"/></p>
</div><p>where <img class="math" src="../../_images/math/3fc72fe9c94599839f613758736d6272a1aac191.svg" alt="\varepsilon_i \stackrel{i.i.d.}{\sim} \mathcal N(0, 1)"/>.</p>
<p>The “true” value of <img class="math" src="../../_images/math/7e3e48300089e25fc3edb19ddc60fb5e8bbfea3d.svg" alt="\theta"/> is:</p>
<div class="math">
<p><img src="../../_images/math/8e4abd695d9309bce5d3d8b8cbeffc946cf5f8d2.svg" alt="\vect \theta_{true} = (-4.5,4.8,2.2)^T."/></p>
</div><p>We use a normal prior on <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/>:</p>
<div class="math">
<p><img src="../../_images/math/6e4e27ea52c2bbe7d0736d127c42d810fa4bd73f.svg" alt="\pi(\vect\theta) = \mathcal N(\vect{\mu}_\vect{\theta}, \mat{\Sigma}_\vect{\theta})"/></p>
</div><p>where</p>
<div class="math">
<p><img src="../../_images/math/de86f7b4da1af3f535761647dec5799a37b4aff8.svg" alt="\vect{\mu}_\vect{\theta} =
\begin{pmatrix}
 -3 \\
  4 \\
  1
\end{pmatrix}"/></p>
</div><p>is the mean of the prior and</p>
<div class="math">
<p><img src="../../_images/math/60617f574c222463c580466e4999a290ad99373c.svg" alt="\mat{\Sigma}_\vect{\theta} =
\begin{pmatrix}
  \sigma_{\theta_1}^2 &amp; 0 &amp; 0 \\
  0 &amp; \sigma_{\theta_2}^2 &amp; 0 \\
  0 &amp; 0 &amp; \sigma_{\theta_3}^2
\end{pmatrix}"/></p>
</div><p>is the prior covariance matrix with</p>
<div class="math">
<p><img src="../../_images/math/1c9c8b773c1d17a105b18dfb4445dc489c6820ea.svg" alt="\sigma_{\theta_1} = 2, \qquad \sigma_{\theta_2} = 1, \qquad \sigma_{\theta_3} = 1.5."/></p>
</div><p>The following objects need to be defined in order to perform Bayesian calibration:</p>
<ul class="simple">
<li><p>The conditional density <img class="math" src="../../_images/math/0c69579bb33b76e4e3aaaa8822e3c5143fa827dd.svg" alt="p(y|\vect z)"/> must be defined as a probability distribution.</p></li>
<li><p>The computer model must be implemented thanks to the ParametricFunction class.
This takes a value of <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/> as input, and outputs the vector of model predictions <img class="math" src="../../_images/math/bbc52dd89a8b2f1566b6f6ff8cac6683272372fe.svg" alt="\vect z"/>,
as defined above (the vector of covariates <img class="math" src="../../_images/math/161499480ed53ad1b98bdf1ea23721ca613d4daa.svg" alt="\vect x = (x_1, \ldots, x_n)"/> is treated as a known constant).
When doing that, we have to keep in mind that <img class="math" src="../../_images/math/bbc52dd89a8b2f1566b6f6ff8cac6683272372fe.svg" alt="\vect z"/> will be used as the vector of parameters corresponding
to the distribution specified for <img class="math" src="../../_images/math/b50da57beee9984d401dcf291d6a75ebb09959a9.svg" alt="p(y |\vect z)"/>. For instance, if <img class="math" src="../../_images/math/0c69579bb33b76e4e3aaaa8822e3c5143fa827dd.svg" alt="p(y|\vect z)"/> is normal,
this means that <img class="math" src="../../_images/math/bbc52dd89a8b2f1566b6f6ff8cac6683272372fe.svg" alt="\vect z"/> must be a vector containing the mean and standard deviation of <img class="math" src="../../_images/math/7887520f8387f92cf22143f7bdce04904c79e3ef.svg" alt="y"/>.</p></li>
<li><p>The prior density <img class="math" src="../../_images/math/067ecb443e80120f8043fae923d7a18977cd56dd.svg" alt="\pi(\vect\theta)"/> encoding the set of possible values for the calibration parameters,
each value being weighted by its a priori probability, reflecting the beliefs about the possible values
of <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/> before consideration of the experimental data.
Again, this is implemented as a probability distribution.</p></li>
<li><p>Metropolis-Hastings algorithm(s), possibly used in tandem with a Gibbs algorithm
in order to sample from the posterior distribution of the calibration parameters.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">openturns</span> <span class="k">as</span> <span class="nn">ot</span>
<span class="kn">import</span> <span class="nn">openturns.viewer</span> <span class="k">as</span> <span class="nn">viewer</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">ot</span><span class="o">.</span><span class="n">Log</span><span class="o">.</span><span class="n">Show</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Log</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
</pre></div>
</div>
<p>Dimension of the vector of parameters to calibrate</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">paramDim</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># The number of obesrvations</span>
<span class="n">obsSize</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
<p>Define the observed inputs <img class="math" src="../../_images/math/8796c964f035c17f755797d51f050539a5e75915.svg" alt="x_i"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.</span>
<span class="n">xmax</span> <span class="o">=</span> <span class="mf">3.</span>
<span class="n">step</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span><span class="o">-</span><span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">obsSize</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rg</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">RegularGrid</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">obsSize</span><span class="p">)</span>
<span class="n">x_obs</span> <span class="o">=</span> <span class="n">rg</span><span class="o">.</span><span class="n">getVertices</span><span class="p">()</span>
</pre></div>
</div>
<p>Define the parametric model <img class="math" src="../../_images/math/63d5f09b8df9e36913806dc0956d2935b3584b96.svg" alt="\vect z = f(x,\vect\theta)"/> that associates each
observation <img class="math" src="../../_images/math/865f48ab61e258cd6e57c005da1578de4b22f440.svg" alt="x"/> and value of <img class="math" src="../../_images/math/42af8c25ddc6c77358a4faa80f45647332c59e76.svg" alt="\vect \theta"/> to the parameters
of the distribution of the corresponding observation <img class="math" src="../../_images/math/7887520f8387f92cf22143f7bdce04904c79e3ef.svg" alt="y"/>:
here <img class="math" src="../../_images/math/6da565bfaacc62e29298cc020e53b0386225477d.svg" alt="\vect z=(\mu, \sigma)"/> where <img class="math" src="../../_images/math/27bac18d6a2d4509501cd348773fd83bd46a0dc6.svg" alt="\mu"/>,
the first output of the model, is the mean and <img class="math" src="../../_images/math/c407acdc527ca1937ae333fa8475cb95384c8087.svg" alt="\sigma"/>,
the second output of the model, is the standard deviation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fullModel</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SymbolicFunction</span><span class="p">(</span>
    <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;theta1&#39;</span><span class="p">,</span> <span class="s1">&#39;theta2&#39;</span><span class="p">,</span> <span class="s1">&#39;theta3&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;theta1+theta2*x+theta3*x^2&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>To differentiate between the two classes of inputs (<img class="math" src="../../_images/math/865f48ab61e258cd6e57c005da1578de4b22f440.svg" alt="x"/> and <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/>),
we define a <a class="reference internal" href="../../user_manual/_generated/openturns.ParametricFunction.html#openturns.ParametricFunction" title="openturns.ParametricFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParametricFunction</span></code></a> from <cite>fullModel</cite>
and make the first input (the observations <img class="math" src="../../_images/math/865f48ab61e258cd6e57c005da1578de4b22f440.svg" alt="x"/>) its <em>parameter</em>:
<img class="math" src="../../_images/math/154860293857eb78809c72f76f1b4f0f7768e136.svg" alt="f_x(\vect \theta) := f(x, \vect \theta)"/>.
We set <img class="math" src="../../_images/math/6d5f036af74bb1e788b4f06554ef4c7d615f69e8.svg" alt="x = 1"/> as a placeholder,
but <img class="math" src="../../_images/math/865f48ab61e258cd6e57c005da1578de4b22f440.svg" alt="x"/> will actually take the values <img class="math" src="../../_images/math/8796c964f035c17f755797d51f050539a5e75915.svg" alt="x_i"/> of the observations
when we sample <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">linkFunction</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ParametricFunction</span><span class="p">(</span><span class="n">fullModel</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linkFunction</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ParametricEvaluation([x,theta1,theta2,theta3]-&gt;[theta1+theta2*x+theta3*x^2,1.0], parameters positions=[0], parameters=[x : 1], input positions=[1,2,3])
</pre></div>
</div>
<p>Define the observation noise <img class="math" src="../../_images/math/a7c6c82d441f294a944fb58c5dc9a4e01548d220.svg" alt="\varepsilon {\sim} \mathcal N(0, 1)"/> and create a sample from it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ot</span><span class="o">.</span><span class="n">RandomGenerator</span><span class="o">.</span><span class="n">SetSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">noiseStandardDeviation</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noiseStandardDeviation</span><span class="p">)</span>
<span class="n">noiseSample</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="n">obsSize</span><span class="p">)</span>
</pre></div>
</div>
<p>Define the vector of observations <img class="math" src="../../_images/math/0ffee592382c3b0811eb93d860f3e36cd9d42aa2.svg" alt="y_i"/>,
here sampled using the “true” value of <img class="math" src="../../_images/math/42af8c25ddc6c77358a4faa80f45647332c59e76.svg" alt="\vect \theta"/>: <img class="math" src="../../_images/math/e0f104bdce060d5bb31ad31bd6eda04ef7d0e7e3.svg" alt="\vect \theta_{true}"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">thetaTrue</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_obs</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">obsSize</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">obsSize</span><span class="p">):</span>
    <span class="n">linkFunction</span><span class="o">.</span><span class="n">setParameter</span><span class="p">(</span><span class="n">x_obs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y_obs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">linkFunction</span><span class="p">(</span><span class="n">thetaTrue</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">noiseSample</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Draw the model predictions vs the observations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">functionnalModel</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ParametricFunction</span><span class="p">(</span><span class="n">fullModel</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">thetaTrue</span><span class="p">)</span>
<span class="n">graphModel</span> <span class="o">=</span> <span class="n">functionnalModel</span><span class="o">.</span><span class="n">getMarginal</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Cloud</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Cloud</span><span class="p">(</span><span class="n">x_obs</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
<span class="n">observations</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">graphModel</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
<span class="n">graphModel</span><span class="o">.</span><span class="n">setLegends</span><span class="p">([</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Observations&quot;</span><span class="p">])</span>
<span class="n">graphModel</span><span class="o">.</span><span class="n">setLegendPosition</span><span class="p">(</span><span class="s2">&quot;topleft&quot;</span><span class="p">)</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">viewer</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graphModel</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_bayesian_calibration_001.png" srcset="../../_images/sphx_glr_plot_bayesian_calibration_001.png" alt="y0 as a function of x" class = "sphx-glr-single-img"/><p>Define the distribution of observations <img class="math" src="../../_images/math/080bd83489702234a4f8f6b6215bfabccd72835d.svg" alt="y | \vect{z}"/> conditional on model predictions.</p>
<p>Note that its parameter dimension is the one of <img class="math" src="../../_images/math/941513b93cec41dd0a260cc6ae6ce462edf907ea.svg" alt="\vect{z}"/>, so the model must be adjusted accordingly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conditional</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Normal</span><span class="p">()</span>
</pre></div>
</div>
<p>Define the mean <img class="math" src="../../_images/math/d462786850bd2fc21fd050569b5468293157c893.svg" alt="\mu_\theta"/>, the covariance matrix <img class="math" src="../../_images/math/3f1a11f37be68795e110c0934f2a70d38b8a68c3.svg" alt="\Sigma_\theta"/>, then the prior distribution <img class="math" src="../../_images/math/067ecb443e80120f8043fae923d7a18977cd56dd.svg" alt="\pi(\vect\theta)"/> of the parameter <img class="math" src="../../_images/math/e3589604ebf609d9164cb6328467ea55057730a7.svg" alt="\vect\theta"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">thetaPriorMean</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sigma0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>  <span class="c1"># standard deviations</span>
<span class="n">thetaPriorCovarianceMatrix</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">CovarianceMatrix</span><span class="p">(</span><span class="n">paramDim</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">paramDim</span><span class="p">):</span>
    <span class="n">thetaPriorCovarianceMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">thetaPriorMean</span><span class="p">,</span> <span class="n">thetaPriorCovarianceMatrix</span><span class="p">)</span>
<span class="n">prior</span><span class="o">.</span><span class="n">setDescription</span><span class="p">([</span><span class="s1">&#39;theta1&#39;</span><span class="p">,</span> <span class="s1">&#39;theta2&#39;</span><span class="p">,</span> <span class="s1">&#39;theta3&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>The proposed steps for
<img class="math" src="../../_images/math/7aac20ab1eb4c38ae4a8af0c998f3e1566e867b8.svg" alt="\theta_1"/>, <img class="math" src="../../_images/math/fd29a542eb2e15c489fc30b4911a69a88ce0ca01.svg" alt="\theta_2"/> and <img class="math" src="../../_images/math/125fbca292ba6e8f747a1e13bce2f89fec96435b.svg" alt="\theta_3"/>
will all follow a uniform distribution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">proposal</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="test-the-metropolis-hastings-sampler">
<h2>Test the Metropolis-Hastings sampler<a class="headerlink" href="#test-the-metropolis-hastings-sampler" title="Permalink to this headline">¶</a></h2>
<p>Creation of a single component random walk Metropolis-Hastings (RWMH) sampler.
This involves a combination of the RWMH and the Gibbs algorithms.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">initialState</span> <span class="o">=</span> <span class="n">thetaPriorMean</span>
</pre></div>
</div>
<p>We create a <a class="reference internal" href="../../user_manual/_generated/openturns.RandomWalkMetropolisHastings.html#openturns.RandomWalkMetropolisHastings" title="openturns.RandomWalkMetropolisHastings"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomWalkMetropolisHastings</span></code></a> sampler for each component.
Each sampler must be aware of the joint prior distribution.
We also use the same proposal distribution, but this is not mandatory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mh_coll</span> <span class="o">=</span> <span class="p">[</span><span class="n">ot</span><span class="o">.</span><span class="n">RandomWalkMetropolisHastings</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">initialState</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">paramDim</span><span class="p">)]</span>
</pre></div>
</div>
<p>Each sampler must be made aware of the likelihood.
Otherwise we would sample from the prior!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">mh</span> <span class="ow">in</span> <span class="n">mh_coll</span><span class="p">:</span> <span class="n">mh</span><span class="o">.</span><span class="n">setLikelihood</span><span class="p">(</span><span class="n">conditional</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">linkFunction</span><span class="p">,</span> <span class="n">x_obs</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, the <a class="reference internal" href="../../user_manual/_generated/openturns.Gibbs.html#openturns.Gibbs" title="openturns.Gibbs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Gibbs</span></code></a> algorithm is constructed from all Metropolis-Hastings samplers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Gibbs</span><span class="p">(</span><span class="n">mh_coll</span><span class="p">)</span>
</pre></div>
</div>
<p>Tuning of the Gibbs algorithm:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span><span class="o">.</span><span class="n">setThinning</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sampler</span><span class="o">.</span><span class="n">setBurnIn</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
<p>Generate a sample from the posterior distribution of the parameters <img class="math" src="../../_images/math/42af8c25ddc6c77358a4faa80f45647332c59e76.svg" alt="\vect \theta"/>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sampleSize</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="n">sampleSize</span><span class="p">)</span>
</pre></div>
</div>
<p>Look at the acceptance rate (basic check of the sampling efficiency:
values close to <img class="math" src="../../_images/math/063ccab33fe1ef95493d970dfce86be0d0b686de.svg" alt="0.2"/> are usually recommended
for Normal posterior distributions).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">mh</span><span class="o">.</span><span class="n">getAcceptanceRate</span><span class="p">()</span> <span class="k">for</span> <span class="n">mh</span> <span class="ow">in</span> <span class="n">sampler</span><span class="o">.</span><span class="n">getMetropolisHastingsCollection</span><span class="p">()]</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.46225, 0.29283333333333333, 0.12466666666666666]
</pre></div>
</div>
<p>Build the distribution of the posterior by kernel smoothing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">KernelSmoothing</span><span class="p">()</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
<p>Display prior vs posterior for each parameter.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">parameter_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">paramDim</span><span class="p">):</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">getMarginal</span><span class="p">(</span><span class="n">parameter_index</span><span class="p">)</span><span class="o">.</span><span class="n">drawPDF</span><span class="p">()</span>
    <span class="n">priorGraph</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">getMarginal</span><span class="p">(</span><span class="n">parameter_index</span><span class="p">)</span><span class="o">.</span><span class="n">drawPDF</span><span class="p">()</span>
    <span class="n">priorGraph</span><span class="o">.</span><span class="n">setColors</span><span class="p">([</span><span class="s1">&#39;blue&#39;</span><span class="p">])</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">priorGraph</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">setLegends</span><span class="p">([</span><span class="s1">&#39;Posterior&#39;</span><span class="p">,</span> <span class="s1">&#39;Prior&#39;</span><span class="p">])</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">paramDim</span><span class="p">,</span> <span class="n">parameter_index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">viewer</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="n">ax</span><span class="p">])</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Bayesian calibration&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_bayesian_calibration_002.png" srcset="../../_images/sphx_glr_plot_bayesian_calibration_002.png" alt="Bayesian calibration" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  1.504 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-calibration-bayesian-calibration-plot-bayesian-calibration-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/557f6965239dde7b8b9613eb917dc826/plot_bayesian_calibration.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_bayesian_calibration.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4c9fe30a2a1c939510fb7d6a12aa86d9/plot_bayesian_calibration.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_bayesian_calibration.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="plot_bayesian_calibration_flooding.html" title="Bayesian calibration of the flooding model"
             >next</a> |</li>
        <li class="right" >
          <a href="plot_gibbs.html" title="Gibbs sampling of the posterior distribution"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.19dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Calibration</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Bayesian calibration of a computer code</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2022 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Jan 01, 2022.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.4.0.
    </div>
  </body>
</html>