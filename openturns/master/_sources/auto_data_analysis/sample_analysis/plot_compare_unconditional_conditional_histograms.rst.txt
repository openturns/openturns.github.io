
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_data_analysis/sample_analysis/plot_compare_unconditional_conditional_histograms.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py:


Compare unconditional and conditional histograms
================================================

.. GENERATED FROM PYTHON SOURCE LINES 6-29

In this example, we compare unconditional and conditional histograms for a
simulation.
We consider the :ref:`flooding model<use-case-flood-model>`.
Let :math:`g` be a function which takes four inputs :math:`Q`, :math:`K_s`,
:math:`Z_v` and :math:`Z_m` and returns one output :math:`S`.

We first consider the (unconditional) distribution of the input :math:`Q`.

Let :math:`t` be a given threshold on the output :math:`S`: we consider
the event :math:`S > t`.
Then we consider the conditional distribution of the input :math:`Q` given
that :math:`S > t` that is to say :math:`Q|S > t`.

If these two distributions are significantly different, we conclude that
the input :math:`Q` has an impact on the event :math:`S > t`.

In order to approximate the distribution of the output :math:`S`,
we perform a Monte-Carlo simulation with size 500.
The threshold :math:`t` is chosen as the 90% quantile of the empirical
distribution of :math:`S`.
In this example, the distribution is aproximated by its empirical histogram
(but this could be done with another distribution approximation as well,
such as kernel smoothing for example).

.. GENERATED FROM PYTHON SOURCE LINES 31-39

.. code-block:: Python

    import numpy as np
    from openturns.usecases import flood_model
    import openturns as ot
    import openturns.viewer as viewer
    from matplotlib import pylab as plt

    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 40-41

We use the `FloodModel` data class that contains all the case parameters.

.. GENERATED FROM PYTHON SOURCE LINES 41-44

.. code-block:: Python

    fm = flood_model.FloodModel()









.. GENERATED FROM PYTHON SOURCE LINES 45-47

Create an input sample from the joint `distribution` defined in the data class.
We build an output sample by taking the image by the `model`.

.. GENERATED FROM PYTHON SOURCE LINES 49-53

.. code-block:: Python

    size = 500
    inputSample = fm.distribution.getSample(size)
    inputSample[:5]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>Q (m3/s)</th><th>Ks</th><th>Zv (m)</th><th>Zm (m)</th><th>B (m)</th><th>L (m)</th><th>Zb (m)</th><th>Hd (m)</th></tr>
      <tr><th>0</th><td>1063.726</td><td>38.06548</td><td>50.39993</td><td>54.86306</td><td>298.0836</td><td>5005.276</td><td>55.9197</td><td>3.769474</td></tr>
      <tr><th>1</th><td>2669.985</td><td>35.38468</td><td>50.96702</td><td>55.02743</td><td>300.6449</td><td>4997.797</td><td>55.51303</td><td>2.20788</td></tr>
      <tr><th>2</th><td>819.3024</td><td>29.63425</td><td>50.47175</td><td>55.29169</td><td>298.9003</td><td>4995.399</td><td>55.40463</td><td>2.025785</td></tr>
      <tr><th>3</th><td>427.9938</td><td>31.48594</td><td>50.98895</td><td>55.23273</td><td>302.6107</td><td>5002.279</td><td>55.24005</td><td>3.356556</td></tr>
      <tr><th>4</th><td>2099.155</td><td>25.49303</td><td>50.87001</td><td>54.12593</td><td>301.6103</td><td>5004</td><td>55.26249</td><td>2.107098</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 54-57

.. code-block:: Python

    outputSample = fm.model(inputSample)
    outputSample[:5]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>H</th><th>S</th><th>C</th></tr>
      <tr><th>0</th><td>1.986611</td><td>-7.30263</td><td>0.8371662</td></tr>
      <tr><th>1</th><td>3.688473</td><td>-3.065411</td><td>1.39999</td></tr>
      <tr><th>2</th><td>1.924566</td><td>-5.034106</td><td>1.231399</td></tr>
      <tr><th>3</th><td>1.29684</td><td>-6.310816</td><td>0.9741227</td></tr>
      <tr><th>4</th><td>4.146667</td><td>-2.35292</td><td>1.4</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 58-59

Merge the input and output samples into a single sample.

.. GENERATED FROM PYTHON SOURCE LINES 61-65

.. code-block:: Python

    sample = ot.Sample(inputSample)
    sample.stack(outputSample)
    sample[0:5]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>Q (m3/s)</th><th>Ks</th><th>Zv (m)</th><th>Zm (m)</th><th>B (m)</th><th>L (m)</th><th>Zb (m)</th><th>Hd (m)</th><th>H</th><th>S</th><th>C</th></tr>
      <tr><th>0</th><td>1063.726</td><td>38.06548</td><td>50.39993</td><td>54.86306</td><td>298.0836</td><td>5005.276</td><td>55.9197</td><td>3.769474</td><td>1.986611</td><td>-7.30263</td><td>0.8371662</td></tr>
      <tr><th>1</th><td>2669.985</td><td>35.38468</td><td>50.96702</td><td>55.02743</td><td>300.6449</td><td>4997.797</td><td>55.51303</td><td>2.20788</td><td>3.688473</td><td>-3.065411</td><td>1.39999</td></tr>
      <tr><th>2</th><td>819.3024</td><td>29.63425</td><td>50.47175</td><td>55.29169</td><td>298.9003</td><td>4995.399</td><td>55.40463</td><td>2.025785</td><td>1.924566</td><td>-5.034106</td><td>1.231399</td></tr>
      <tr><th>3</th><td>427.9938</td><td>31.48594</td><td>50.98895</td><td>55.23273</td><td>302.6107</td><td>5002.279</td><td>55.24005</td><td>3.356556</td><td>1.29684</td><td>-6.310816</td><td>0.9741227</td></tr>
      <tr><th>4</th><td>2099.155</td><td>25.49303</td><td>50.87001</td><td>54.12593</td><td>301.6103</td><td>5004</td><td>55.26249</td><td>2.107098</td><td>4.146667</td><td>-2.35292</td><td>1.4</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 66-68

Extract the first column of `inputSample` into the sample of the flowrates
:math:`Q`.

.. GENERATED FROM PYTHON SOURCE LINES 70-72

.. code-block:: Python

    sampleQ = inputSample[:, 0]








.. GENERATED FROM PYTHON SOURCE LINES 73-76

The next cell defines a function that computes the conditional sample of
a component given that the a marginal (defined by its index `criteriaComponent`)
exceeds a given threshold, defined by its quantile level.

.. GENERATED FROM PYTHON SOURCE LINES 76-98

.. code-block:: Python



    def computeConditionnedSample(
        sample, alpha=0.9, criteriaComponent=None, selectedComponent=0
    ):
        """
        Return values from the selectedComponent-th component of the sample.
        Selects the values according to the alpha-level quantile of
        the criteriaComponent-th component of the sample.
        """
        dim = sample.getDimension()
        if criteriaComponent is None:
            criteriaComponent = dim - 1
        sortedSample = sample.sortAccordingToAComponent(criteriaComponent)
        quantiles = sortedSample.computeQuantilePerComponent(alpha)
        quantileValue = quantiles[criteriaComponent]
        sortedSampleCriteria = sortedSample[:, criteriaComponent]
        indices = np.where(np.array(sortedSampleCriteria.asPoint()) > quantileValue)[0]
        conditionnedSortedSample = sortedSample[int(indices[0]) :, selectedComponent]
        return conditionnedSortedSample









.. GENERATED FROM PYTHON SOURCE LINES 99-100

Create an histogram for the unconditional flowrates.

.. GENERATED FROM PYTHON SOURCE LINES 102-105

.. code-block:: Python

    numberOfBins = 10
    histogram = ot.HistogramFactory().buildAsHistogram(sampleQ, numberOfBins)








.. GENERATED FROM PYTHON SOURCE LINES 106-107

Extract the sub-sample of the input flowrates `Q` which leads to large values of the output `S`.

.. GENERATED FROM PYTHON SOURCE LINES 109-110

Search the index of the marginal `S` in the columns of the sample.

.. GENERATED FROM PYTHON SOURCE LINES 110-113

.. code-block:: Python

    criteriaComponent = list(sample.getDescription()).index("S")
    criteriaComponent





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    9



.. GENERATED FROM PYTHON SOURCE LINES 114-120

.. code-block:: Python

    alpha = 0.9
    selectedComponent = 0
    conditionnedSampleQ = computeConditionnedSample(
        sample, alpha, criteriaComponent, selectedComponent
    )








.. GENERATED FROM PYTHON SOURCE LINES 121-131

We could as well use:

.. code-block::

    # conditionnedHistogram = ot.HistogramFactory().buildAsHistogram(conditionnedSampleQ)

but this creates an histogram with new classes, corresponding
to `conditionnedSampleQ`.
We want to use exactly the same classes as the full sample,
so that the two histograms match.

.. GENERATED FROM PYTHON SOURCE LINES 133-139

.. code-block:: Python

    first = histogram.getFirst()
    width = histogram.getWidth()
    conditionnedHistogram = ot.HistogramFactory().buildAsHistogram(
        conditionnedSampleQ, first, width
    )








.. GENERATED FROM PYTHON SOURCE LINES 140-141

Then creates a graphics with the unconditional and the conditional histograms.

.. GENERATED FROM PYTHON SOURCE LINES 143-153

.. code-block:: Python

    graph = histogram.drawPDF()
    graph.setLegends(["Q"])
    #
    graphConditionnalQ = conditionnedHistogram.drawPDF()
    graphConditionnalQ.setColors(["blue"])
    graphConditionnalQ.setLegends([r"$Q | S > S_{%s}$" % (alpha)])
    graph.add(graphConditionnalQ)
    view = viewer.View(graph)

    plt.show()



.. image-sg:: /auto_data_analysis/sample_analysis/images/sphx_glr_plot_compare_unconditional_conditional_histograms_001.png
   :alt: Q (m3/s) PDF
   :srcset: /auto_data_analysis/sample_analysis/images/sphx_glr_plot_compare_unconditional_conditional_histograms_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 154-162

We see that the two histograms are very different.
The high values of the input :math:`Q` seem to often lead to a high value of the output :math:`S`.

We could explore this situation further by comparing the unconditional
distribution of :math:`Q` (which is known in this case) with the conditonal
distribution of :math:`Q | S > t`, estimated by kernel smoothing.
This would have the advantage of accuracy, since the kernel smoothing is a
more accurate approximation of a distribution than the histogram.


.. _sphx_glr_download_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_compare_unconditional_conditional_histograms.ipynb <plot_compare_unconditional_conditional_histograms.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_compare_unconditional_conditional_histograms.py <plot_compare_unconditional_conditional_histograms.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_compare_unconditional_conditional_histograms.zip <plot_compare_unconditional_conditional_histograms.zip>`
