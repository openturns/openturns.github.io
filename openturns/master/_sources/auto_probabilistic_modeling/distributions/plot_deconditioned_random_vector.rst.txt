
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_probabilistic_modeling/distributions/plot_deconditioned_random_vector.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_probabilistic_modeling_distributions_plot_deconditioned_random_vector.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_probabilistic_modeling_distributions_plot_deconditioned_random_vector.py:


Create a deconditioned random vector
====================================

.. GENERATED FROM PYTHON SOURCE LINES 7-33

In this example we are going to build the random vector :math:`\inputRV` defined as the
deconditioned distribution of:

.. math::

   \inputRV|\vect{\Theta}

with respect to parameter random vector :math:`\vect{\Theta}` following the distribution :math:`\cL_{\vect{\Theta}}`.

This example creates a :class:`~openturns.DeconditionedRandomVector`. Remember that a :class:`~openturns.DeconditionedRandomVector`
(and more generally a :class:`~openturns.RandomVector`) can only be sampled.

There is no restriction on the random vector :math:`\vect{\Theta}`. It can be created from any multivariate distribution or
as the output of a function :math:`f` applied to an input random vector :math:`\vect{Y}`: :math:`\vect{\Theta} = f(\vect{Y})`.

Note that in some restricted cases, it is possible to create the
distribution of :math:`\inputRV` using the class :class:`~openturns.DeconditionedDistribution`.
The :class:`~openturns.DeconditionedDistribution` offers a lot of methods attached to the distribution, in particular the
computation of the PDF, CDF, the moments if any, :math:`\dots`. The advantage of the :class:`~openturns.DeconditionedRandomVector` relies
on the fact that it is fast to build and can be built in all cases. But it only offers the sampling capacity.

We consider the following cases:

- Case 1: the parameter random vector has continuous marginals,
- Case 2: the parameter random vector has dependent continuous and discrete marginals,
- Case 3: the parameter random vector has any dependent marginals.

.. GENERATED FROM PYTHON SOURCE LINES 35-38

.. code-block:: Python

    import openturns as ot
    import openturns.viewer as otv








.. GENERATED FROM PYTHON SOURCE LINES 39-54

Case 1: the parameter random vector  has continuous marginals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We consider the case where :math:`X` is of dimension 1 and follows an exponential distribution
defined by:

================================ =========================================================  ====================================
Variable                         Distribution                                               Parameter
================================ =========================================================  ====================================
:math:`X`                        :class:`~openturns.Exponential` (:math:`\Lambda, \Gamma`)  (:math:`\Lambda, \Gamma`) are random
:math:`\Lambda`                  :class:`~openturns.Uniform` (:math:`a, b`)                 :math:`(a,b) = (0, 1)`
:math:`\Gamma`                   :class:`~openturns.Uniform` (:math:`a, b`)                 :math:`(a,b) = (1, 2)`
Copula (:math:`\Lambda, \Gamma`) :class:`~openturns.ClaytonCopula` (:math:`\theta`)         :math:`\theta = 2`
================================ =========================================================  ====================================


.. GENERATED FROM PYTHON SOURCE LINES 56-57

Create the parameter random vector :math:`\vect{\Theta} = (\Lambda, \Gamma)`:

.. GENERATED FROM PYTHON SOURCE LINES 57-62

.. code-block:: Python

    lambdaDist = ot.Uniform(0.0, 1.0)
    gammaDist = ot.Uniform(1.0, 2.0)
    thetaDist = ot.JointDistribution([lambdaDist, gammaDist], ot.ClaytonCopula(2))
    thetaRV = ot.RandomVector(thetaDist)








.. GENERATED FROM PYTHON SOURCE LINES 63-65

Create the :math:`\inputRV|\vect{\Theta}` distribution: as the parameters have no importance, we
create the default distribution.

.. GENERATED FROM PYTHON SOURCE LINES 65-67

.. code-block:: Python

    XgivenThetaDist = ot.Exponential()








.. GENERATED FROM PYTHON SOURCE LINES 68-69

Create the :math:`\inputRV` random vector.

.. GENERATED FROM PYTHON SOURCE LINES 69-71

.. code-block:: Python

    X_RV = ot.DeconditionedRandomVector(XgivenThetaDist, thetaRV)








.. GENERATED FROM PYTHON SOURCE LINES 72-73

Draw a sample

.. GENERATED FROM PYTHON SOURCE LINES 73-75

.. code-block:: Python

    X_RV.getSample(5)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>X0</th></tr>
      <tr><th>0</th><td>5.081867</td></tr>
      <tr><th>1</th><td>1.987522</td></tr>
      <tr><th>2</th><td>4.769532</td></tr>
      <tr><th>3</th><td>4.779249</td></tr>
      <tr><th>4</th><td>1.950028</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 76-78

If we generate a large sample of the random vector, we can fit its distribution with non-parametric techniques
such as a kernel smoothing.

.. GENERATED FROM PYTHON SOURCE LINES 78-86

.. code-block:: Python

    sample_large = X_RV.getSample(10000)
    dist_KS = ot.KernelSmoothing().build(sample_large)
    g_PDF = dist_KS.drawPDF()
    g_PDF.setTitle("Case 1: PDF of X by kernel smoothing")
    g_PDF.setXTitle("x")
    g_PDF.setLegendPosition("")
    view = otv.View(g_PDF)




.. image-sg:: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_001.png
   :alt: Case 1: PDF of X by kernel smoothing
   :srcset: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 87-102

Case 2: the parameter random vector has dependent continuous and discrete marginals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We consider the case where :math:`X` is of dimension 1 and follows an exponential distribution
defined by:

=================================  =========================================================  ====================================
Variable                           Distribution                                               Parameter
=================================  =========================================================  ====================================
:math:`X`                          :class:`~openturns.Exponential` (:math:`\Lambda, \Gamma`)  (:math:`\Lambda, \Gamma`) are random
:math:`\Lambda`                    1 + :class:`~openturns.Poisson` (:math:`\ell`)             :math:`\ell = 1`
:math:`\Gamma`                     :class:`~openturns.Uniform` (:math:`a, b`)                 :math:`(a,b) = (1, 2)`
Copula  (:math:`\Lambda, \Gamma`)  :class:`~openturns.ClaytonCopula` (:math:`\theta`)         :math:`\theta = 2`
=================================  =========================================================  ====================================


.. GENERATED FROM PYTHON SOURCE LINES 104-106

Create the parameter random vector :math:`\vect{\Theta} = (\Lambda, \Gamma)`. We shift the Poisson distribution to
get positive values for :math:`\Lambda`.

.. GENERATED FROM PYTHON SOURCE LINES 106-111

.. code-block:: Python

    lambdaDist = 1 + ot.Poisson(1)
    gammaDist = ot.Uniform(1.0, 2.0)
    thetaDist = ot.JointDistribution([lambdaDist, gammaDist], ot.ClaytonCopula(2))
    thetaRV = ot.RandomVector(thetaDist)








.. GENERATED FROM PYTHON SOURCE LINES 112-113

Create the :math:`\inputRV|\vect{\Theta}` random vector.

.. GENERATED FROM PYTHON SOURCE LINES 113-116

.. code-block:: Python

    XgivenThetaDist = ot.Exponential()
    X_RV = ot.DeconditionedRandomVector(XgivenThetaDist, thetaRV)








.. GENERATED FROM PYTHON SOURCE LINES 117-119

If we generate a large sample of the random vector, we can fit its distribution with non-parametric techniques
such as a kernel smoothing.

.. GENERATED FROM PYTHON SOURCE LINES 119-127

.. code-block:: Python

    sample_large = X_RV.getSample(10000)
    dist_KS = ot.KernelSmoothing().build(sample_large)
    g_PDF = dist_KS.drawPDF()
    g_PDF.setTitle("Case 2: PDF of X by kernel smoothing")
    g_PDF.setXTitle("x")
    g_PDF.setLegendPosition("")
    view = otv.View(g_PDF)




.. image-sg:: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_002.png
   :alt: Case 2: PDF of X by kernel smoothing
   :srcset: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 128-146

Case 3: the parameter random vector has any dependent marginals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We consider the case where :math:`X` is of dimension 1 and follows an exponential distribution
defined by:

=================================  =========================================================  ====================================
Variable         Distribution                                               Parameter
=================================  =========================================================  ====================================
:math:`X`                          :class:`~openturns.Exponential` (:math:`\Lambda, \Gamma`)  (:math:`\Lambda, \Gamma`) are random
:math:`\Lambda`                    :class:`~openturns.Mixture`                                see below
:math:`\Gamma`                     :class:`~openturns.Uniform` (:math:`a, b`)                 :math:`(a,b) = (1, 2)`
Copula  (:math:`\Lambda, \Gamma`)  :class:`~openturns.ClaytonCopula` (:math:`\theta`)         :math:`\theta = 2`
=================================  =========================================================  ====================================

where the mixture is built from the :class:`~openturns.Exponential` (:math:`\ell`) with :math:`\ell = 1` and the
:class:`~openturns.Geometric` (:math:`p`) with :math:`p = 0.1`, with equal weights. In this case, the distribution of :math:`\Lambda` is
not discrete nor continuous.

.. GENERATED FROM PYTHON SOURCE LINES 148-149

Create the parameter random vector :math:`\vect{\Theta} = (\Lambda, \Gamma)`:

.. GENERATED FROM PYTHON SOURCE LINES 149-154

.. code-block:: Python

    lambdaDist = ot.Mixture([ot.Exponential(1.0), ot.Geometric(0.1)])
    gammaDist = ot.Uniform(1.0, 2.0)
    thetaDist = ot.JointDistribution([lambdaDist, gammaDist], ot.ClaytonCopula(2))
    thetaRV = ot.RandomVector(thetaDist)








.. GENERATED FROM PYTHON SOURCE LINES 155-156

Create the :math:`\inputRV|\vect{\Theta}` random vector.

.. GENERATED FROM PYTHON SOURCE LINES 156-159

.. code-block:: Python

    XgivenThetaDist = ot.Exponential()
    X_RV = ot.DeconditionedRandomVector(XgivenThetaDist, thetaRV)








.. GENERATED FROM PYTHON SOURCE LINES 160-162

If we generate a large sample of the random vector, we can fit its distribution with non-parametric techniques
such as a kernel smoothing.

.. GENERATED FROM PYTHON SOURCE LINES 162-170

.. code-block:: Python

    sample_large = X_RV.getSample(10000)
    dist_KS = ot.KernelSmoothing().build(sample_large)
    g_PDF = dist_KS.drawPDF()
    g_PDF.setTitle("Case 3: PDF of X by kernel smoothing")
    g_PDF.setXTitle("x")
    g_PDF.setLegendPosition("")
    view = otv.View(g_PDF)




.. image-sg:: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_003.png
   :alt: Case 3: PDF of X by kernel smoothing
   :srcset: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_deconditioned_random_vector_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 171-172

.. code-block:: Python

    view.ShowAll()








.. _sphx_glr_download_auto_probabilistic_modeling_distributions_plot_deconditioned_random_vector.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_deconditioned_random_vector.ipynb <plot_deconditioned_random_vector.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_deconditioned_random_vector.py <plot_deconditioned_random_vector.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_deconditioned_random_vector.zip <plot_deconditioned_random_vector.zip>`
