
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_surrogate_modeling/gaussian_process_regression/plot_gpr_choose_trend.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_surrogate_modeling_gaussian_process_regression_plot_gpr_choose_trend.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_surrogate_modeling_gaussian_process_regression_plot_gpr_choose_trend.py:


Gaussian Process Regression: choose a polynomial trend
======================================================

.. GENERATED FROM PYTHON SOURCE LINES 5-9

.. code-block:: Python


    import openturns as ot
    import openturns.viewer as otv








.. GENERATED FROM PYTHON SOURCE LINES 10-67

Introduction
------------

In this example, we build a metamodel using a Gaussian process regression whose trend is estimated on a
given data set. We illustrate the impact of the choice of the trend function basis on the metamodel.
This example focuses on three polynomial trends:

- :class:`~openturns.ConstantBasisFactory`;
- :class:`~openturns.LinearBasisFactory`;
- :class:`~openturns.QuadraticBasisFactory`.

At lats, we illustrate that far away from the data set, the Gaussian Process Regression metamodel is entirely
determined by the trend function. Depending on the trend, it might be a bad idea to use the Gaussian process
regression metamodel far away from the training data set.

Refer to :ref:`gaussian_process_regression` to get all the notations and the theoretical aspects.
In the :doc:`/auto_surrogate_modeling/gaussian_process_regression/plot_gpr_beam_trend` example,
we give another example of this method.
In the :doc:`/auto_surrogate_modeling/gaussian_process_regression/plot_gpr_beam_arbitrary_trend` example,
we show how to configure an arbitrary trend.

The model is the function :math:`g: \Rset \rightarrow \Rset` defined by:

.. math::
   \model(x) = x \sin \left( \frac{x}{2} \right), \quad \forall x \in [0,10].

We consider the :class:`~openturns.MaternModel` covariance model.
The covariance model is fixed but its parameters must be calibrated
depending on the data.
The Gaussian process regression metamodel is defined by:

.. math::

   \metaModel(\vect{x})  \Expect{Y(\omega, x)\, | \,  \cC}

where:

.. math::

   Y(\omega, x) = \mu(x) + W(\omega, x)

where :math:`\mu: \Rset \rightarrow \Rset` is the trend function and
:math:`\vect{W}` a Gaussian process of dimension 1 with zero mean and covariance function :math:`\mat{C}`.
We consider the :class:`~openturns.MaternModel` covariance model.

The trend is deterministic and the Gaussian process is probabilistic but they both contribute to the metamodel.
A special feature of the Gaussian process regression metamodel :math:`\metaModel` is the interpolation
property: the metamodel is exact at the training data set.

The objective is to estimate the trend function :math:`\mu` and the parameters of the covariance model,
labelled as *active*: by default, the active parameters are the scale and the amplitude :math:`\vect{\theta} = (\theta, \sigma)` but refer to
:class:`openturns.CovarianceModel` to get details on the activation of the estimation of the other parameters.

Define the model
----------------

We define the model :math:`\model` with a :class:`~openturns.SymbolicFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 67-69

.. code-block:: Python

    model = ot.SymbolicFunction(["x"], ["x * sin(0.5 * x)"])








.. GENERATED FROM PYTHON SOURCE LINES 70-71

We use the following sample to train our metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 71-77

.. code-block:: Python

    xmin = 0.0
    xmax = 10.0
    nTrain = 8
    Xtrain = ot.Uniform(xmin, xmax).getSample(nTrain).sort()
    Xtrain






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>v0</th></tr>
      <tr><th>0</th><td>0.3250275</td></tr>
      <tr><th>1</th><td>1.352764</td></tr>
      <tr><th>2</th><td>3.47057</td></tr>
      <tr><th>3</th><td>5.030402</td></tr>
      <tr><th>4</th><td>6.298766</td></tr>
      <tr><th>5</th><td>8.828052</td></tr>
      <tr><th>6</th><td>9.206796</td></tr>
      <tr><th>7</th><td>9.69423</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 78-79

The values of the model are also needed for training.

.. GENERATED FROM PYTHON SOURCE LINES 79-82

.. code-block:: Python

    Ytrain = model(Xtrain)
    Ytrain






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>y0</th></tr>
      <tr><th>0</th><td>0.05258924</td></tr>
      <tr><th>1</th><td>0.8467968</td></tr>
      <tr><th>2</th><td>3.423725</td></tr>
      <tr><th>3</th><td>2.94895</td></tr>
      <tr><th>4</th><td>-0.0490677</td></tr>
      <tr><th>5</th><td>-8.43802</td></tr>
      <tr><th>6</th><td>-9.152166</td></tr>
      <tr><th>7</th><td>-9.606383</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 83-84

We shall test the model on a set of points based on a regular grid.

.. GENERATED FROM PYTHON SOURCE LINES 84-88

.. code-block:: Python

    nTest = 100
    step = (xmax - xmin) / (nTest - 1)
    x_test = ot.RegularGrid(xmin, step, nTest).getVertices()








.. GENERATED FROM PYTHON SOURCE LINES 89-91

We draw the training points and the model at the testing points. We encapsulate it into a function to use it
again later.

.. GENERATED FROM PYTHON SOURCE LINES 91-110

.. code-block:: Python



    def plot_model(color):
        graph = ot.Graph("", "x", "", True, "")
        y_test = model(x_test)
        curveModel = ot.Curve(x_test, y_test)
        curveModel.setLineStyle("solid")
        curveModel.setColor(color)
        curveModel.setLegend("Model")
        graph.add(curveModel)
        cloud = ot.Cloud(Xtrain, Ytrain)
        cloud.setColor(color)
        cloud.setPointStyle("fsquare")
        cloud.setLegend("Data")
        graph.add(cloud)
        graph.setLegendPosition("bottom")
        return graph









.. GENERATED FROM PYTHON SOURCE LINES 111-116

.. code-block:: Python

    palette = ot.Drawable.BuildDefaultPalette(5)
    graph = plot_model(palette[0])
    graph.setTitle("Model and data set")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_001.svg
   :alt: Model and data set
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_001.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 117-128

Scale the input training sample
-------------------------------

We often have to apply a transform on the input data before performing the Gaussian process regression.
This makes the estimation of the hyperparameters of the Gaussian process regression metamodel
easier for the optimization algorithm.
To do so, we write a linear transform of our input data: we make it unit centered at its mean.
Then we fix the mean and the standard deviation to their values with the :class:`~openturns.ParametricFunction`.
We build the inverse transform as well.

We first compute the mean and standard deviation of the input data.

.. GENERATED FROM PYTHON SOURCE LINES 128-133

.. code-block:: Python

    mean = Xtrain.computeMean()[0]
    stdDev = Xtrain.computeStandardDeviation()[0]
    print("Xtrain, mean: %.3f" % mean)
    print("Xtrain, standard deviation: %.3f" % stdDev)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Xtrain, mean: 5.526
    Xtrain, standard deviation: 3.613




.. GENERATED FROM PYTHON SOURCE LINES 134-139

.. code-block:: Python

    trans_func = ot.SymbolicFunction(["mean", "sigma", "x"], ["(x - mean) / sigma"])
    inv_trans_func = ot.SymbolicFunction(["mean", "sigma", "x"], ["sigma * x + mean"])
    myTransform = ot.ParametricFunction(trans_func, [0, 1], [mean, stdDev])
    myInverseTransform = ot.ParametricFunction(inv_trans_func, [0, 1], [mean, stdDev])








.. GENERATED FROM PYTHON SOURCE LINES 140-141

Scale the input training sample.

.. GENERATED FROM PYTHON SOURCE LINES 141-145

.. code-block:: Python

    scaledXtrain = myTransform(Xtrain)
    scaledXtrain







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>y0</th></tr>
      <tr><th>0</th><td>-1.439601</td></tr>
      <tr><th>1</th><td>-1.15512</td></tr>
      <tr><th>2</th><td>-0.5689025</td></tr>
      <tr><th>3</th><td>-0.1371353</td></tr>
      <tr><th>4</th><td>0.2139527</td></tr>
      <tr><th>5</th><td>0.9140688</td></tr>
      <tr><th>6</th><td>1.018907</td></tr>
      <tr><th>7</th><td>1.15383</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 146-151

Constant basis
--------------

In this paragraph we choose a basis constant for the estimation of the trend.
The basis is built with the :class:`~openturns.ConstantBasisFactory` class.

.. GENERATED FROM PYTHON SOURCE LINES 151-154

.. code-block:: Python

    dimension = 1
    basis = ot.ConstantBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 155-163

We build the Gaussian process regression algorithm on the transformed data, the output data, the covariance
model and the basis.
First, we define the :class:`~openturns.MaternModel` covariance model. The two first parameters
(scale and amplitude) will be updated
but not the third one (which is the :math:`\nu` parameter).

First, we build the :math:`Y(\omega, x)` Gaussian process with the class
:class:`~openturns.GaussianProcessFitter`.

.. GENERATED FROM PYTHON SOURCE LINES 163-168

.. code-block:: Python

    covarianceModel = ot.MaternModel([1.0], [1.0], 2.5)
    algo_fit = ot.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 169-171

Then, we condition the process :math:`Y(\omega, x)` to the data set with the class
:class:`~openturns.GaussianProcessRegression`.

.. GENERATED FROM PYTHON SOURCE LINES 171-174

.. code-block:: Python

    algo_gpr = ot.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 175-176

We can get the metamodel on the transformed data:

.. GENERATED FROM PYTHON SOURCE LINES 176-179

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()








.. GENERATED FROM PYTHON SOURCE LINES 180-182

The final metamodel on the initial input data is built with the class
:class:`~openturns.ComposedFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 182-184

.. code-block:: Python

    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 185-186

Define a function to plot the metamodel:

.. GENERATED FROM PYTHON SOURCE LINES 186-197

.. code-block:: Python



    def plot_metamodel(x_test, metamodel, color):
        y_test = metamodel(x_test)
        curve = ot.Curve(x_test, y_test)
        curve.setLineStyle("dashed")
        curve.setColor(color)
        curve.setLegend("Metamodel")
        return curve









.. GENERATED FROM PYTHON SOURCE LINES 198-199

We can draw the metamodel and the model on the same graph.

.. GENERATED FROM PYTHON SOURCE LINES 199-204

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.setTitle("Gaussian Process Regression metamodel: constant trend")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_002.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_002.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 205-208

We also observe the estimated values of the hyperparameters of the trained covariance model.
Note that the scale parameter is related to the transformed data. To get the scale parameter related to
the initial variables, you have to multiply it by the *stdDev* factor.

.. GENERATED FROM PYTHON SOURCE LINES 208-215

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 1.368e+00
    Amplitude parameter: 6.077e+00




.. GENERATED FROM PYTHON SOURCE LINES 216-220

We can display the trend function computed on the transformed data:
:math:`\mu \left(\dfrac{x-m}{\sigma}\right)` where :math:(m, \sigma)` is the mean and standard
deviation of the input data set. We use the method
:meth:`~openturns.GaussianProcessFitterResult.getTrendCoefficients`.

.. GENERATED FROM PYTHON SOURCE LINES 220-223

.. code-block:: Python

    c0 = fit_result.getTrendCoefficients()
    print("The trend is the curve mu((x-m)/sigma) = %.6e" % c0[0])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The trend is the curve mu((x-m)/sigma) = -2.726224e+00




.. GENERATED FROM PYTHON SOURCE LINES 224-227

We can also get the trend function acting on the transformed data using the method
:meth:`~openturns.GaussianProcessFitterResult.getMetaModel` of the
class :class:`~openturns.GaussianProcessFitterResult`.

.. GENERATED FROM PYTHON SOURCE LINES 227-230

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend_transformed_data






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <ul>
      <li> Input dimension = 1  </li>
      <li> Input description = [x0]  </li>
      <li> Output dimension = 1  </li>
      <li> Output description = [y0]  </li>
      <li> Parameter = []  </li>
    </ul>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 231-233

The trend function acting on the initial input data is built with the class
:class:`~openturns.ComposedFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 233-235

.. code-block:: Python

    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 236-237

Define a function to plot the trend.

.. GENERATED FROM PYTHON SOURCE LINES 237-248

.. code-block:: Python



    def plot_trend(x_test, trend_func, color):
        y_test = trend_func(x_test)
        curve = ot.Curve(x_test, y_test)
        curve.setLineStyle("dotdash")
        curve.setColor(color)
        curve.setLegend("Trend")
        return curve









.. GENERATED FROM PYTHON SOURCE LINES 249-250

We draw the estimated trend function.

.. GENERATED FROM PYTHON SOURCE LINES 250-254

.. code-block:: Python

    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: constant trend")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_003.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_003.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 255-258

Now, we want to plot some confidence bounds of the metamodel. We use the class
:class:`~openturns.GaussianProcessConditionalCovariance` which is built from the Gaussian
Process Regression result. We create a function to plot confidence bounds.

.. GENERATED FROM PYTHON SOURCE LINES 258-283

.. code-block:: Python



    def plot_GPRConfidenceBounds(gpr_result, x_test, myTransform, color, alpha=0.05):
        bilateralCI = ot.Normal().computeBilateralConfidenceInterval(1.0 - alpha)
        quantileAlpha = bilateralCI.getUpperBound()[0]
        sqrt = ot.SymbolicFunction(["x"], ["sqrt(x)"])
        n_test = x_test.getSize()
        scaled_x_test = myTransform(x_test)
        gpr_condCov = ot.GaussianProcessConditionalCovariance(gpr_result)
        conditionalVariance = gpr_condCov.getConditionalMarginalVariance(scaled_x_test)
        conditionalSigma = sqrt(conditionalVariance)
        metamodel_transf_data = gpr_result.getMetaModel()
        y_test = metamodel_transf_data(scaled_x_test)
        dataLower = [
            y_test[i, 0] - quantileAlpha * conditionalSigma[i, 0] for i in range(n_test)
        ]
        dataUpper = [
            y_test[i, 0] + quantileAlpha * conditionalSigma[i, 0] for i in range(n_test)
        ]
        boundsPoly = ot.Polygon.FillBetween(x_test.asPoint(), dataLower, dataUpper)
        boundsPoly.setColor(ot.Drawable.ConvertFromHSV(color[0], color[1], color[2]))
        boundsPoly.setLegend("%d%% C.I." % ((1.0 - alpha) * 100))
        return boundsPoly









.. GENERATED FROM PYTHON SOURCE LINES 284-285

We plot the bounds of three different confidence intervals of level :math:`1-\alpha`:

.. GENERATED FROM PYTHON SOURCE LINES 285-314

.. code-block:: Python

    alphas = [0.05, 0.1, 0.2]
    # three different green colors defined by HSV values:
    bounds_colors = [[120, 1.0, 1.0], [120, 1.0, 0.75], [120, 1.0, 0.5]]

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: constant trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_004.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_004.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 315-321

Linear basis
------------

With a linear basis, the vector space is defined by the basis :math:`\{1, z\}`: that is
all the function of type :math:`y(z) = az + b` where :math:`a` and :math:`b` are
real parameters.

.. GENERATED FROM PYTHON SOURCE LINES 321-323

.. code-block:: Python

    basis = ot.LinearBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 324-325

We build the :math:`Y(\omega, x)` Gaussian process, then we condition it to the data set.

.. GENERATED FROM PYTHON SOURCE LINES 325-332

.. code-block:: Python

    algo_fit = ot.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()

    algo_gpr = ot.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 333-334

We  get the metamodel on the transformed data and we build the final metamodel acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 334-338

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()
    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 339-340

We get the updated covariance model.

.. GENERATED FROM PYTHON SOURCE LINES 340-346

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 1.100e+00
    Amplitude parameter: 4.627e+00




.. GENERATED FROM PYTHON SOURCE LINES 347-348

We get the trend function acting on the transformed data and we build the trend function acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 348-351

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 352-353

We draw the model, the trained data set, the estimated trend function and the Gaussian Process Regression metamodel

.. GENERATED FROM PYTHON SOURCE LINES 353-359

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: linear basis")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_005.svg
   :alt: Gaussian Process Regression metamodel: linear basis
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_005.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 360-362

We plot some confidence bounds of the metamodel.
sphinx_gallery_thumbnail_number = 6

.. GENERATED FROM PYTHON SOURCE LINES 362-385

.. code-block:: Python

    graph = ot.Graph("Gaussian Process Regression metamodel: linear trend", "x", "y", True)
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_006.svg
   :alt: Gaussian Process Regression metamodel: linear trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_006.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 386-390

Quadratic basis
---------------

In this last section, we turn to the quadratic basis. All subsequent analysis should remain the same.

.. GENERATED FROM PYTHON SOURCE LINES 390-392

.. code-block:: Python

    basis = ot.QuadraticBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 393-394

We build the :math:`Y(\omega, x)` Gaussian process, then we condition it to the data set.

.. GENERATED FROM PYTHON SOURCE LINES 394-401

.. code-block:: Python

    algo_fit = ot.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()

    algo_gpr = ot.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 402-403

We  get the metamodel on the transformed data and we build the final metamodel acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 403-407

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()
    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 408-409

We get the updated covariance model.

.. GENERATED FROM PYTHON SOURCE LINES 409-415

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 2.593e-03
    Amplitude parameter: 1.000e+00




.. GENERATED FROM PYTHON SOURCE LINES 416-417

We get the trend function acting on the transformed data and we build the trend acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 417-420

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 421-423

We draw the model, the trained data set, the estimated trend function and the Gaussian Process Regression
metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 423-429

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: quadratic basis")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_007.svg
   :alt: Gaussian Process Regression metamodel: quadratic basis
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_007.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 430-431

We plot some confidence bounds of the metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 431-456

.. code-block:: Python

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: quadratic trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_008.svg
   :alt: Gaussian Process Regression metamodel: quadratic trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_008.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 457-463

And far away from the training data set?
----------------------------------------

We illustrate here that far away from the data set, the Gaussian Process Regression metamodel is entirely
determined by the trend function.
To do that, we define another input test sample.

.. GENERATED FROM PYTHON SOURCE LINES 463-494

.. code-block:: Python

    xmin = -10.0
    xmax = 20.0
    nTest = 500
    step = (xmax - xmin) / (nTest - 1)
    x_test = ot.RegularGrid(xmin, step, nTest).getVertices()

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: quadratic trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_009.svg
   :alt: Gaussian Process Regression metamodel: quadratic trend
   :srcset: /auto_surrogate_modeling/gaussian_process_regression/images/sphx_glr_plot_gpr_choose_trend_009.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 495-498

We observe that far away from the training data set, the Gaussian Process Regression metamodel is equal to the
trend function which is not a good approximation of the model. In that case, it is not a good idea to use the
Gaussian Process Regression metamodel far away from the training data set.

.. GENERATED FROM PYTHON SOURCE LINES 500-501

Display figures

.. GENERATED FROM PYTHON SOURCE LINES 501-502

.. code-block:: Python

    otv.View.ShowAll()








.. _sphx_glr_download_auto_surrogate_modeling_gaussian_process_regression_plot_gpr_choose_trend.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_gpr_choose_trend.ipynb <plot_gpr_choose_trend.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_gpr_choose_trend.py <plot_gpr_choose_trend.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_gpr_choose_trend.zip <plot_gpr_choose_trend.zip>`
