
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_withoutobservedinputs.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_withoutobservedinputs.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_withoutobservedinputs.py:


Calibration without observed inputs
===================================

.. GENERATED FROM PYTHON SOURCE LINES 8-15

The goal of this example is to present the calibration of a parametric model which 
does not have observed inputs.
We are going to see how to use the :class:`~openturns.Sample` class 
and create an empty sample. 
Indeed, this is mandatory in order to fit within the calibration 
framework that is used in the library. 
In this example there are, however, several outputs to be calibrated.

.. GENERATED FROM PYTHON SOURCE LINES 15-20

.. code-block:: default


    import openturns as ot
    from matplotlib import pylab as plt
    import openturns.viewer as viewer








.. GENERATED FROM PYTHON SOURCE LINES 21-35

The vector of parameters is 
:math:`\boldsymbol{\theta} = (a, b, c)^T \in \mathbb{R}^3`. 
This model is linear in :math:`\boldsymbol{\theta}` and identifiable.
It is derived from the equation:

.. math::
    y(x) = a + b x + c x^2

at :math:`x=-1.0, -0.6, -0.2, 0.2, 0.6, 1.0`. 
In the model, however, the abscissas are fixed and constant. 
Therefore, the parametric model has 3 parameters, no input and 6 outputs 
:math:`y_1, ..., y_6`.
This produces a set of 5 observations for each output, leading to a total 
of 5 (observations per output) * 6 (outputs) = 30 observations.

.. GENERATED FROM PYTHON SOURCE LINES 35-49

.. code-block:: default

    g = ot.SymbolicFunction(
        ["a", "b", "c"],
        [
            "a +  -1.0  * b +  1.0  * c",
            "a +  -0.6  * b +  0.36  * c",
            "a +  -0.2  * b +  0.04  * c",
            "a +  0.2  * b +  0.04  * c",
            "a +  0.6  * b +  0.36  * c",
            "a +  1.0  * b +  1.0  * c",
        ],
    )
    outputDimension = g.getOutputDimension()
    print(outputDimension)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    6




.. GENERATED FROM PYTHON SOURCE LINES 50-51

We set the true value of the parameters.

.. GENERATED FROM PYTHON SOURCE LINES 51-54

.. code-block:: default

    trueParameter = ot.Point([12.0, 7.0, -8.0])
    print(trueParameter)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [12,7,-8]




.. GENERATED FROM PYTHON SOURCE LINES 55-57

In order to generate the observed outputs, we create a distribution 
in dimension 3, with Dirac (i.e. constant) marginals.

.. GENERATED FROM PYTHON SOURCE LINES 57-59

.. code-block:: default

    inputRandomVector = ot.ComposedDistribution([ot.Dirac(theta) for theta in trueParameter])








.. GENERATED FROM PYTHON SOURCE LINES 60-61

The candidate value is chosen to be different from the true parameter value. 

.. GENERATED FROM PYTHON SOURCE LINES 61-65

.. code-block:: default

    candidate = ot.Point([8.0, 9.0, -6.0])
    calibratedIndices = [0, 1, 2]
    model = ot.ParametricFunction(g, calibratedIndices, candidate)








.. GENERATED FROM PYTHON SOURCE LINES 66-69

We consider a multivariate gaussian noise with zero mean, standard deviation 
equal to 0.05 and independent copula.
The independent copula implies that the errors of the 6 outputs are independent.

.. GENERATED FROM PYTHON SOURCE LINES 69-76

.. code-block:: default

    outputObservationNoiseSigma = 1.0
    meanNoise = ot.Point(outputDimension)
    covarianceNoise = [outputObservationNoiseSigma] * outputDimension
    R = ot.IdentityMatrix(outputDimension)
    observationOutputNoise = ot.Normal(meanNoise, covarianceNoise, R)
    print(observationOutputNoise)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Normal(mu = [0,0,0,0,0,0], sigma = [1,1,1,1,1,1], R = 6x6
    [[ 1 0 0 0 0 0 ]
     [ 0 1 0 0 0 0 ]
     [ 0 0 1 0 0 0 ]
     [ 0 0 0 1 0 0 ]
     [ 0 0 0 0 1 0 ]
     [ 0 0 0 0 0 1 ]])




.. GENERATED FROM PYTHON SOURCE LINES 77-80

Finally, we generate the outputs by evaluating the exact outputs of the 
function and adding the noise.
We use a sample with size equal to 5.

.. GENERATED FROM PYTHON SOURCE LINES 80-88

.. code-block:: default

    size = 5
    # Generate exact outputs
    inputSample = inputRandomVector.getSample(size)
    outputStress = g(inputSample)
    # Add noise
    sampleNoise = observationOutputNoise.getSample(size)
    outputObservations = outputStress + sampleNoise








.. GENERATED FROM PYTHON SOURCE LINES 89-94

Now is the important part of this script : there are no input observations. 
This is why we create a sample with size equal to 5 and dimension equal to 0. 
Even if the calibration model has no input observations, observed inputs 
are required by the current programming interface and this is why we have to 
create this object. 

.. GENERATED FROM PYTHON SOURCE LINES 94-96

.. code-block:: default

    inputObservations = ot.Sample(size, 0)  # Trick








.. GENERATED FROM PYTHON SOURCE LINES 97-98

We are now ready to perform the calibration.

.. GENERATED FROM PYTHON SOURCE LINES 98-107

.. code-block:: default

    algo = ot.LinearLeastSquaresCalibration(
        model, inputObservations, outputObservations, candidate, "SVD"
    )
    algo.run()
    calibrationResult = algo.getResult()
    parameterMAP = calibrationResult.getParameterMAP()
    print(parameterMAP)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [12.1866,6.31929,-8.1176]




.. GENERATED FROM PYTHON SOURCE LINES 108-110

We observe that the estimated parameter is relatively close to 
the true parameter value.

.. GENERATED FROM PYTHON SOURCE LINES 110-113

.. code-block:: default

    print(parameterMAP - trueParameter)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [0.186606,-0.680713,-0.117596]




.. GENERATED FROM PYTHON SOURCE LINES 114-119

Graphical validation
--------------------

We now validate the calculation by drawing the exact function and compare 
it to the function with estimated parameters.

.. GENERATED FROM PYTHON SOURCE LINES 119-128

.. code-block:: default

    fullModel = ot.SymbolicFunction(["a", "b", "c", "x"], ["a + b * x + c * x^2"])
    parameterIndices = [0, 1, 2]
    trueFunction = ot.ParametricFunction(fullModel, parameterIndices, trueParameter)
    print(trueFunction)
    beforeCalibrationFunction = ot.ParametricFunction(fullModel, parameterIndices, candidate)
    print(beforeCalibrationFunction)
    calibratedFunction = ot.ParametricFunction(fullModel, parameterIndices, parameterMAP)
    print(calibratedFunction)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ParametricEvaluation([a,b,c,x]->[a + b * x + c * x^2], parameters positions=[0,1,2], parameters=[a : 12, b : 7, c : -8], input positions=[3])
    ParametricEvaluation([a,b,c,x]->[a + b * x + c * x^2], parameters positions=[0,1,2], parameters=[a : 8, b : 9, c : -6], input positions=[3])
    ParametricEvaluation([a,b,c,x]->[a + b * x + c * x^2], parameters positions=[0,1,2], parameters=[a : 12.1866, b : 6.31929, c : -8.1176], input positions=[3])




.. GENERATED FROM PYTHON SOURCE LINES 129-132

In order to validate the calibration, we compare the parametric function 
with true parameters at given abscissas with the parametric function 
with calibrated parameters. 

.. GENERATED FROM PYTHON SOURCE LINES 132-165

.. code-block:: default

    abscissas = [-1.0, -0.6, -0.2, 0.2, 0.6, 1.0]
    xmin = min(abscissas)
    xmax = max(abscissas)

    npoints = 50
    graph = ot.Graph("Calibration without observations", "x", "y", True, "bottomright")
    curve = trueFunction.draw(xmin, xmax, npoints).getDrawable(0)
    curve.setLineStyle("dashed")
    curve.setLegend("True model")
    curve.setColor("darkorange1")
    graph.add(curve)
    # Before calibration
    curve = beforeCalibrationFunction.draw(xmin, xmax, npoints)
    curve.setLegends(["Model before calibration"])
    curve.setColors(["red"])
    graph.add(curve)
    # After calibration
    curve = calibratedFunction.draw(xmin, xmax, npoints)
    curve.setLegends(["Model after calibration"])
    curve.setColors(["green"])
    graph.add(curve)
    # Observations
    for i in range(outputDimension):
        cloud = ot.Cloud(ot.Sample([[abscissas[i]]] * size), outputObservations[:, i])
        cloud.setColor("blue")
        if i == 0:
            cloud.setLegend("Observations")
        graph.add(cloud)
    viewer = viewer.View(graph)

    plt.show()





.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_withoutobservedinputs_001.png
   :alt: Calibration without observations
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_withoutobservedinputs_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 166-174

We notice that the calibration produces a good fit to the data. 
Still, we notice a small discrepancy between the true mode and the model 
after calibration, but this discrepancy is very small.
Since the model is linear with respect to the parameters :math:`a`, :math:`b`, :math:`c`, 
the LinearLeastSquares method performs well. 
If the model were non linear w.r.t. :math:`a`, :math:`b`, :math:`c`, then the linear least 
squares method would not work that well and the parameters would be estimated 
with less accuracy.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.137 seconds)


.. _sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_withoutobservedinputs.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_calibration_withoutobservedinputs.py <plot_calibration_withoutobservedinputs.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_calibration_withoutobservedinputs.ipynb <plot_calibration_withoutobservedinputs.ipynb>`
