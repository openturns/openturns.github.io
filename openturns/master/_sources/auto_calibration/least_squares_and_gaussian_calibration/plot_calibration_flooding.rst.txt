
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_flooding.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py:


Calibration of the flooding model
=================================

In this example we are interested in the calibration of the :ref:`flooding model <use-case-flood-model>`.
We calibrate the parameters of a flooding model where only the difference between the
downstream and upstream riverbed levels can be calibrated.
This example shows how to manage the lack of identifiability in a calibration problem.

This example use least squares to calibrate the parametric
model.
Please read :ref:`code_calibration` for more details on code calibration and least squares.
This study is relatively complicated: please read the :doc:`calibration of the Chaboche mechanical model
</auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_chaboche>` first if this is not already done.
The observations that we use in this study are simulated with the script
:doc:`Generate flooding model observations
</auto_calibration/least_squares_and_gaussian_calibration/plot_generate_flooding>`.

.. GENERATED FROM PYTHON SOURCE LINES 20-48

Parameters to calibrate and observations
----------------------------------------

The variables of the model are:

- :math:`Q` : Input. Observed.
- :math:`K_s`, :math:`Z_v`, :math:`Z_m` : Input. Calibrated.
- :math:`H`: Output. Observed.

The vector of parameters to calibrate is:

.. math::
   \theta = (K_s,Z_v,Z_m).

In the description of the :ref:`flooding model<use-case-flood-model>`,
we see that only one parameter can be identified.
Hence, calibrating this model requires some regularization.
We return to this topic when analyzing the singular values of
the Jacobian matrix.

We consider a sample size equal to:

.. math::
   n = 10.


The observations are the couples :math:`\{(Q_i,H_i)\}_{i=1,...,n}`, i.e. each observation is a
couple made of the flowrate and the corresponding river height.

.. GENERATED FROM PYTHON SOURCE LINES 48-58

.. code-block:: default


    from openturns.usecases import flood_model
    from matplotlib import pylab as plt
    import openturns.viewer as otv
    import numpy as np
    import openturns as ot

    ot.ResourceMap.SetAsUnsignedInteger("Normal-SmallDimension", 1)
    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 59-67

Define the observations
-----------------------
In practice, we generally use a data set which has been obtained from
measurements.
This data set can be loaded using e.g. :meth:`~openturns.Sample.ImportFromCSVFile`.
Here we import the data from the
:class:`~openturns.usecases.flood_model.FloodModel`
class.

.. GENERATED FROM PYTHON SOURCE LINES 67-74

.. code-block:: default

    fm = flood_model.FloodModel()
    print(fm.data)
    Qobs = fm.data[:, 0]
    Hobs = fm.data[:, 1]
    nbobs = fm.data.getSize()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

        [ Q ($m^3/s$) H (m)       ]
    0 : [  130           0.59     ]
    1 : [  530           1.33     ]
    2 : [  960           2.03     ]
    3 : [ 1400           2.72     ]
    4 : [ 1830           2.83     ]
    5 : [ 2260           3.5      ]
    6 : [ 2700           3.82     ]
    7 : [ 3130           4.36     ]
    8 : [ 3560           4.63     ]
    9 : [ 4010           4.96     ]




.. GENERATED FROM PYTHON SOURCE LINES 75-89

Create the physical model
-------------------------
We define the model :math:`g` which has 4 inputs and one output H.

The nonlinear least squares algorithm does not take into account for bounds
in the parameters.
Therefore, we ensure that the output is computed whatever the inputs.
The model fails into two situations:

* if :math:`K_s<0`,
* if :math:`Z_v-Z_m<0`.

In these cases, we return an infinite number, so that the optimization
algorithm does not get trapped.

.. GENERATED FROM PYTHON SOURCE LINES 89-106

.. code-block:: default

    def functionFlooding(X):
        L = 5.0e3
        B = 300.0
        Q, K_s, Z_v, Z_m = X
        alpha = (Z_m - Z_v) / L
        if alpha < 0.0 or K_s <= 0.0:
            H = np.inf
        else:
            H = (Q / (K_s * B * np.sqrt(alpha))) ** (3.0 / 5.0)
        return [H]


    g = ot.PythonFunction(4, 1, functionFlooding)
    g = ot.MemoizeFunction(g)
    g.setInputDescription(["Q ($m^3/s$)", "Ks ($m^{1/3}/s$)", "Zv (m)", "Zm (m)"])
    g.setOutputDescription(["H (m)"])








.. GENERATED FROM PYTHON SOURCE LINES 107-113

Setting the calibration parameters
----------------------------------
Define the value of the reference values of the :math:`\theta` parameter.
In the Bayesian framework, this is called the mean of the *prior* normal
distribution.
In the data assimilation framework, this is called the *background*.

.. GENERATED FROM PYTHON SOURCE LINES 113-118

.. code-block:: default

    KsInitial = 20.0
    ZvInitial = 49.0
    ZmInitial = 51.0
    thetaPrior = [KsInitial, ZvInitial, ZmInitial]








.. GENERATED FROM PYTHON SOURCE LINES 119-145

Create the parametric function
------------------------------
In the physical model, the inputs and parameters are ordered as
presented in the next table.
Notice that there are no parameters in the physical model.

+-------+----------------+
| Index | Input variable |
+=======+================+
| 0     | Q              |
+-------+----------------+
| 1     | Ks             |
+-------+----------------+
| 2     | Zv             |
+-------+----------------+
| 3     | Zm             |
+-------+----------------+

+-------+-----------+
| Index | Parameter |
+=======+===========+
| ∅     | ∅         |
+-------+-----------+

**Table 1.** Indices and names of the inputs and parameters of the physical model.


.. GENERATED FROM PYTHON SOURCE LINES 145-148

.. code-block:: default

    print("Physical Model Inputs:", g.getInputDescription())
    print("Physical Model Parameters:", g.getParameterDescription())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Physical Model Inputs: [Q ($m^3/s$),Ks ($m^{1/3}/s$),Zv (m),Zm (m)]
    Physical Model Parameters: []




.. GENERATED FROM PYTHON SOURCE LINES 149-173

In order to perform calibration, we have to define a parametric model,
with observed inputs and parameters to calibrate.
In order to do this, we create a :class:`~openturns.ParametricFunction`
where the parameters are `Ks`, `Zv` and `Zm` which have the indices 1, 2
and 3 in the physical model.

+-------+----------------+
| Index | Input variable |
+=======+================+
| 0     | Q              |
+-------+----------------+

+-------+-----------+
| Index | Parameter |
+=======+===========+
| 0     | Ks        |
+-------+-----------+
| 1     | Zv        |
+-------+-----------+
| 3     | Zm        |
+-------+-----------+

**Table 2.** Indices and names of the inputs and parameters of the parametric model.


.. GENERATED FROM PYTHON SOURCE LINES 176-179

The following statement creates the calibrated function from the model.
The calibrated parameters :math:`K_s`, :math:`Z_v`, :math:`Z_m` are at
indices 1, 2, 3 in the inputs arguments of the model.

.. GENERATED FROM PYTHON SOURCE LINES 179-182

.. code-block:: default

    calibratedIndices = [1, 2, 3]
    mycf = ot.ParametricFunction(g, calibratedIndices, thetaPrior)








.. GENERATED FROM PYTHON SOURCE LINES 183-184

Plot the Y observations versus the X observations.

.. GENERATED FROM PYTHON SOURCE LINES 184-202

.. code-block:: default

    graph = ot.Graph("Observations", "Q ($m^3/s$)", "H (m)", True)
    # Plot the model before calibration
    curve = mycf.draw(100.0, 4000.0).getDrawable(0)
    curve.setLegend("Model, before calibration")
    curve.setLineStyle(ot.ResourceMap.GetAsString("CalibrationResult-ObservationLineStyle"))
    graph.add(curve)
    # Plot the noisy observations
    cloud = ot.Cloud(Qobs, Hobs)
    cloud.setLegend("Observations")
    cloud.setPointStyle(
        ot.ResourceMap.GetAsString("CalibrationResult-ObservationPointStyle")
    )
    graph.add(cloud)
    #
    graph.setColors(ot.Drawable.BuildDefaultPalette(2))
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_001.png
   :alt: Observations
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 203-206

Wee see that the model does not fit to the data.
The goal of calibration is to find which parameter best fit to the
observations.

.. GENERATED FROM PYTHON SOURCE LINES 208-213

Calibration with linear least squares
-------------------------------------
The :class:`~openturns.LinearLeastSquaresCalibration` class performs the linear
least squares calibration by linearizing the model in the neighbourhood of
the reference point.

.. GENERATED FROM PYTHON SOURCE LINES 213-215

.. code-block:: default

    algo = ot.LinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior, "SVD")








.. GENERATED FROM PYTHON SOURCE LINES 216-218

The :meth:`~openturns.LinearLeastSquaresCalibration.run` method computes the
solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 218-221

.. code-block:: default

    algo.run()
    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 222-224

The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the
maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 224-227

.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    print("theta After = ", thetaMAP)
    print("theta Before = ", thetaPrior)




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    theta After =  [2.94129e+09,-3.26646e+24,-3.26646e+24]
    theta Before =  [20.0, 49.0, 51.0]




.. GENERATED FROM PYTHON SOURCE LINES 228-229

Print the true values of the parameters.

.. GENERATED FROM PYTHON SOURCE LINES 229-234

.. code-block:: default

    print("True theta")
    print("  Ks = ", fm.trueKs)
    print("  Zv = ", fm.trueZv)
    print("  Zm = ", fm.trueZm)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    True theta
      Ks =  30.0
      Zv =  50.0
      Zm =  55.0




.. GENERATED FROM PYTHON SOURCE LINES 235-239

In this case, we see that there seems to be a great distance from the
reference value of :math:`\theta` to the optimum: the values seem too large in magnitude.
As we are going to see, there is an identification problem because the
Jacobian matrix is rank-degenerate.

.. GENERATED FROM PYTHON SOURCE LINES 241-243

Diagnostic of the identification issue
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 245-249

In this section, we show how to diagnose the identification problem.

The :meth:`~openturns.CalibrationResult.getParameterPosterior` method returns
the posterior normal distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 251-254

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()
    print(distributionPosterior)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Normal(mu = [2.94129e+09,-3.26646e+24,-3.26646e+24], sigma = [3.03385e+28,2.38506e+34,2.38506e+34], R = [[  1           4.9106e-26 -4.9106e-26 ]
     [  4.9106e-26  1           1          ]
     [ -4.9106e-26  1           1          ]])




.. GENERATED FROM PYTHON SOURCE LINES 255-258

We see that there is a large covariance matrix diagonal.

Let us compute a 95% confidence interval for the solution :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 260-266

.. code-block:: default

    print(
        distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(
            0.95
        )[0]
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [-6.78496e+28, 6.78496e+28]
    [-5.33401e+34, 5.33401e+34]
    [-5.33401e+34, 5.33401e+34]




.. GENERATED FROM PYTHON SOURCE LINES 267-270

The confidence interval is *very* large.
In order to clarify the situation, we compute the Jacobian matrix of the
model at the candidate point.

.. GENERATED FROM PYTHON SOURCE LINES 272-279

.. code-block:: default

    mycf.setParameter(thetaPrior)
    thetaDim = len(thetaPrior)
    jacobianMatrix = ot.Matrix(nbobs, thetaDim)
    for i in range(nbobs):
        jacobianMatrix[i, :] = mycf.parameterGradient(Qobs[i]).transpose()
    print(jacobianMatrix[0:5, :])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    5x3
    [[ -0.0314759  0.15738   -0.15738   ]
     [ -0.0731439  0.365719  -0.365719  ]
     [ -0.104466   0.52233   -0.52233   ]
     [ -0.131005   0.655027  -0.655027  ]
     [ -0.153845   0.769225  -0.769225  ]]




.. GENERATED FROM PYTHON SOURCE LINES 280-282

The rank of the problem can be seen from the singular values of the Jacobian
matrix.

.. GENERATED FROM PYTHON SOURCE LINES 284-286

.. code-block:: default

    print(jacobianMatrix.computeSingularValues())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [3.8102,5.32438e-11,3.00517e-26]




.. GENERATED FROM PYTHON SOURCE LINES 287-304

We can see that there are two singular values which are relatively close to zero.

This explains why the Jacobian matrix is close to being rank-degenerate.

Moreover, this allows one to compute the actual dimensionality of the problem.
The algorithm we use computes the singular values in descending order.
Moreover, by definition, the singular values are nonnegative.
We see that the first singular value is close to :math:`10`
and the others are very close to :math:`0` in comparison.
This implies that the (numerical) rank of the Jacobian matrix is 1,
even if there are 3 parameters.

Hence, only one parameter can be identified, be it :math:`K_s`, :math:`Z_v`
or :math:`Z_m`.
The choice of the particular parameter to identify is free.
However, in hydraulic studies, the parameter :math:`K_s` is classically
calibrated while :math:`Z_v` and :math:`Z_m` are left constant.

.. GENERATED FROM PYTHON SOURCE LINES 306-308

Conclusion of the linear least squares calibration
--------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 310-322

There are several methods to solve the problem.

* Given that the problem is not identifiable, we can use some regularization
  method. Two methods are provided in the library: the Gaussian linear least
  squares `GaussianLinearCalibration` and the Gaussian non linear least
  squares `GaussianNonlinearCalibration`.
* We can change the problem, replacing it with a problem which is identifiable.
  In the flooding model, we can view :math:`Z_v` and :math:`Z_m` as
  constants and calibrate :math:`K_s` only.

In this example, we do not change the problem and see how the different
methods perform.

.. GENERATED FROM PYTHON SOURCE LINES 324-329

Calibration with non linear least squares
-----------------------------------------
The :class:`~openturns.NonLinearLeastSquaresCalibration` class performs the
non linear least squares calibration by minimizing the squared Euclidian norm
between the predictions and the observations.

.. GENERATED FROM PYTHON SOURCE LINES 331-333

.. code-block:: default

    algo = ot.NonLinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior)








.. GENERATED FROM PYTHON SOURCE LINES 334-336

The :meth:`~openturns.NonLinearLeastSquaresCalibration.run` method computes
the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 336-339

.. code-block:: default

    algo.run()
    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 340-342

Analysis of the results
-----------------------

.. GENERATED FROM PYTHON SOURCE LINES 344-346

The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the
maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 348-351

.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    print(thetaMAP)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [27.566,47.0918,52.9082]




.. GENERATED FROM PYTHON SOURCE LINES 352-359

We can compute a 95% confidence interval of the parameter :math:`\theta^\star`.

This confidence interval is based on bootstrap, based on a sample size equal
to 100 (as long as the value of the :class:`~openturns.ResourceMap` key
"NonLinearLeastSquaresCalibration-BootstrapSize" is unchanged).
This confidence interval reflects the sensitivity of the optimum
to the variability in the observations.

.. GENERATED FROM PYTHON SOURCE LINES 359-361

.. code-block:: default

    print(ot.ResourceMap.GetAsUnsignedInteger("NonLinearLeastSquaresCalibration-BootstrapSize"))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    100




.. GENERATED FROM PYTHON SOURCE LINES 362-365

.. code-block:: default

    thetaPosterior = calibrationResult.getParameterPosterior()
    print(thetaPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [27.2302, 28.0034]
    [46.9071, 47.2336]
    [52.7664, 53.0929]




.. GENERATED FROM PYTHON SOURCE LINES 366-368

In this case, the values of the parameters are quite accurately
computed.

.. GENERATED FROM PYTHON SOURCE LINES 370-372

Increase the default number of points in the plots.
This produces smoother spiky distributions.

.. GENERATED FROM PYTHON SOURCE LINES 372-374

.. code-block:: default

    ot.ResourceMap.SetAsUnsignedInteger("Distribution-DefaultPointNumber", 300)








.. GENERATED FROM PYTHON SOURCE LINES 375-379

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_002.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 380-382

We see that there is a good fit after calibration, since the predictions after calibration
are close to the observations.

.. GENERATED FROM PYTHON SOURCE LINES 384-387

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_003.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 388-390

We see that there is a much better fit after calibration, since the
predictions are close to the diagonal of the graphics.

.. GENERATED FROM PYTHON SOURCE LINES 392-395

.. code-block:: default

    observationError = calibrationResult.getObservationsError()
    print(observationError)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Normal(mu = 0.0185511, sigma = 0.110646)




.. GENERATED FROM PYTHON SOURCE LINES 396-398

We can see that the observation error has a sample mean close to zero and a
sample standard deviation approximately equal to 0.11.

.. GENERATED FROM PYTHON SOURCE LINES 398-404

.. code-block:: default


    # sphinx_gallery_thumbnail_number = 5
    graph = calibrationResult.drawResiduals()
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_004.png
   :alt: Residual analysis
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 405-412

The analysis of the residuals shows that the distribution is centered on
zero and symmetric.
This indicates that the calibration performed well.
Moreover, the distribution of the residuals is close to being Gaussian.
This is an important hypothesis of the least squares method so that
checking that this hypothesis occurs in the study is an important
verification.

.. GENERATED FROM PYTHON SOURCE LINES 414-423

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = otv.View(
        graph,
        figure_kw={"figsize": (8.0, 4.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plt.subplots_adjust(right=0.8, bottom=0.2)





.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_005.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 424-460

.. code-block:: default

    def plotDistributionGridPDF(distribution):
        """
        Plot the marginal and bi-dimensional iso-PDF on a grid.

        Parameters
        ----------
        distribution : ot.Distribution
            The distribution.

        Returns
        -------
        grid : ot.GridLayout(dimension, dimension)
            The grid of plots.

        """
        dimension = distribution.getDimension()
        grid = ot.GridLayout(dimension, dimension)
        for i in range(dimension):
            for j in range(dimension):
                if i == j:
                    distributionI = distribution.getMarginal([i])
                    graph = distributionI.drawPDF()
                else:
                    distributionJI = distribution.getMarginal([j, i])
                    graph = distributionJI.drawPDF()
                graph.setLegends([""])
                graph.setTitle("")
                if i < dimension - 1:
                    graph.setXTitle("")
                if j > 0:
                    graph.setYTitle("")
                grid.setGraph(i, j, graph)
        grid.setTitle("Iso-PDF values")
        return grid









.. GENERATED FROM PYTHON SOURCE LINES 461-462

Plot the PDF values of the distribution of the optimum parameters.

.. GENERATED FROM PYTHON SOURCE LINES 462-471

.. code-block:: default

    grid = plotDistributionGridPDF(thetaPosterior)
    view = otv.View(
        grid,
        figure_kw={"figsize": (6.0, 6.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plot_space = 0.5
    plt.subplots_adjust(wspace=plot_space, hspace=plot_space)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_006.png
   :alt: Iso-PDF values
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 472-474

Gaussian linear calibration
---------------------------

.. GENERATED FROM PYTHON SOURCE LINES 476-477

The standard deviation of the observations.

.. GENERATED FROM PYTHON SOURCE LINES 477-479

.. code-block:: default

    sigmaH = 0.5  # (m^2)








.. GENERATED FROM PYTHON SOURCE LINES 480-481

Define the covariance matrix of the output Y of the model.

.. GENERATED FROM PYTHON SOURCE LINES 481-484

.. code-block:: default

    errorCovariance = ot.CovarianceMatrix(1)
    errorCovariance[0, 0] = sigmaH**2








.. GENERATED FROM PYTHON SOURCE LINES 485-486

Define the covariance matrix of the parameters :math:`\theta` to calibrate.

.. GENERATED FROM PYTHON SOURCE LINES 486-496

.. code-block:: default

    sigmaKs = 5.0
    sigmaZv = 1.0
    sigmaZm = 1.0
    #
    sigma = ot.CovarianceMatrix(3)
    sigma[0, 0] = sigmaKs**2
    sigma[1, 1] = sigmaZv**2
    sigma[2, 2] = sigmaZm**2
    print(sigma)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [[ 25  0  0 ]
     [  0  1  0 ]
     [  0  0  1 ]]




.. GENERATED FROM PYTHON SOURCE LINES 497-499

The :class:`~openturns.GaussianLinearCalibration` class performs Gaussian
linear calibration by linearizing the model in the neighbourhood of the prior.

.. GENERATED FROM PYTHON SOURCE LINES 499-503

.. code-block:: default

    algo = ot.GaussianLinearCalibration(
        mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance, "SVD"
    )








.. GENERATED FROM PYTHON SOURCE LINES 504-506

The :meth:`~openturns.GaussianLinearCalibration.run` method computes
the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 506-509

.. code-block:: default

    algo.run()
    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 510-514

Analysis of the results
-----------------------
The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the
maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 514-517

.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    print(thetaMAP)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [24.4058,48.1188,51.8812]




.. GENERATED FROM PYTHON SOURCE LINES 518-522

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_007.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 523-525

We see that the output of the model after calibration is closer to the
observations.

.. GENERATED FROM PYTHON SOURCE LINES 527-530

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_008.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_008.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 531-532

In this case, the fit is satisfactory after calibration.

.. GENERATED FROM PYTHON SOURCE LINES 534-538

.. code-block:: default

    graph = calibrationResult.drawResiduals()
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_009.png
   :alt: Residual analysis
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_009.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 539-541

We see that the distribution of the residual is centered on zero after
calibration.

.. GENERATED FROM PYTHON SOURCE LINES 543-545

The :meth:`~openturns.CalibrationResult.getParameterPosterior` method
returns the posterior normal distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 547-550

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()
    print(distributionPosterior)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Normal(mu = [24.4058,48.1188,51.8812], sigma = [4.09428,0.818856,0.818856], R = [[  1         0.491369 -0.491369 ]
     [  0.491369  1         0.491369 ]
     [ -0.491369  0.491369  1        ]])




.. GENERATED FROM PYTHON SOURCE LINES 551-552

We can compute a 95% credibility interval of the parameter :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 552-558

.. code-block:: default

    print(
        distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(
            0.95
        )[0]
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [14.8113, 34.0003]
    [46.1999, 50.0377]
    [49.9623, 53.8001]




.. GENERATED FROM PYTHON SOURCE LINES 559-561

We see that there is a large uncertainty on the value of the parameter
:math:`K_s` which can be as small as :math:`14` and as large as :math:`34`.

.. GENERATED FROM PYTHON SOURCE LINES 563-564

We can compare the prior and posterior distributions of the marginals of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 566-574

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = otv.View(
        graph,
        figure_kw={"figsize": (8.0, 4.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plt.subplots_adjust(right=0.8)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_010.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_010.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 575-582

The two distributions are different, which shows that the calibration is
sensitive to the observations (if the observations were not sensitive, the
two distributions were superimposed).
Moreover, the two distributions are quite close, which implies that the prior
distribution has played a role in the calibration (otherwise the two
distributions would be completely different,
indicating that only the observations were taken into account).

.. GENERATED FROM PYTHON SOURCE LINES 584-585

Plot the PDF values of the distribution of the optimum parameters.

.. GENERATED FROM PYTHON SOURCE LINES 585-594

.. code-block:: default

    grid = plotDistributionGridPDF(thetaPosterior)
    view = otv.View(
        grid,
        figure_kw={"figsize": (6.0, 6.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plot_space = 0.5
    plt.subplots_adjust(wspace=plot_space, hspace=plot_space)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_011.png
   :alt: Iso-PDF values
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_011.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 595-599

Gaussian nonlinear calibration
------------------------------
The :class:`~openturns.GaussianNonLinearCalibration` class performs Gaussian
nonlinear calibration.

.. GENERATED FROM PYTHON SOURCE LINES 599-603

.. code-block:: default

    algo = ot.GaussianNonLinearCalibration(
        mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance
    )








.. GENERATED FROM PYTHON SOURCE LINES 604-606

The :meth:`~openturns.GaussianNonLinearCalibration.run` method computes the
solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 606-609

.. code-block:: default

    algo.run()
    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 610-614

Analysis of the results
-----------------------
The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the
maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 614-617

.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    print(thetaMAP)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [29.4528,47.7599,52.2401]




.. GENERATED FROM PYTHON SOURCE LINES 618-622

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_012.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_012.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 623-625

We see that the output of the model after calibration is in the middle of the
observations: the calibration seems correct.

.. GENERATED FROM PYTHON SOURCE LINES 627-630

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = otv.View(graph)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_013.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_013.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 631-632

The fit is excellent after calibration. Indeed, the cloud of points after calibration is on the diagonal.

.. GENERATED FROM PYTHON SOURCE LINES 634-642

.. code-block:: default

    graph = calibrationResult.drawResiduals()
    view = otv.View(
        graph,
        figure_kw={"figsize": (8.0, 4.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plt.subplots_adjust(right=0.6)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_014.png
   :alt: Residual analysis
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_014.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 643-645

We see that the distribution of the residual is centered on zero.
This is a proof that the calibration did perform correctly.

.. GENERATED FROM PYTHON SOURCE LINES 647-649

The :meth:`~openturns.CalibrationResult.getParameterPosterior` method
returns the posterior normal distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 649-651

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()








.. GENERATED FROM PYTHON SOURCE LINES 652-653

We can compute a 95% credibility interval of the parameter :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 653-659

.. code-block:: default

    print(
        distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(
            0.95
        )[0]
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [29.9024, 30.9945]
    [47.5636, 47.7011]
    [52.2989, 52.4364]




.. GENERATED FROM PYTHON SOURCE LINES 660-661

We see that there is a small uncertainty on the value of all parameters.

.. GENERATED FROM PYTHON SOURCE LINES 663-664

We can compare the prior and posterior distributions of the marginals of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 664-672

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = otv.View(
        graph,
        figure_kw={"figsize": (8.0, 4.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plt.subplots_adjust(right=0.8)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_015.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_015.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 673-675

The two distributions are very different, with a spiky posterior distribution.
This shows that the calibration is very sensitive to the observations.

.. GENERATED FROM PYTHON SOURCE LINES 677-678

Plot the PDF values of the distribution of the optimum parameters.

.. GENERATED FROM PYTHON SOURCE LINES 678-687

.. code-block:: default

    grid = plotDistributionGridPDF(thetaPosterior)
    view = otv.View(
        grid,
        figure_kw={"figsize": (6.0, 6.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plot_space = 0.5
    plt.subplots_adjust(wspace=plot_space, hspace=plot_space)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_016.png
   :alt: Iso-PDF values
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_016.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 688-702

Tuning the posterior distribution estimation
--------------------------------------------

The "GaussianNonLinearCalibration-BootstrapSize" key of the
:class:`~openturns.ResourceMap` controls the posterior distribution estimation.

* If "GaussianNonLinearCalibration-BootstrapSize" > 0 (by default it is equal to 100),
  then a bootstrap resample algorithm is used to see the dispersion of the MAP estimator.
  This allows one to see the variability of the estimator with respect to
  the finite noisy observation sample.
* If "GaussianNonLinearCalibration-BootstrapSize" is zero, then the
  Gaussian linear calibration estimator is used (i.e. the :class:`~openturns.GaussianLinearCalibration`
  class) at the optimum. This is called the Laplace approximation.


.. GENERATED FROM PYTHON SOURCE LINES 704-707

The default value of the key is nonzero, meaning that bootstrap is used.
This can be costly in some cases, because it requires to repeat the
optimization several times.

.. GENERATED FROM PYTHON SOURCE LINES 707-709

.. code-block:: default

    print(ot.ResourceMap.GetAsUnsignedInteger("GaussianNonLinearCalibration-BootstrapSize"))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    100




.. GENERATED FROM PYTHON SOURCE LINES 710-712

We must configure the key before creating the object (otherwise changing
the parameter does not change the result).

.. GENERATED FROM PYTHON SOURCE LINES 712-726

.. code-block:: default

    ot.ResourceMap.SetAsUnsignedInteger("GaussianNonLinearCalibration-BootstrapSize", 0)
    algo = ot.GaussianNonLinearCalibration(
        mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance
    )
    algo.run()
    calibrationResult = algo.getResult()
    graph = calibrationResult.drawParameterDistributions()
    view = otv.View(
        graph,
        figure_kw={"figsize": (8.0, 4.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plt.subplots_adjust(right=0.8)




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_017.png
   :alt: plot calibration flooding
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_017.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 727-728

As we can see, this does not change much the posterior distribution, which remains spiky.

.. GENERATED FROM PYTHON SOURCE LINES 730-731

Plot the PDF values of the distribution of the optimum parameters.

.. GENERATED FROM PYTHON SOURCE LINES 731-742

.. code-block:: default

    grid = plotDistributionGridPDF(thetaPosterior)
    view = otv.View(
        grid,
        figure_kw={"figsize": (6.0, 6.0)},
        legend_kw={"bbox_to_anchor": (1.0, 1.0), "loc": "upper left"},
    )
    plot_space = 0.5
    plt.subplots_adjust(wspace=plot_space, hspace=plot_space)

    otv.View.ShowAll()




.. image-sg:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_018.png
   :alt: Iso-PDF values
   :srcset: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_018.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 743-744

Reset default settings

.. GENERATED FROM PYTHON SOURCE LINES 744-745

.. code-block:: default

    ot.ResourceMap.Reload()








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  8.267 seconds)


.. _sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_calibration_flooding.py <plot_calibration_flooding.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_calibration_flooding.ipynb <plot_calibration_flooding.ipynb>`
