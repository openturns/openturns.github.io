
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_flooding.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py:


Calibration of the flooding model
=================================

.. GENERATED FROM PYTHON SOURCE LINES 6-58

In this example we are interested in the calibration of the :ref:`flooding model <use-case-flood-model>`.

Parameters to calibrate
-----------------------

The vector of parameters to calibrate is: 

.. math::
   \theta = (K_s,Z_v,Z_m).


The variables to calibrate are :math:`(K_s,Z_v,Z_m)` and are set to the following values:

.. math::
   K_s = 30, \qquad Z_v = 50, \qquad Z_m = 55.


Observations
------------

In this section, we describe the statistical model associated with the :math:`n` observations.
The errors of the water heights are associated with a gaussian distribution with a zero mean and a standard variation equal to:

.. math::
   \sigma=0.1.


Therefore, the observed water heights are:

.. math::
   H_i = G(Q_i,K_s,Z_v,Z_m) + \epsilon_i


for :math:`i=1,...,n` where

.. math::
   \epsilon \sim \mathcal{N}(0,\sigma^2)


and we make the hypothesis that the observation errors are independent.
We consider a sample size equal to:

.. math::
   n=100.


The observations are the couples :math:`\{(Q_i,H_i)\}_{i=1,...,n}`, i.e. each observation is a couple made of the flowrate and the corresponding river height.

Analysis
--------

In this model, the variables :math:`Z_m` and :math:`Z_v` are not identifiables, since only the difference :math:`Z_m-Z_v` matters. Hence, calibrating this model requires some regularization.

.. GENERATED FROM PYTHON SOURCE LINES 60-62

Generate the observations
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 64-71

.. code-block:: default

    import numpy as np
    import openturns as ot
    ot.ResourceMap.SetAsUnsignedInteger('Normal-SmallDimension', 1)
    import openturns.viewer as viewer
    from matplotlib import pylab as plt
    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 72-73

We load the flooding use case :

.. GENERATED FROM PYTHON SOURCE LINES 73-76

.. code-block:: default

    from openturns.usecases import flood_model as flood_model
    fm = flood_model.FloodModel()








.. GENERATED FROM PYTHON SOURCE LINES 77-85

We define the model :math:`g` which has 4 inputs and one output H.

The nonlinear least squares does not take into account for bounds in the parameters. Therefore, we ensure that the output is computed whatever the inputs. The model fails into two situations:

* if :math:`K_s<0`,
* if :math:`Z_v-Z_m<0`.

In these cases, we return an infinite number, so that the optimization algorithm does not get trapped.

.. GENERATED FROM PYTHON SOURCE LINES 87-99

.. code-block:: default

    def functionFlooding(X) :
        L = 5.0e3
        B = 300.0
        Q, K_s, Z_v, Z_m = X
        alpha = (Z_m - Z_v)/L
        if alpha < 0.0 or K_s <= 0.0:
            H = np.inf
        else:
            H = (Q/(K_s*B*np.sqrt(alpha)))**(3.0/5.0)
        return [H]









.. GENERATED FROM PYTHON SOURCE LINES 100-104

.. code-block:: default

    g = ot.PythonFunction(4, 1, functionFlooding) 
    g = ot.MemoizeFunction(g)
    g.setOutputDescription(["H (m)"])








.. GENERATED FROM PYTHON SOURCE LINES 105-106

We load the input distribution for :math:`Q` :

.. GENERATED FROM PYTHON SOURCE LINES 108-111

.. code-block:: default

    Q = fm.Q
    Q






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>TruncatedDistribution(Gumbel(beta = 558, gamma = 1013), bounds = [0, (19000.8) +inf[)</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 112-113

Set the parameters to be calibrated.

.. GENERATED FROM PYTHON SOURCE LINES 115-122

.. code-block:: default

    K_s = ot.Dirac(30.0)
    Z_v = ot.Dirac(50.0)
    Z_m = ot.Dirac(55.0)
    K_s.setDescription(["Ks (m^(1/3)/s)"])
    Z_v.setDescription(["Zv (m)"])
    Z_m.setDescription(["Zm (m)"])








.. GENERATED FROM PYTHON SOURCE LINES 123-124

Create the joint input distribution.

.. GENERATED FROM PYTHON SOURCE LINES 126-128

.. code-block:: default

    inputRandomVector = ot.ComposedDistribution([Q, K_s, Z_v, Z_m])








.. GENERATED FROM PYTHON SOURCE LINES 129-130

Create a Monte-Carlo sample of the output H.

.. GENERATED FROM PYTHON SOURCE LINES 132-136

.. code-block:: default

    nbobs = 100
    inputSample = inputRandomVector.getSample(nbobs)
    outputH = g(inputSample)








.. GENERATED FROM PYTHON SOURCE LINES 137-138

Observe the distribution of the output H.

.. GENERATED FROM PYTHON SOURCE LINES 140-143

.. code-block:: default

    graph = ot.HistogramFactory().build(outputH).drawPDF()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_001.png
    :alt: H (m) PDF
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 144-145

Generate the observation noise and add it to the output of the model.

.. GENERATED FROM PYTHON SOURCE LINES 147-152

.. code-block:: default

    sigmaObservationNoiseH = 0.1 # (m)
    noiseH = ot.Normal(0.,sigmaObservationNoiseH)
    sampleNoiseH = noiseH.getSample(nbobs)
    Hobs = outputH + sampleNoiseH








.. GENERATED FROM PYTHON SOURCE LINES 153-154

Plot the Y observations versus the X observations.

.. GENERATED FROM PYTHON SOURCE LINES 156-158

.. code-block:: default

    Qobs = inputSample[:,0]








.. GENERATED FROM PYTHON SOURCE LINES 159-164

.. code-block:: default

    graph = ot.Graph("Observations","Q (m3/s)","H (m)",True)
    cloud = ot.Cloud(Qobs,Hobs)
    graph.add(cloud)
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_002.png
    :alt: Observations
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 165-167

Setting the calibration parameters
----------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 169-170

Define the value of the reference values of the :math:`\theta` parameter. In the bayesian framework, this is called the mean of the *prior* gaussian distribution. In the data assimilation framework, this is called the *background*.

.. GENERATED FROM PYTHON SOURCE LINES 172-177

.. code-block:: default

    KsInitial = 20.
    ZvInitial = 49.
    ZmInitial = 51.
    thetaPrior = [KsInitial, ZvInitial, ZmInitial]








.. GENERATED FROM PYTHON SOURCE LINES 178-179

The following statement create the calibrated function from the model. The calibrated parameters Ks, Zv, Zm are at indices 1, 2, 3 in the inputs arguments of the model.

.. GENERATED FROM PYTHON SOURCE LINES 181-184

.. code-block:: default

    calibratedIndices = [1,2,3]
    mycf = ot.ParametricFunction(g, calibratedIndices, thetaPrior)








.. GENERATED FROM PYTHON SOURCE LINES 185-187

Calibration with linear least squares
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 189-190

The `LinearLeastSquaresCalibration` class performs the linear least squares calibration by linearizing the model in the neighbourhood of the reference point.

.. GENERATED FROM PYTHON SOURCE LINES 192-194

.. code-block:: default

    algo = ot.LinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior, "SVD")








.. GENERATED FROM PYTHON SOURCE LINES 195-196

The `run` method computes the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 198-200

.. code-block:: default

    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 201-203

.. code-block:: default

    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 204-205

The `getParameterMAP` method returns the maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 207-210

.. code-block:: default

    thetaStar = calibrationResult.getParameterMAP()
    thetaStar






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[-1.5344e+09,3.82448e+23,3.82448e+23]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 211-212

In this case, we see that there seems to be a great distance from the reference value of :math:`\theta` to the optimum: the values seem too large in magnitude. The value of the optimum :math:`K_s` is nonpositive. In fact, there is an identification problem because the Jacobian matrix is rank-degenerate.

.. GENERATED FROM PYTHON SOURCE LINES 214-216

Diagnostic of the identification issue
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 218-221

In this section, we show how to diagnose the identification problem.

The `getParameterPosterior` method returns the posterior gaussian distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 223-226

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()
    distributionPosterior






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>Normal(mu = [-1.5344e+09,3.82448e+23,3.82448e+23], sigma = [1.87726e+26,1.47581e+32,1.47581e+32], R = [[  1            5.72409e-25 -5.72409e-25 ]<br>
     [  5.72409e-25  1            1           ]<br>
     [ -5.72409e-25  1            1           ]])</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 227-230

We see that there is a large covariance matrix diagonal. 

Let us compute a 95% confidence interval for the solution :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 232-234

.. code-block:: default

    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[-4.19405e+26, 4.19405e+26]<br>
    [-3.29716e+32, 3.29716e+32]<br>
    [-3.29716e+32, 3.29716e+32]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 235-236

The confidence interval is *very* large.

.. GENERATED FROM PYTHON SOURCE LINES 238-245

.. code-block:: default

    mycf.setParameter(thetaPrior)
    thetaDim = len(thetaPrior)
    jacobianMatrix = ot.Matrix(nbobs,thetaDim)
    for i in range(nbobs):
        jacobianMatrix[i,:] = mycf.parameterGradient(Qobs[i]).transpose()
    jacobianMatrix[0:5,:]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>5x3<br>
    [[ -0.103257   0.516284  -0.516284  ]<br>
     [ -0.149304   0.746522  -0.746522  ]<br>
     [ -0.105068   0.525341  -0.525341  ]<br>
     [ -0.0900736  0.450368  -0.450368  ]<br>
     [ -0.10892    0.544602  -0.544602  ]]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 246-248

.. code-block:: default

    jacobianMatrix.computeSingularValues()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[8.87203,1.54711e-10,2.98131e-25]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 249-252

We can see that there are two singular values which are relatively close to zero. 

This explains why the Jacobian matrix is close to being rank-degenerate.

.. GENERATED FROM PYTHON SOURCE LINES 254-256

Conclusion of the linear least squares calibration
--------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 258-262

There are several methods to solve the problem.

* Given that the problem is not identifiable, we can use some regularization method. Two methods are provided in the library: the gaussian linear least squares `GaussianLinearCalibration` and the gaussian non linear least squares `GaussianNonlinearCalibration`.
* We can change the problem, replacing it with a problem which is identifiable. In the flooding model, replacing :math:`Z_v-Z_m` with :math:`\Delta Z` allows to solve the issue.

.. GENERATED FROM PYTHON SOURCE LINES 264-266

Calibration with non linear least squares
-----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 268-269

The `NonLinearLeastSquaresCalibration` class performs the non linear least squares calibration by minimizing the squared euclidian norm between the predictions and the observations.

.. GENERATED FROM PYTHON SOURCE LINES 271-273

.. code-block:: default

    algo = ot.NonLinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior)








.. GENERATED FROM PYTHON SOURCE LINES 274-275

The `run` method computes the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 277-279

.. code-block:: default

    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 280-282

.. code-block:: default

    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 283-285

Analysis of the results
-----------------------

.. GENERATED FROM PYTHON SOURCE LINES 287-288

The `getParameterMAP` method returns the maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 290-293

.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    thetaMAP






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[27.6494,47.065,52.935]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 294-297

We can compute a 95% confidence interval of the parameter :math:`\theta^\star`. 

This confidence interval is based on bootstrap, based on a sample size equal to 100 (as long as the value of the `ResourceMap` key "NonLinearLeastSquaresCalibration-BootstrapSize" is unchanged). This confidence interval reflects the sensitivity of the optimum to the variability in the observations.

.. GENERATED FROM PYTHON SOURCE LINES 299-302

.. code-block:: default

    thetaPosterior = calibrationResult.getParameterPosterior()
    thetaPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[27.5083, 27.8092]<br>
    [46.9972, 47.1249]<br>
    [52.8751, 53.0028]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 303-304

In this case, the value of the parameter :math:`K_s` is quite accurately computed, but there is a relatively large uncertainty on the values of :math:`Z_v` and :math:`Z_m`.

.. GENERATED FROM PYTHON SOURCE LINES 306-310

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_003.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 311-312

We see that there is a good fit after calibration, since the predictions after calibration (i.e. the green crosses) are close to the observations (i.e. the blue crosses).

.. GENERATED FROM PYTHON SOURCE LINES 314-317

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_004.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 318-319

We see that there is a much better fit after calibration, since the predictions are close to the diagonal of the graphics.

.. GENERATED FROM PYTHON SOURCE LINES 321-324

.. code-block:: default

    observationError = calibrationResult.getObservationsError()
    observationError






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>Normal(mu = 0.00262637, sigma = 0.0951039)</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 325-326

We can see that the observation error is close to have a zero mean and a standard deviation equal to 0.1.

.. GENERATED FROM PYTHON SOURCE LINES 328-332

.. code-block:: default

    graph = calibrationResult.drawResiduals()
    graph.setLegendPosition("topleft")
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_005.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 333-336

The analysis of the residuals shows that the distribution is centered on zero and symmetric. This indicates that the calibration performed well. 

Moreover, the distribution of the residuals is close to being gaussian.

.. GENERATED FROM PYTHON SOURCE LINES 338-341

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_006.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 342-344

Gaussian linear calibration
---------------------------

.. GENERATED FROM PYTHON SOURCE LINES 346-347

The standard deviation of the observations.

.. GENERATED FROM PYTHON SOURCE LINES 349-351

.. code-block:: default

    sigmaH = 0.5 # (m^2)








.. GENERATED FROM PYTHON SOURCE LINES 352-353

Define the covariance matrix of the output Y of the model.

.. GENERATED FROM PYTHON SOURCE LINES 355-358

.. code-block:: default

    errorCovariance = ot.CovarianceMatrix(1)
    errorCovariance[0,0] = sigmaH**2








.. GENERATED FROM PYTHON SOURCE LINES 359-360

Define the covariance matrix of the parameters :math:`\theta` to calibrate.

.. GENERATED FROM PYTHON SOURCE LINES 362-366

.. code-block:: default

    sigmaKs = 5.
    sigmaZv = 1.
    sigmaZm = 1.








.. GENERATED FROM PYTHON SOURCE LINES 367-373

.. code-block:: default

    sigma = ot.CovarianceMatrix(3)
    sigma[0,0] = sigmaKs**2
    sigma[1,1] = sigmaZv**2
    sigma[2,2] = sigmaZm**2
    sigma






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[[ 25  0  0 ]<br>
     [  0  1  0 ]<br>
     [  0  0  1 ]]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 374-375

The `GaussianLinearCalibration` class performs the gaussian linear calibration by linearizing the model in the neighbourhood of the prior.

.. GENERATED FROM PYTHON SOURCE LINES 377-379

.. code-block:: default

    algo = ot.GaussianLinearCalibration(mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance,"SVD")








.. GENERATED FROM PYTHON SOURCE LINES 380-381

The `run` method computes the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 383-385

.. code-block:: default

    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 386-388

.. code-block:: default

    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 389-391

Analysis of the results
-----------------------

.. GENERATED FROM PYTHON SOURCE LINES 393-394

The `getParameterMAP` method returns the maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 396-399

.. code-block:: default

    thetaStar = calibrationResult.getParameterMAP()
    thetaStar






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[24.4781,48.1044,51.8956]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 400-404

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_007.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 405-406

We see that the output of the model after calibration is closer to the observations. However, there is still a distance from the outputs of the model to the observations. This indicates that the calibration cannot be performed with this method.

.. GENERATED FROM PYTHON SOURCE LINES 408-411

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_008.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 412-413

In this case, the fit is better after calibration, but not perfect. Indeed, the cloud of points after calibration is not centered on the diagonal. 

.. GENERATED FROM PYTHON SOURCE LINES 415-419

.. code-block:: default

    graph = calibrationResult.drawResiduals()
    graph.setLegendPosition("topleft")
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_009.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 420-421

We see that the distribution of the residual is not centered on zero: the mean residual is approximately -0.5, which implies that the predictions are, on average, smaller than the observations. This is a proof that the calibration cannot be performed with this method in this particular case.

.. GENERATED FROM PYTHON SOURCE LINES 423-424

The `getParameterPosterior` method returns the posterior gaussian distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 426-429

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()
    distributionPosterior






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>Normal(mu = [24.4781,48.1044,51.8956], sigma = [4.08468,0.816936,0.816936], R = [[  1         0.498385 -0.498385 ]<br>
     [  0.498385  1         0.498385 ]<br>
     [ -0.498385  0.498385  1        ]])</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 430-431

We can compute a 95% confidence interval of the parameter :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 433-435

.. code-block:: default

    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[14.8981, 34.058]<br>
    [46.1884, 50.0204]<br>
    [49.9796, 53.8116]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 436-437

We see that there is a large uncertainty on the value of the parameter :math:`K_s` which can be as small as 14 and as large as 34. 

.. GENERATED FROM PYTHON SOURCE LINES 439-440

We can compare the prior and posterior distributions of the marginals of :math:`\theta`. 

.. GENERATED FROM PYTHON SOURCE LINES 442-445

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_010.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 446-447

The two distributions are different, which shows that the calibration is sensible to the observations (if the observations were not sensible, the two distributions were superimposed). Moreover, the two distributions are quite close, which implies that the prior distribution has played a roled in the calibration (otherwise the two distributions would be completely different, indicating that only the observations were taken into account). 

.. GENERATED FROM PYTHON SOURCE LINES 449-451

Gaussian nonlinear calibration
------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 453-454

The `GaussianNonLinearCalibration` class performs the gaussian nonlinear calibration.

.. GENERATED FROM PYTHON SOURCE LINES 456-458

.. code-block:: default

    algo = ot.GaussianNonLinearCalibration(mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance)








.. GENERATED FROM PYTHON SOURCE LINES 459-460

The `run` method computes the solution of the problem.

.. GENERATED FROM PYTHON SOURCE LINES 462-464

.. code-block:: default

    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 465-467

.. code-block:: default

    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 468-470

Analysis of the results
-----------------------

.. GENERATED FROM PYTHON SOURCE LINES 472-473

The `getParameterMAP` method returns the maximum of the posterior distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 475-478

.. code-block:: default

    thetaStar = calibrationResult.getParameterMAP()
    thetaStar






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[30.4264,47.6447,52.3553]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 479-483

.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    graph.setLegendPosition("topleft")
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_011.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 484-485

We see that the output of the model after calibration is in the middle of the observations: the calibration seems correct.

.. GENERATED FROM PYTHON SOURCE LINES 487-490

.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_012.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 491-492

The fit is excellent after calibration. Indeed, the cloud of points after calibration is on the diagonal. 

.. GENERATED FROM PYTHON SOURCE LINES 494-497

.. code-block:: default

    graph = calibrationResult.drawResiduals()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_013.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 498-499

We see that the histogram of the residual is centered on zero. This is a proof that the calibration did perform correctly.

.. GENERATED FROM PYTHON SOURCE LINES 501-502

The `getParameterPosterior` method returns the posterior gaussian distribution of :math:`\theta`.

.. GENERATED FROM PYTHON SOURCE LINES 504-506

.. code-block:: default

    distributionPosterior = calibrationResult.getParameterPosterior()








.. GENERATED FROM PYTHON SOURCE LINES 507-508

We can compute a 95% confidence interval of the parameter :math:`\theta^\star`.

.. GENERATED FROM PYTHON SOURCE LINES 510-512

.. code-block:: default

    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <p>[30.3861, 30.9228]<br>
    [47.5811, 47.6498]<br>
    [52.3502, 52.4189]</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 513-514

We see that there is a small uncertainty on the value of all parameters.

.. GENERATED FROM PYTHON SOURCE LINES 516-517

We can compare the prior and posterior distributions of the marginals of :math:`\theta`. 

.. GENERATED FROM PYTHON SOURCE LINES 519-522

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = viewer.View(graph)




.. image:: /auto_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_flooding_014.png
    :alt: plot calibration flooding
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 523-524

The two distributions are very different, with a spiky posterior distribution. This shows that the calibration is very sensible to the observations. 

.. GENERATED FROM PYTHON SOURCE LINES 526-535

Tuning the posterior distribution estimation
--------------------------------------------

The "GaussianNonLinearCalibration-BootstrapSize" key controls the posterior distribution estimation.

* If "GaussianNonLinearCalibration-BootstrapSize" > 0 (by default it is equal to 100), then a bootstrap resample algorithm is used to see the dispersion of the MAP estimator. This allows to see the variability of the estimator with respect to the finite observation sample.
* If "GaussianNonLinearCalibration-BootstrapSize" is zero, then the gaussian linear calibration estimator is used (i.e. the `GaussianLinearCalibration` class) at the optimum. This is called the Laplace approximation. 

We must configure the key before creating the object (otherwise changing the parameter does not change the result). 

.. GENERATED FROM PYTHON SOURCE LINES 537-539

.. code-block:: default

    ot.ResourceMap_SetAsUnsignedInteger("GaussianNonLinearCalibration-BootstrapSize",0) 








.. GENERATED FROM PYTHON SOURCE LINES 540-542

.. code-block:: default

    algo = ot.GaussianNonLinearCalibration(mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance)








.. GENERATED FROM PYTHON SOURCE LINES 543-545

.. code-block:: default

    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 546-548

.. code-block:: default

    calibrationResult = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 549-552

.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()

    plt.show()







.. GENERATED FROM PYTHON SOURCE LINES 553-554

As we can see, this does not change much the posterior distribution, which remains spiky. 


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  5.441 seconds)


.. _sphx_glr_download_auto_calibration_least_squares_and_gaussian_calibration_plot_calibration_flooding.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_calibration_flooding.py <plot_calibration_flooding.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_calibration_flooding.ipynb <plot_calibration_flooding.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
