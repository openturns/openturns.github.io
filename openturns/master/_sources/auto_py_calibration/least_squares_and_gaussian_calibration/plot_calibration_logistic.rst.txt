.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_py_calibration_least_squares_and_gaussian_calibration_plot_calibration_logistic.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_py_calibration_least_squares_and_gaussian_calibration_plot_calibration_logistic.py:


Calibration of the logistic model
=================================

Introduction
------------

The logistic growth model is the differential equation:

.. math::
   \frac{dy(t)}{dt} = ay(t) - by(t)^2


for any :math:`t\in[t_0, t_{final}]`, with the initial condition:

.. math::
   y(t_0) = y_0


where

- :math:`a > 0` and :math:`b > 0` are two real parameters, 
- :math:`y(t)` is the size of the population at time :math:`t`, 
- :math:`t_0` is the initial time,
- :math:`y_0` is the initial population at time :math:`t=t_0`, 
- :math:`t_{final}` is the final time.

The :math:`a` parameter sets the growth rate of the population. The :math:`b` parameter acts as a competition parameter which limits the size of the population by increasing the competition between its members. 

In [1], the author uses this model to simulate the growth of the U.S. population. To do this, the author uses the U.S. census data from 1790 to 1910. For this time interval, R. Pearl and L. Reed [2] computed the following values of the parameters:

.. math::
   a = 0.03134, \qquad b = 1.5887 \times 10^{-10}.


Our goal is to use the logistic growth model in order to simulate the solution for a larger time interval, from 1790 to 2000:

.. math::
   t_0 = 1790, \qquad t_{final} = 2000.


Then we can compare the predictions of this model with the real evolution of the U.S. population.

We can prove that, if :math:`y_0 > 0`, then the limit population is:

.. math::
   y_{limit} =\frac{a}{b}.


In 1790, the U.S. population was 3.9 Millions inhabitants:

.. math::
   y_0 = 3.9 \times 10^6.


We can prove that the exact solution of the ordinary differential equation is:

.. math::
   y(t)=\frac{ay_0}{by_0+(a-by_0 ) \exp(-a(t-t_0)) }


for any :math:`t\in[t_0, t_{final}]`.

We want to see the solution of the ordinary differential equation when uncertainties are taken into account in the parameters:

- the initial U.S. population :math:`y_0`,
- the parameters :math:`a` and :math:`b`.

Indeed, Pearl and Reed [2] estimated the parameters :math:`a` and :math:`b` using the U.S. census data from 1790 to 1910 while we have the data up to 2000. Moreover, the method used by Pearl and Reed to estimate the parameters could be improved; they only used 3 dates to estimate the parameters instead of using least squares, for example. Finally, Pearl and Reed did not provide confidence intervals for the parameters :math:`a` and :math:`b`. 

Normalizing the data
--------------------

The order of magnitude of :math:`a` and :math:`b` are very different. In order to mitigate this, we consider the parameter :math:`c` as the logarithm of :math:`b`:

.. math::
   c = \log(b).


This leads to the value:

.. math::
   c = \log\left(1.5887 \times 10^{-10}\right) = -22.58.


The order of magnitude of the population is :math:`10^6`. This is why we consider the normalized population in millions:

.. math::
   z(t) = \frac{y(t)}{10^6}


for any :math:`t\in[t_0, t_{final}]`.

Let :math:`z_0` be the initial population:

.. math::
   z_0 = z(t_0).


Uncertainties
-------------

Uncertainty can be accounted for by turning :math:`z_0`, :math:`a` and :math:`c` into independent random variables :math:`Z_0`, :math:`A` and :math:`C` with Gaussian distributions. From this point onward, :math:`z_0`, :math:`a` and :math:`b` respectively denote :math:`\mathbb{E}[Z_0]`, :math:`\mathbb{E}[A]` and :math:`\mathbb{E}[C]`.

===========   ===============================================================
Variable      Distribution
===========   ===============================================================
:math:`Z_0`   gaussian, mean :math:`z_0`, coefficient of variation 10% 
:math:`A`     gaussian, mean :math:`a`, coefficient of variation 30% 
:math:`C`     gaussian, mean :math:`c`, coefficient of variation 30% 
===========   ===============================================================

No particular probabilistic method was used to set these distributions. An improvement would be to use calibration methods to get a better quantification of these distributions. An improvement would be to use calibration methods to get a better quantification of these distributions. 

Notes
-----

* This example is based on [1], chapter "First order differential equations", page 28. The data used in [1] are from [3]. The logistic growth model was first suggested by Pierre Francois Verhulst near 1840. The data are from [1] for the time interval from 1790 to 1950, then from [2] for the time interval from 1960 to 2000.
* Calibrating this model may require to take into account for the time dependency of the measures.


References
----------

[1] Martin Braun. Differential equations and their applications, Fourth Edition. Texts in applied
mathematics. Springer, 1993.

[2] Cleve Moler. Numerical Computing with Matlab. Society for Industrial Applied Mathematics,
2004.

[3] Raymond Pearl and Lowell Reed. On the rate of growth of the population of the united states
since 1790 and its mathematical representation. Proceedings of the National Academy of Sciences,
1920.

Analysis of the data
--------------------


.. code-block:: default

    import openturns as ot
    import numpy as np
    import openturns.viewer as viewer
    from matplotlib import pylab as plt
    ot.Log.Show(ot.Log.NONE)








The data is based on 22 dates from 1790 to 2000.


.. code-block:: default

    observedSample=ot.Sample([\
    [1790,3.9], \
    [1800,5.3], \
    [1810,7.2], \
    [1820,9.6], \
    [1830,13], \
    [1840,17], \
    [1850,23], \
    [1860,31], \
    [1870,39], \
    [1880,50], \
    [1890,62], \
    [1900,76], \
    [1910,92], \
    [1920,106], \
    [1930,123], \
    [1940,132], \
    [1950,151], \
    [1960,179], \
    [1970,203], \
    [1980,221], \
    [1990,250], \
    [2000,281]])









.. code-block:: default

    nbobs = observedSample.getSize()
    nbobs





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    22




.. code-block:: default

    timeObservations = observedSample[:,0]
    timeObservations[0:5]






.. raw:: html

    <TABLE><TR><TD></TD><TH>v0</TH></TR>
    <TR><TH>0</TH><TD>1790</TD></TR>
    <TR><TH>1</TH><TD>1800</TD></TR>
    <TR><TH>2</TH><TD>1810</TD></TR>
    <TR><TH>3</TH><TD>1820</TD></TR>
    <TR><TH>4</TH><TD>1830</TD></TR>
    </TABLE>
    <br />
    <br />


.. code-block:: default

    populationObservations = observedSample[:,1]
    populationObservations[0:5]






.. raw:: html

    <TABLE><TR><TD></TD><TH>v1</TH></TR>
    <TR><TH>0</TH><TD>3.9</TD></TR>
    <TR><TH>1</TH><TD>5.3</TD></TR>
    <TR><TH>2</TH><TD>7.2</TD></TR>
    <TR><TH>3</TH><TD>9.6</TD></TR>
    <TR><TH>4</TH><TD>13</TD></TR>
    </TABLE>
    <br />
    <br />


.. code-block:: default

    graph = ot.Graph('', 'Time (years)', 'Population (Millions)', True, 'topleft')
    cloud = ot.Cloud(timeObservations, populationObservations)
    cloud.setLegend("Observations")
    graph.add(cloud)
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_001.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img





We consider the times and populations as dimension 22 vectors. The `logisticModel` function takes a dimension 24 vector as input and returns a dimension 22 vector. The first 22 components of the input vector contains the dates and the remaining 2 components are $a$ and $b$. 


.. code-block:: default

    nbdates = 22
    def logisticModel(X):
        t = [X[i] for i in range(nbdates)]
        a = X[22]
        c = X[23]
        t0 = 1790.
        y0 = 3.9e6
        b = np.exp(c)
        y = ot.Point(nbdates)
        for i in range(nbdates):
            y[i] = a*y0/(b*y0+(a-b*y0)*np.exp(-a*(t[i]-t0)))
        z = y/1.e6 # Convert into millions
        return z










.. code-block:: default

    logisticModelPy = ot.PythonFunction(24, nbdates, logisticModel)








The reference values of the parameters. 

Because :math:`b` is so small with respect to :math:`a`, we use the logarithm. 


.. code-block:: default

    np.log(1.5587e-10)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    -22.581998789427587




.. code-block:: default

    a=0.03134
    c=-22.58
    thetaPrior = [a,c]









.. code-block:: default

    logisticParametric = ot.ParametricFunction(logisticModelPy,[22,23],thetaPrior)








Check that we can evaluate the parametric function.


.. code-block:: default

    populationPredicted = logisticParametric(timeObservations.asPoint())
    populationPredicted






.. raw:: html

    <p>[3.9,5.29757,7.17769,9.69198,13.0277,17.4068,23.0769,30.2887,39.2561,50.0977,62.7691,77.0063,92.311,108.001,123.322,137.59,150.3,161.184,170.193,177.442,183.144,187.55]#22</p>
    <br />
    <br />


.. code-block:: default

    graph = ot.Graph('', 'Time (years)', 'Population (Millions)', True, 'topleft')
    # Observations
    cloud = ot.Cloud(timeObservations, populationObservations)
    cloud.setLegend("Observations")
    cloud.setColor("blue")
    graph.add(cloud)
    # Predictions
    cloud = ot.Cloud(timeObservations.asPoint(), populationPredicted)
    cloud.setLegend("Predictions")
    cloud.setColor("green")
    graph.add(cloud)
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_002.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img





We see that the fit is not good: the observations continue to grow after 1950, while the growth of the prediction seem to fade.

Calibration with linear least squares
-------------------------------------


.. code-block:: default

    timeObservationsVector = ot.Sample([[timeObservations[i,0] for i in range(nbobs)]])
    timeObservationsVector[0:10]






.. raw:: html

    <TABLE><TR><TD></TD><TH>v0</TH><TH>v1</TH><TH>v2</TH><TH>v3</TH><TH>v4</TH><TH>v5</TH><TH>v6</TH><TH>v7</TH><TH>v8</TH><TH>v9</TH><TH>v10</TH><TH>v11</TH><TH>v12</TH><TH>v13</TH><TH>v14</TH><TH>v15</TH><TH>v16</TH><TH>v17</TH><TH>v18</TH><TH>v19</TH><TH>v20</TH><TH>v21</TH></TR>
    <TR><TH>0</TH><TD>1790</TD><TD>1800</TD><TD>1810</TD><TD>1820</TD><TD>1830</TD><TD>1840</TD><TD>1850</TD><TD>1860</TD><TD>1870</TD><TD>1880</TD><TD>1890</TD><TD>1900</TD><TD>1910</TD><TD>1920</TD><TD>1930</TD><TD>1940</TD><TD>1950</TD><TD>1960</TD><TD>1970</TD><TD>1980</TD><TD>1990</TD><TD>2000</TD></TR>
    </TABLE>
    <br />
    <br />


.. code-block:: default

    populationObservationsVector = ot.Sample([[populationObservations[i, 0] for i in range(nbobs)]])
    populationObservationsVector[0:10]






.. raw:: html

    <TABLE><TR><TD></TD><TH>v0</TH><TH>v1</TH><TH>v2</TH><TH>v3</TH><TH>v4</TH><TH>v5</TH><TH>v6</TH><TH>v7</TH><TH>v8</TH><TH>v9</TH><TH>v10</TH><TH>v11</TH><TH>v12</TH><TH>v13</TH><TH>v14</TH><TH>v15</TH><TH>v16</TH><TH>v17</TH><TH>v18</TH><TH>v19</TH><TH>v20</TH><TH>v21</TH></TR>
    <TR><TH>0</TH><TD>3.9</TD><TD>5.3</TD><TD>7.2</TD><TD>9.6</TD><TD>13</TD><TD>17</TD><TD>23</TD><TD>31</TD><TD>39</TD><TD>50</TD><TD>62</TD><TD>76</TD><TD>92</TD><TD>106</TD><TD>123</TD><TD>132</TD><TD>151</TD><TD>179</TD><TD>203</TD><TD>221</TD><TD>250</TD><TD>281</TD></TR>
    </TABLE>
    <br />
    <br />

The reference values of the parameters. 


.. code-block:: default

    a=0.03134
    c=-22.58
    thetaPrior = ot.Point([a,c])










.. code-block:: default

    logisticParametric = ot.ParametricFunction(logisticModelPy,[22,23],thetaPrior)








Check that we can evaluate the parametric function.


.. code-block:: default

    populationPredicted = logisticParametric(timeObservationsVector)
    populationPredicted[0:10]






.. raw:: html

    <TABLE><TR><TD></TD><TH>y0</TH><TH>y1</TH><TH>y2</TH><TH>y3</TH><TH>y4</TH><TH>y5</TH><TH>y6</TH><TH>y7</TH><TH>y8</TH><TH>y9</TH><TH>y10</TH><TH>y11</TH><TH>y12</TH><TH>y13</TH><TH>y14</TH><TH>y15</TH><TH>y16</TH><TH>y17</TH><TH>y18</TH><TH>y19</TH><TH>y20</TH><TH>y21</TH></TR>
    <TR><TH>0</TH><TD>3.9</TD><TD>5.297571</TD><TD>7.177694</TD><TD>9.691977</TD><TD>13.02769</TD><TD>17.40682</TD><TD>23.07691</TD><TD>30.2887</TD><TD>39.25606</TD><TD>50.09767</TD><TD>62.76907</TD><TD>77.0063</TD><TD>92.31103</TD><TD>108.0009</TD><TD>123.3223</TD><TD>137.5899</TD><TD>150.3003</TD><TD>161.1843</TD><TD>170.193</TD><TD>177.4422</TD><TD>183.1443</TD><TD>187.5496</TD></TR>
    </TABLE>
    <br />
    <br />

Calibration
------------


.. code-block:: default

    algo = ot.LinearLeastSquaresCalibration(logisticParametric, timeObservationsVector, populationObservationsVector, thetaPrior)









.. code-block:: default

    algo.run()









.. code-block:: default

    calibrationResult = algo.getResult()









.. code-block:: default

    thetaMAP = calibrationResult.getParameterMAP()
    thetaMAP






.. raw:: html

    <p>[0.0265958,-23.1714]</p>
    <br />
    <br />


.. code-block:: default

    thetaPosterior = calibrationResult.getParameterPosterior()
    thetaPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]






.. raw:: html

    <p>[0.0246465, 0.028545]<br>
    [-23.3182, -23.0247]</p>
    <br />
    <br />

transpose samples to interpret several observations instead of several input/outputs as it is a field model


.. code-block:: default

    if calibrationResult.getInputObservations().getSize() == 1:
        calibrationResult.setInputObservations([timeObservations[i] for i in range(nbdates)])
        calibrationResult.setOutputObservations([populationObservations[i] for i in range(nbdates)])
        outputAtPrior = [[calibrationResult.getOutputAtPriorMean()[0, i]] for i in range(nbdates)]
        outputAtPosterior = [[calibrationResult.getOutputAtPosteriorMean()[0, i]] for i in range(nbdates)]
        calibrationResult.setOutputAtPriorAndPosteriorMean(outputAtPrior, outputAtPosterior)









.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_003.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img






.. code-block:: default

    graph = calibrationResult.drawObservationsVsInputs()
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_004.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img






.. code-block:: default

    graph = calibrationResult.drawObservationsVsPredictions()
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_005.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img






.. code-block:: default

    graph = calibrationResult.drawResiduals()
    view = viewer.View(graph)




.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_006.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img






.. code-block:: default

    graph = calibrationResult.drawParameterDistributions()
    view = viewer.View(graph)

    plt.show()



.. image:: /auto_py_calibration/least_squares_and_gaussian_calibration/images/sphx_glr_plot_calibration_logistic_007.png
    :alt: plot calibration logistic
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.296 seconds)


.. _sphx_glr_download_auto_py_calibration_least_squares_and_gaussian_calibration_plot_calibration_logistic.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_calibration_logistic.py <plot_calibration_logistic.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_calibration_logistic.ipynb <plot_calibration_logistic.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
