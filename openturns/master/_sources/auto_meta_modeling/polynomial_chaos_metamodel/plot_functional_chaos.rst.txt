
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_meta_modeling/polynomial_chaos_metamodel/plot_functional_chaos.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_functional_chaos.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_meta_modeling_polynomial_chaos_metamodel_plot_functional_chaos.py:


Create a polynomial chaos metamodel from a data set
===================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-12

In this example, we create a polynomial chaos expansion (PCE) using
a data set.
More precisely, given a pair of input and output samples,
we create a PCE without the knowledge of the input distribution.
In this example, we use a relatively small sample size equal to 80.

.. GENERATED FROM PYTHON SOURCE LINES 14-35

In this example we create a global approximation of a model response using
polynomial chaos expansion.

Let :math:`\vect{g}` be the function defined by:

.. math::
   \vect{g}(\vect{x}) = \Tr{\left(\cos(x_1 + x_2), (x_2 + 1) e^{x_1}\right)}


for any :math:`\vect{x} \in \Rset^2`.

We assume that

.. math::
   X_1 \sim \mathcal{N}(0,1) \textrm{ and } X_2 \sim \mathcal{N}(0,1)

and that :math:`X_1` and :math:`X_2` are independent.

An interesting point in this example is that the output is multivariate.
This is why we are going to use the `getMarginal` method in the script
in order to select the output marginal that we want to manage.

.. GENERATED FROM PYTHON SOURCE LINES 37-39

Simulate input and output samples
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 41-47

.. code-block:: Python

    import openturns as ot
    import openturns.viewer as viewer
    from matplotlib import pylab as plt

    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 48-49

We first create the function `model`.

.. GENERATED FROM PYTHON SOURCE LINES 51-58

.. code-block:: Python

    ot.RandomGenerator.SetSeed(0)
    input_names = ["x1", "x2"]
    formulas = ["cos(x1 + x2)", "(x2 + 1) * exp(x1)"]
    model = ot.SymbolicFunction(input_names, formulas)
    inputDimension = model.getInputDimension()
    outputDimension = model.getOutputDimension()








.. GENERATED FROM PYTHON SOURCE LINES 59-61

Then we create a sample `inputSample` and compute the corresponding output
sample `outputSample`.

.. GENERATED FROM PYTHON SOURCE LINES 63-68

.. code-block:: Python

    distribution = ot.Normal(inputDimension)
    samplesize = 80
    inputSample = distribution.getSample(samplesize)
    outputSample = model(inputSample)








.. GENERATED FROM PYTHON SOURCE LINES 69-71

Create the PCE
~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 73-83

Create a functional chaos model.
The algorithm needs to fit a distribution on the input sample.
To do this, the algorithm in :class:`~openturns.FunctionalChaosAlgorithm`
uses the :class:`~openturns.FunctionalChaosAlgorithm.BuildDistribution`
static method to fit the distribution to the input sample.
Please read :doc:`Fit a distribution from an input sample </auto_meta_modeling/polynomial_chaos_metamodel/plot_chaos_build_distribution>`
for an example of this method.
The algorithm does this automatically using the Lilliefors test.
In order to make the algorithm a little faster, we reduce the
value of the sample size used in the Lilliefors test.

.. GENERATED FROM PYTHON SOURCE LINES 85-87

.. code-block:: Python

    ot.ResourceMap.SetAsUnsignedInteger("FittingTest-LillieforsMaximumSamplingSize", 50)








.. GENERATED FROM PYTHON SOURCE LINES 88-91

The main topic of this example is to introduce the next constructor of
:class:`~openturns.FunctionalChaosAlgorithm`.
Notice that the only input arguments are the input and output samples.

.. GENERATED FROM PYTHON SOURCE LINES 91-96

.. code-block:: Python

    algo = ot.FunctionalChaosAlgorithm(inputSample, outputSample)
    algo.run()
    result = algo.getResult()
    result






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    FunctionalChaosResult
    <ul>
      <li>input dimension: 2</li>
      <li>output dimension: 2</li>
      <li>distribution dimension: 2</li>
      <li>transformation: 2 -> 2</li>
      <li>inverse transformation: 2 -> 2</li>
      <li>orthogonal basis dimension: 2</li>
      <li>indices size: 33</li>
      <li>relative errors: [0.000326182,2.94703e-07]</li>
      <li>residuals: [0.00129952,0.000160374]</li>
    </ul>
    <table>
      <tr>
        <th>Index</th>
        <th>Multi-index</th>
        <th>Coeff.#0</th>
        <th>Coeff.#1</th>
      </tr>
      <tr>
        <th>0</th>
        <td>[0,0]</td>
        <td>0.4157338</td>
        <td>1.766267</td>
      </tr>
      <tr>
        <th>1</th>
        <td>[1,0]</td>
        <td>0.2310582</td>
        <td>2.017161</td>
      </tr>
      <tr>
        <th>2</th>
        <td>[0,1]</td>
        <td>0.06674082</td>
        <td>1.837368</td>
      </tr>
      <tr>
        <th>3</th>
        <td>[2,0]</td>
        <td>0.09816137</td>
        <td>1.821379</td>
      </tr>
      <tr>
        <th>4</th>
        <td>[0,2]</td>
        <td>-0.3076637</td>
        <td>-0.01464018</td>
      </tr>
      <tr>
        <th>5</th>
        <td>[3,0]</td>
        <td>0.3951189</td>
        <td>1.146608</td>
      </tr>
      <tr>
        <th>6</th>
        <td>[0,3]</td>
        <td>0.07087581</td>
        <td>0.0002386309</td>
      </tr>
      <tr>
        <th>7</th>
        <td>[1,1]</td>
        <td>0.04728438</td>
        <td>1.983242</td>
      </tr>
      <tr>
        <th>8</th>
        <td>[4,0]</td>
        <td>0.4122558</td>
        <td>0.7798714</td>
      </tr>
      <tr>
        <th>9</th>
        <td>[0,4]</td>
        <td>0.1268529</td>
        <td>0.001559385</td>
      </tr>
      <tr>
        <th>10</th>
        <td>[5,0]</td>
        <td>0.2841537</td>
        <td>0.4215949</td>
      </tr>
      <tr>
        <th>11</th>
        <td>[0,5]</td>
        <td>-0.008199683</td>
        <td>-0.002441298</td>
      </tr>
      <tr>
        <th>12</th>
        <td>[2,1]</td>
        <td>0.05345879</td>
        <td>1.437201</td>
      </tr>
      <tr>
        <th>13</th>
        <td>[1,2]</td>
        <td>0.09992143</td>
        <td>-0.02049864</td>
      </tr>
      <tr>
        <th>14</th>
        <td>[6,0]</td>
        <td>0.19985</td>
        <td>0.3551065</td>
      </tr>
      <tr>
        <th>15</th>
        <td>[0,6]</td>
        <td>0.1080172</td>
        <td>0.01664983</td>
      </tr>
      <tr>
        <th>16</th>
        <td>[7,0]</td>
        <td>0.1479776</td>
        <td>0.173851</td>
      </tr>
      <tr>
        <th>17</th>
        <td>[0,7]</td>
        <td>-0.03474477</td>
        <td>-0.00292527</td>
      </tr>
      <tr>
        <th>18</th>
        <td>[3,1]</td>
        <td>0.2354754</td>
        <td>0.7409979</td>
      </tr>
      <tr>
        <th>19</th>
        <td>[1,3]</td>
        <td>0.6043447</td>
        <td>0.04656466</td>
      </tr>
      <tr>
        <th>20</th>
        <td>[2,2]</td>
        <td>0.4434066</td>
        <td>-0.004206286</td>
      </tr>
      <tr>
        <th>21</th>
        <td>[8,0]</td>
        <td>0.08286844</td>
        <td>0.1384384</td>
      </tr>
      <tr>
        <th>22</th>
        <td>[0,8]</td>
        <td>0.1204243</td>
        <td>0.01601914</td>
      </tr>
      <tr>
        <th>23</th>
        <td>[4,1]</td>
        <td>0.01628032</td>
        <td>0.2432426</td>
      </tr>
      <tr>
        <th>24</th>
        <td>[1,4]</td>
        <td>0.01408954</td>
        <td>-0.006884768</td>
      </tr>
      <tr>
        <th>25</th>
        <td>[9,0]</td>
        <td>0.04082984</td>
        <td>0.04282058</td>
      </tr>
      <tr>
        <th>26</th>
        <td>[0,9]</td>
        <td>-0.009678954</td>
        <td>0.0001552316</td>
      </tr>
      <tr>
        <th>27</th>
        <td>[3,2]</td>
        <td>0.1005659</td>
        <td>-0.002783204</td>
      </tr>
      <tr>
        <th>28</th>
        <td>[2,3]</td>
        <td>0.04742904</td>
        <td>-0.002838578</td>
      </tr>
      <tr>
        <th>29</th>
        <td>[10,0]</td>
        <td>0.01375835</td>
        <td>0.02651859</td>
      </tr>
      <tr>
        <th>30</th>
        <td>[0,10]</td>
        <td>0.05126546</td>
        <td>0.006360932</td>
      </tr>
      <tr>
        <th>31</th>
        <td>[5,1]</td>
        <td>-0.06583213</td>
        <td>0.0634149</td>
      </tr>
      <tr>
        <th>32</th>
        <td>[1,5]</td>
        <td>0.09951267</td>
        <td>0.02014581</td>
      </tr>
    </table>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 97-102

Not all coefficients are selected in this PCE.
Indeed, the default constructor of :class:`~openturns.FunctionalChaosAlgorithm`
creates a sparse PCE.
Please read :doc:`Create a full or sparse polynomial chaos expansion </auto_meta_modeling/polynomial_chaos_metamodel/plot_functional_chaos_database>`
for more details on this topic.

.. GENERATED FROM PYTHON SOURCE LINES 104-105

Get the metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 105-107

.. code-block:: Python

    metamodel = result.getMetaModel()








.. GENERATED FROM PYTHON SOURCE LINES 108-111

Plot the second output of our model depending on :math:`x_2` with :math:`x_1=0.5`.
In order to do this, we create a `ParametricFunction` and set the value of :math:`x_1`.
Then we use the `getMarginal` method to extract the second output (which index is equal to 1).

.. GENERATED FROM PYTHON SOURCE LINES 113-131

.. code-block:: Python

    x1index = 0
    x1value = 0.5
    x2min = -3.0
    x2max = 3.0
    outputIndex = 1
    metamodelParametric = ot.ParametricFunction(metamodel, [x1index], [x1value])
    graph = metamodelParametric.getMarginal(outputIndex).draw(x2min, x2max)
    graph.setLegends(["Metamodel"])
    modelParametric = ot.ParametricFunction(model, [x1index], [x1value])
    curve = modelParametric.getMarginal(outputIndex).draw(x2min, x2max).getDrawable(0)
    curve.setColor("red")
    curve.setLegend("Model")
    graph.add(curve)
    graph.setLegendPosition("lower right")
    graph.setXTitle("X2")
    graph.setTitle("Metamodel Validation, output #%d" % (outputIndex))
    view = viewer.View(graph)




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_001.png
   :alt: Metamodel Validation, output #1
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 132-136

We see that the metamodel fits approximately to the model, except
perhaps for extreme values of :math:`x_2`.
However, there is a better way of globally validating the metamodel,
using the :class:`~openturns.MetaModelValidation` on a validation design of experiments.

.. GENERATED FROM PYTHON SOURCE LINES 138-143

.. code-block:: Python

    n_valid = 100
    inputTest = distribution.getSample(n_valid)
    outputTest = model(inputTest)









.. GENERATED FROM PYTHON SOURCE LINES 144-145

Plot the corresponding validation graphics.

.. GENERATED FROM PYTHON SOURCE LINES 147-154

.. code-block:: Python

    metamodelPredictions = metamodel(inputTest)
    val = ot.MetaModelValidation(outputTest, metamodelPredictions)
    r2Score = val.computeR2Score()
    graph = val.drawValidation()
    graph.setTitle("Metamodel validation R2=" + str(r2Score))
    view = viewer.View(graph)




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_002.png
   :alt: Metamodel validation R2=[-3.50512,0.969793]
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 155-159

The coefficient of determination is not extremely satisfactory for the
first output, but is would be sufficient for a central dispersion study.
The second output has a much more satisfactory :math:`R^2`: only one single
extreme point is far from the diagonal of the graphics.

.. GENERATED FROM PYTHON SOURCE LINES 161-163

Compute and print Sobol' indices
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 165-168

.. code-block:: Python

    chaosSI = ot.FunctionalChaosSobolIndices(result)
    chaosSI






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    FunctionalChaosSobolIndices
    <ul>
      <li>input dimension: 2</li>
      <li>output dimension: 2</li>
      <li>basis size: 33</li>
      <li>mean: [0.415734,1.76627]</li>
      <li>std-dev: [1.16199,4.4335]</li>
    </ul>
    Output marginal: 0
    <table>
      <tr>
        <th>Input</th>
        <th>Variable</th>
        <th>Sobol' index</th>
        <th>Total index</th>
      </tr>
      <tr>
        <td>0</td>
        <td>X0</td>
        <td>0.400231</td>
        <td>0.888617</td>
      </tr>
      <tr>
        <td>1</td>
        <td>X1</td>
        <td>0.111383</td>
        <td>0.599769</td>
      </tr>
    </table>
    <table>
      <tr>
        <th>Index</th>
        <th>Multi-index</th>
        <th>Part of variance</th>
      </tr>
      <tr>
        <td>19</td>
        <td>[1,3]</td>
        <td>0.270497</td>
      </tr>
      <tr>
        <td>20</td>
        <td>[2,2]</td>
        <td>0.145612</td>
      </tr>
      <tr>
        <td>8</td>
        <td>[4,0]</td>
        <td>0.125871</td>
      </tr>
      <tr>
        <td>5</td>
        <td>[3,0]</td>
        <td>0.115624</td>
      </tr>
      <tr>
        <td>4</td>
        <td>[0,2]</td>
        <td>0.070105</td>
      </tr>
      <tr>
        <td>10</td>
        <td>[5,0]</td>
        <td>0.059800</td>
      </tr>
      <tr>
        <td>18</td>
        <td>[3,1]</td>
        <td>0.041066</td>
      </tr>
      <tr>
        <td>1</td>
        <td>[1,0]</td>
        <td>0.039540</td>
      </tr>
      <tr>
        <td>14</td>
        <td>[6,0]</td>
        <td>0.029580</td>
      </tr>
      <tr>
        <td>16</td>
        <td>[7,0]</td>
        <td>0.016218</td>
      </tr>
      <tr>
        <td>9</td>
        <td>[0,4]</td>
        <td>0.011918</td>
      </tr>
      <tr>
        <td>22</td>
        <td>[0,8]</td>
        <td>0.010740</td>
      </tr>
    </table>
    Output marginal: 1
    <table>
      <tr>
        <th>Input</th>
        <th>Variable</th>
        <th>Sobol' index</th>
        <th>Total index</th>
      </tr>
      <tr>
        <td>0</td>
        <td>X0</td>
        <td>0.491712</td>
        <td>0.828208</td>
      </tr>
      <tr>
        <td>1</td>
        <td>X1</td>
        <td>0.171792</td>
        <td>0.508288</td>
      </tr>
    </table>
    <table>
      <tr>
        <th>Index</th>
        <th>Multi-index</th>
        <th>Part of variance</th>
      </tr>
      <tr>
        <td>1</td>
        <td>[1,0]</td>
        <td>0.207009</td>
      </tr>
      <tr>
        <td>7</td>
        <td>[1,1]</td>
        <td>0.200105</td>
      </tr>
      <tr>
        <td>2</td>
        <td>[0,1]</td>
        <td>0.171751</td>
      </tr>
      <tr>
        <td>3</td>
        <td>[2,0]</td>
        <td>0.168775</td>
      </tr>
      <tr>
        <td>12</td>
        <td>[2,1]</td>
        <td>0.105085</td>
      </tr>
      <tr>
        <td>5</td>
        <td>[3,0]</td>
        <td>0.066886</td>
      </tr>
      <tr>
        <td>8</td>
        <td>[4,0]</td>
        <td>0.030942</td>
      </tr>
      <tr>
        <td>18</td>
        <td>[3,1]</td>
        <td>0.027935</td>
      </tr>
    </table>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 169-177

Let us analyze the results of this global sensitivity analysis.

* We see that the first output involves significant multi-indices with
  higher marginal degree.
* For the second output, the first variable is especially significant,
  with a significant contribution of the interactions.
  The contribution of the interactions are very
  significant in this model.

.. GENERATED FROM PYTHON SOURCE LINES 179-180

Draw Sobol' indices.

.. GENERATED FROM PYTHON SOURCE LINES 182-186

.. code-block:: Python

    sensitivityAnalysis = ot.FunctionalChaosSobolIndices(result)
    first_order = [sensitivityAnalysis.getSobolIndex(i) for i in range(inputDimension)]
    total_order = [sensitivityAnalysis.getSobolTotalIndex(i) for i in range(inputDimension)]








.. GENERATED FROM PYTHON SOURCE LINES 187-192

.. code-block:: Python

    input_names = model.getInputDescription()
    graph = ot.SobolIndicesAlgorithm.DrawSobolIndices(input_names, first_order, total_order)
    graph.setLegendPosition("center")
    view = viewer.View(graph)




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_003.png
   :alt: Sobol' indices
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 193-208

Testing the sensitivity to the degree
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

With the specific constructor of :class:`~openturns.FunctionalChaosAlgorithm` that
we use, the `FunctionalChaosAlgorithm-MaximumTotalDegree`
in the `ResourceMap` configures the maximum degree explored by
the algorithm. This degree is a trade-off.

* If the maximum degree is too low, the polynomial may miss some
  coefficients so that the quality is lower than possible.
* If the maximum degree is too large, the number of coefficients
  to explore is too large, so that the coefficients might be poorly estimated.

This is why the following `for` loop explores various degrees to see
the sensitivity of the metamodel predictivity depending on the degree.

.. GENERATED FROM PYTHON SOURCE LINES 210-211

The default value of this parameter is 10.

.. GENERATED FROM PYTHON SOURCE LINES 213-215

.. code-block:: Python

    ot.ResourceMap.GetAsUnsignedInteger("FunctionalChaosAlgorithm-MaximumTotalDegree")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    10



.. GENERATED FROM PYTHON SOURCE LINES 216-217

This is why we explore the values from 1 to 10.

.. GENERATED FROM PYTHON SOURCE LINES 219-237

.. code-block:: Python

    maximumDegree = 11
    degrees = range(1, maximumDegree)
    r2Score = ot.Sample(len(degrees), outputDimension)
    for maximumDegree in degrees:
        ot.ResourceMap.SetAsUnsignedInteger(
            "FunctionalChaosAlgorithm-MaximumTotalDegree", maximumDegree
        )
        print("Maximum total degree =", maximumDegree)
        algo = ot.FunctionalChaosAlgorithm(inputSample, outputSample)
        algo.run()
        result = algo.getResult()
        metamodel = result.getMetaModel()
        metamodelPredictions = metamodel(inputTest)
        val = ot.MetaModelValidation(outputTest, metamodelPredictions)
        r2ScoreLocal = val.computeR2Score()
        r2ScoreLocal = [max(0.0, r2ScoreLocal[i]) for i in range(outputDimension)]
        r2Score[maximumDegree - degrees[0]] = r2ScoreLocal





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Maximum total degree = 1
    Maximum total degree = 2
    Maximum total degree = 3
    Maximum total degree = 4
    Maximum total degree = 5
    Maximum total degree = 6
    Maximum total degree = 7
    Maximum total degree = 8
    Maximum total degree = 9
    Maximum total degree = 10




.. GENERATED FROM PYTHON SOURCE LINES 238-253

.. code-block:: Python

    graph = ot.Graph("Predictivity", "Total degree", "R2", True)
    cloud = ot.Cloud([[d] for d in degrees], r2Score[:, 0])
    cloud.setLegend("Output #0")
    cloud.setPointStyle("bullet")
    graph.add(cloud)
    cloud = ot.Cloud([[d] for d in degrees], r2Score[:, 1])
    cloud.setLegend("Output #1")
    cloud.setPointStyle("diamond")
    graph.add(cloud)
    graph.setLegendPosition("upper left")
    graph.setLegendCorner([1.0, 1.0])
    view = viewer.View(graph)
    plt.subplots_adjust(right=0.7)
    plt.show()




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_004.png
   :alt: Predictivity
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_functional_chaos_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 254-275

We see that a low total degree is not sufficient to describe the
first output with good :math:`R^2` score.
However, the coefficient of determination can drop when the total degree increases.
The :math:`R^2` score of the second output seems to be much less satisfactory:
a little more work would be required to improve the metamodel.

In this situation, the following methods may be used.

* Since the distribution of the input is known, we may want to give
  this information to the :class:`~openturns.FunctionalChaosAlgorithm`.
  This prevents the algorithm from trying to fit the input distribution
  which best fit to the data.
* We may want to customize the `adaptiveStrategy` by selecting an enumerate
  function which best fit to this particular example.
  In this specific example, however, the interactions plays a great role so that the
  linear enumerate function may provide better results than the hyperbolic rule.
* We may want to customize the `projectionStrategy` by selecting a method
  to compute the coefficient which improves the estimation.
  For example, it might be interesting to
  try an integration rule instead of the least squares method.
  Notice that a specific design of experiments is required in this case.

.. GENERATED FROM PYTHON SOURCE LINES 277-278

Reset default settings

.. GENERATED FROM PYTHON SOURCE LINES 278-279

.. code-block:: Python

    ot.ResourceMap.Reload()








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 14.771 seconds)


.. _sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_functional_chaos.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_functional_chaos.ipynb <plot_functional_chaos.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_functional_chaos.py <plot_functional_chaos.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_functional_chaos.zip <plot_functional_chaos.zip>`
