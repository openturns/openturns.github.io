
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_meta_modeling/polynomial_chaos_metamodel/plot_chaos_cantilever_beam_integration.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_cantilever_beam_integration.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_cantilever_beam_integration.py:


Create a polynomial chaos metamodel by integration on the cantilever beam
=========================================================================

.. GENERATED FROM PYTHON SOURCE LINES 7-17

In this example, we create a polynomial chaos metamodel by integration on the
:ref:`cantilever beam <use-case-cantilever-beam>` example.
We choose to evaluate the coefficients of the chaos decomposition by
integration using various kinds of design of experiment:

- Gauss product
- Latin hypercube sampling
- Quasi Monte Carlo with a Sobol' sequence

We will compare the results obtained on each design.

.. GENERATED FROM PYTHON SOURCE LINES 19-24

.. code-block:: default

    from openturns.usecases import cantilever_beam
    import openturns as ot
    import openturns.viewer as otv
    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 25-26

We first load the model from the usecases module :

.. GENERATED FROM PYTHON SOURCE LINES 26-28

.. code-block:: default

    cb = cantilever_beam.CantileverBeam()








.. GENERATED FROM PYTHON SOURCE LINES 29-31

In this example we consider all marginals independent.
They are defined in the :class:`~openturns.usecases.cantilever_beam.CantileverBeam`  class:

.. GENERATED FROM PYTHON SOURCE LINES 31-37

.. code-block:: default

    dist_E = cb.E
    dist_F = cb.F
    dist_L = cb.L
    dist_I = cb.I
    distribution = cb.independentDistribution








.. GENERATED FROM PYTHON SOURCE LINES 38-39

We load the model.

.. GENERATED FROM PYTHON SOURCE LINES 39-43

.. code-block:: default

    dim_input = cb.dim  # dimension of the input
    dim_output = 1  # dimension of the output
    g = cb.model








.. GENERATED FROM PYTHON SOURCE LINES 44-46

Create a polynomial chaos decomposition
---------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 48-50

We create the multivariate polynomial basis by tensorization of the
univariate polynomials and the default linear enumerate rule.

.. GENERATED FROM PYTHON SOURCE LINES 50-53

.. code-block:: default

    multivariateBasis = ot.OrthogonalProductPolynomialFactory(
        [dist_E, dist_F, dist_L, dist_I])








.. GENERATED FROM PYTHON SOURCE LINES 54-58

In this case, we select `P` using the
:meth:`~openturns.EnumerateFunction.getBasisSizeFromTotalDegree` method,
so that all polynomials with total degree lower or equal to 5 are used.
This will lead to the computation of 126 coefficients.

.. GENERATED FROM PYTHON SOURCE LINES 58-63

.. code-block:: default

    totalDegree = 5
    enum_func = multivariateBasis.getEnumerateFunction()
    P = enum_func.getBasisSizeFromTotalDegree(totalDegree)
    print(f"P={P}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    P=126




.. GENERATED FROM PYTHON SOURCE LINES 64-66

We select the :class:`~openturns.FixedStrategy` truncation rule, which corresponds to using
the first `P` polynomials of the polynomial basis.

.. GENERATED FROM PYTHON SOURCE LINES 66-68

.. code-block:: default

    adaptiveStrategy = ot.FixedStrategy(multivariateBasis, P)








.. GENERATED FROM PYTHON SOURCE LINES 69-72

We begin by getting the standard measure associated with the multivariate polynomial basis.
We see that the range of the `Beta` distribution has been standardized into the [-1,1] interval.
This is the same for the `Uniform` distribution and the second `Beta` distribution.

.. GENERATED FROM PYTHON SOURCE LINES 72-75

.. code-block:: default

    measure = multivariateBasis.getMeasure()
    print(f"measure={measure}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    measure=ComposedDistribution(Beta(alpha = 0.9, beta = 3.5, a = -1, b = 1), LogNormal(muLog = 5.69881, sigmaLog = 0.0997513, gamma = 0), Uniform(a = -1, b = 1), Beta(alpha = 2.5, beta = 4, a = -1, b = 1), IndependentCopula(dimension = 4))




.. GENERATED FROM PYTHON SOURCE LINES 76-78

The choice of the :class:`~openturns.GaussProductExperiment` rule with 4 nodes
in each of the 4 dimensions leads to :math:`4^4=256` evaluations of the model.

.. GENERATED FROM PYTHON SOURCE LINES 78-84

.. code-block:: default

    marginalSizes = [4] * dim_input
    experiment = ot.GaussProductExperiment(distribution, marginalSizes)
    print(f"N={experiment.getSize()}")
    X, W = experiment.generateWithWeights()
    Y = g(X)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    N=256




.. GENERATED FROM PYTHON SOURCE LINES 85-86

We now set the method used to compute the coefficients; we select the integration method.

.. GENERATED FROM PYTHON SOURCE LINES 86-88

.. code-block:: default

    projectionStrategy = ot.IntegrationStrategy()








.. GENERATED FROM PYTHON SOURCE LINES 89-90

We can now create the functional chaos.

.. GENERATED FROM PYTHON SOURCE LINES 90-94

.. code-block:: default

    algo = ot.FunctionalChaosAlgorithm(X, W, Y, distribution,
                                       adaptiveStrategy, projectionStrategy)
    algo.run()








.. GENERATED FROM PYTHON SOURCE LINES 95-96

Get the result

.. GENERATED FROM PYTHON SOURCE LINES 96-98

.. code-block:: default

    result = algo.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 99-100

The :meth:`~openturns.FunctionalChaosResult.getMetaModel` method returns the metamodel function.

.. GENERATED FROM PYTHON SOURCE LINES 100-102

.. code-block:: default

    metamodel = result.getMetaModel()








.. GENERATED FROM PYTHON SOURCE LINES 103-105

Validate the metamodel
----------------------

.. GENERATED FROM PYTHON SOURCE LINES 107-108

Generate a new validation sample (which is independent of the training sample).

.. GENERATED FROM PYTHON SOURCE LINES 108-112

.. code-block:: default

    n_valid = 1000
    X_test = distribution.getSample(n_valid)
    Y_test = g(X_test)








.. GENERATED FROM PYTHON SOURCE LINES 113-115

The :class:`~openturns.MetaModelValidation` class validates the metamodel
based on a validation sample.

.. GENERATED FROM PYTHON SOURCE LINES 115-117

.. code-block:: default

    val = ot.MetaModelValidation(X_test, Y_test, metamodel)








.. GENERATED FROM PYTHON SOURCE LINES 118-119

Compute the :math:`Q^2` predictivity coefficient.

.. GENERATED FROM PYTHON SOURCE LINES 119-122

.. code-block:: default

    Q2 = val.computePredictivityFactor()[0]
    Q2





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    0.9999980369284825



.. GENERATED FROM PYTHON SOURCE LINES 123-124

Plot the observed versus the predicted outputs.

.. GENERATED FROM PYTHON SOURCE LINES 124-128

.. code-block:: default

    graph = val.drawValidation()
    graph.setTitle(f"Gauss product N={experiment.getSize()} - Q2={Q2*100:.2f}")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_001.png
   :alt: Gauss product N=256 - Q2=100.00
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 129-130

Now repeat the same process on various designs.

.. GENERATED FROM PYTHON SOURCE LINES 130-148

.. code-block:: default



    def draw_validation(experiment):
        projectionStrategy = ot.IntegrationStrategy(experiment)
        algo = ot.FunctionalChaosAlgorithm(
            g, distribution, adaptiveStrategy, projectionStrategy)
        algo.run()
        result = algo.getResult()
        metamodel = result.getMetaModel()
        X_test = distribution.getSample(n_valid)
        Y_test = g(X_test)
        val = ot.MetaModelValidation(X_test, Y_test, metamodel)
        Q2 = val.computePredictivityFactor()[0]
        graph = val.drawValidation()
        graph.setTitle(f"{experiment.__class__.__name__} - N={experiment.getSize()} - Q2={Q2*100:.2f}")
        return graph









.. GENERATED FROM PYTHON SOURCE LINES 149-150

Use an LHS design.

.. GENERATED FROM PYTHON SOURCE LINES 150-154

.. code-block:: default

    experiment = ot.LHSExperiment(distribution, int(1e6))
    graph = draw_validation(experiment)
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_002.png
   :alt: LHSExperiment - N=1000000 - Q2=99.28
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 155-156

Use a low-discrepancy experiment (Quasi-Monte Carlo).

.. GENERATED FROM PYTHON SOURCE LINES 156-163

.. code-block:: default

    sequence = ot.SobolSequence()
    experiment = ot.LowDiscrepancyExperiment(sequence, distribution, int(1e5))
    graph = draw_validation(experiment)
    view = otv.View(graph)

    otv.View.ShowAll()




.. image-sg:: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_003.png
   :alt: LowDiscrepancyExperiment - N=100000 - Q2=99.85
   :srcset: /auto_meta_modeling/polynomial_chaos_metamodel/images/sphx_glr_plot_chaos_cantilever_beam_integration_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 164-171

Conclusion
----------
With the Gauss product rule the coefficients are particularily well computed
since the Q2 coefficient is excellent, even with the relatively limited amount
of simulation (256 points).
On the other hand the LHS and low-discrepancy experiments require many more
points to achieve a Q2>99%.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  13.315 seconds)


.. _sphx_glr_download_auto_meta_modeling_polynomial_chaos_metamodel_plot_chaos_cantilever_beam_integration.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_chaos_cantilever_beam_integration.py <plot_chaos_cantilever_beam_integration.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_chaos_cantilever_beam_integration.ipynb <plot_chaos_cantilever_beam_integration.ipynb>`
