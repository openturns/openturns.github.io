<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Gaussian Process Regression: surrogate model with continuous and categorical variables &#8212; OpenTURNS 1.27dev documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="../../_static/openturns.css?v=105494d3" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=4652c2b6" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/sphx_glr.css?v=2ae27345" />
    <script src="../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../_static/documentation_options.js?v=c75cadd3"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=35a8b989"></script>
    <script src="../../_static/js/mysearchtools.js?v=40848abd"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fields surrogate models" href="../fields_surrogate_models/index.html" />
    <link rel="prev" title="Gaussian Process Regression: choose a polynomial trend" href="plot_gpr_choose_trend.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://github.com/openturns/openturns/wiki/Modules">Modules</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../fields_surrogate_models/index.html" title="Fields surrogate models"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_gpr_choose_trend.html" title="Gaussian Process Regression: choose a polynomial trend"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.27dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Surrogate modeling</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" accesskey="U">Gaussian Process Regression</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Gaussian Process Regression: surrogate model with continuous and categorical variables</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="plot_gpr_choose_trend.html"
                          title="previous chapter">Gaussian Process Regression: choose a polynomial trend</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="../fields_surrogate_models/index.html"
                          title="next chapter">Fields surrogate models</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/auto_surrogate_modeling/gaussian_process_regression/plot_gpr_categorical.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-surrogate-modeling-gaussian-process-regression-plot-gpr-categorical-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="gaussian-process-regression-surrogate-model-with-continuous-and-categorical-variables">
<span id="sphx-glr-auto-surrogate-modeling-gaussian-process-regression-plot-gpr-categorical-py"></span><h1>Gaussian Process Regression: surrogate model with continuous and categorical variables<a class="headerlink" href="#gaussian-process-regression-surrogate-model-with-continuous-and-categorical-variables" title="Link to this heading">Â¶</a></h1>
<p>We consider here the surrogate modeling of an analytical function characterized by
continuous and categorical variables</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">openturns</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ot</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Seed chosen in order to obtain a visually nice plot</span>
<span class="n">ot</span><span class="o">.</span><span class="n">RandomGenerator</span><span class="o">.</span><span class="n">SetSeed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>We first show the advantage of modeling the various levels of a mixed
continuous / categorical function through a single surrogate model
on a simple test-case taken from <a class="reference internal" href="../../bibliography.html#pelamatti2020" id="id1"><span>[pelamatti2020]</span></a>, defined below.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">illustrativeFunc</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">inp</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>


<span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">fun</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">PythonFunction</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">illustrativeFunc</span><span class="p">)</span>
<span class="n">numberOfZLevels</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Number of categorical levels for z</span>
<span class="c1"># Input distribution</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span>
    <span class="p">[</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">)))]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In this example, we compare the performances of the <a class="reference internal" href="../../user_manual/_generated/openturns.LatentVariableModel.html#openturns.LatentVariableModel" title="openturns.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a>
with a naive approach, which would consist in modeling each combination of categorical
variables through a separate and independent Gaussian process.</p>
<p>In order to deal with mixed continuous / categorical problems we can rely on the
<a class="reference internal" href="../../user_manual/_generated/openturns.ProductCovarianceModel.html#openturns.ProductCovarianceModel" title="openturns.ProductCovarianceModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProductCovarianceModel</span></code></a> class. We start here by defining the product kernel,
which combines <a class="reference internal" href="../../user_manual/_generated/openturns.SquaredExponential.html#openturns.SquaredExponential" title="openturns.SquaredExponential"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquaredExponential</span></code></a> kernels for the continuous variables, and
<a class="reference internal" href="../../user_manual/_generated/openturns.LatentVariableModel.html#openturns.LatentVariableModel" title="openturns.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a> for the categorical ones.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">latDim</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Dimension of the latent space</span>
<span class="n">activeCoord</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span>
    <span class="n">numberOfZLevels</span> <span class="o">-</span> <span class="mi">2</span>
<span class="p">)</span>  <span class="c1"># Nb of active coordinates in the latent space</span>
<span class="n">kx</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kz</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ProductCovarianceModel</span><span class="p">([</span><span class="n">kx</span><span class="p">,</span> <span class="n">kz</span><span class="p">])</span>
<span class="n">kLV</span><span class="o">.</span><span class="n">setNuggetFactor</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="c1"># Bounds for the hyperparameter optimization</span>
<span class="n">lowerBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">upperBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="c1"># Distribution for the hyperparameters initialization</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">)):</span>
    <span class="n">initDistLV</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span><span class="n">initDistLV</span><span class="p">)</span>
</pre></div>
</div>
<p>As a reference, we consider a purely continuous kernel for independent Gaussian processes.
One for each combination of categorical variables levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">kIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lowerBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span>
<span class="n">upperBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">20.0</span><span class="p">]</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">)):</span>
    <span class="n">initDistInd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span><span class="n">initDistInd</span><span class="p">)</span>
<span class="n">initSampleInd</span> <span class="o">=</span> <span class="n">initDistInd</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optAlgInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Cobyla</span><span class="p">(),</span> <span class="n">initSampleInd</span><span class="p">)</span>
</pre></div>
</div>
<p>Generate the training data set</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># And the plotting data set</span>
<span class="n">xPlt</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">xPlt</span> <span class="o">=</span> <span class="n">xPlt</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">yPlt</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">xPlt</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize  and parameterize the optimization algorithm</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">initSampleLV</span> <span class="o">=</span> <span class="n">initDistLV</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">optAlgLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Cobyla</span><span class="p">(),</span> <span class="n">initSampleLV</span><span class="p">)</span>
</pre></div>
</div>
<p>Create and train the Gaussian process models</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">fitterLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessFitter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kLV</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
<span class="n">fitterLV</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgLV</span><span class="p">)</span>
<span class="n">fitterLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">regressionLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">fitterLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">())</span>
<span class="n">regressionLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">resLV</span> <span class="o">=</span> <span class="n">regressionLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

<span class="n">resIndependentList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># Select the training samples corresponding to the correct combination</span>
    <span class="c1"># of categorical levels</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Create and train the Gaussian process models</span>
    <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">fitter_independent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessFitter</span><span class="p">(</span><span class="n">xLoc</span><span class="p">,</span> <span class="n">yLoc</span><span class="p">,</span> <span class="n">kIndependent</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
    <span class="n">fitter_independent</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgInd</span><span class="p">)</span>
    <span class="n">fitter_independent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">regression_independent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessRegression</span><span class="p">(</span>
        <span class="n">fitter_independent</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">regression_independent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">resIndependentList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">regression_independent</span><span class="o">.</span><span class="n">getResult</span><span class="p">())</span>
</pre></div>
</div>
<p>Plot the prediction of the mixed continuous / categorical GP,
as well as the one of the two separate continuous GPs</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax1</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax2</span></a><span class="p">)</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels</span><span class="p">):</span>
    <span class="c1"># Select the training samples corresponding to the correct combination</span>
    <span class="c1"># of categorical levels</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="c1"># Compute the models predictive performances on a validation data set.</span>
    <span class="c1"># The predictions are computed independently for each level of z,</span>
    <span class="c1"># i.e., by only considering the values of z corresponding to the</span>
    <span class="c1"># target level.</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xPlt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">xPltInd</span> <span class="o">=</span> <span class="n">xPlt</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="n">yPltInd</span> <span class="o">=</span> <span class="n">yPlt</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

    <span class="n">predMeanLV</span> <span class="o">=</span> <span class="n">resLV</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">()(</span><span class="n">xPltInd</span><span class="p">)</span>
    <span class="n">predMeanInd</span> <span class="o">=</span> <span class="n">resIndependentList</span><span class="p">[</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">()(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">cond_covLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessConditionalCovariance</span><span class="p">(</span><span class="n">resLV</span><span class="p">)</span>
    <span class="n">cond_independent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessConditionalCovariance</span><span class="p">(</span><span class="n">resIndependentList</span><span class="p">[</span><span class="n">z</span><span class="p">])</span>
    <span class="n">predSTDLV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cond_covLV</span><span class="o">.</span><span class="n">getConditionalMarginalVariance</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">))</span>
    <span class="n">predSTDInd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cond_independent</span><span class="o">.</span><span class="n">getConditionalMarginalVariance</span><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>

    <span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainingData</span></a><span class="p">,)</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xLoc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yLoc</span><span class="p">,</span> <span class="s2">&quot;r*&quot;</span><span class="p">)</span>
    <span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trueFunction</span></a><span class="p">,)</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yPltInd</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <span class="p">(</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">prediction</span></a><span class="p">,)</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">predMeanLV</span><span class="p">,</span> <span class="s2">&quot;b-&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/collections_api.html#matplotlib.collections.FillBetweenPolyCollection" title="matplotlib.collections.FillBetweenPolyCollection" class="sphx-glr-backref-module-matplotlib-collections sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stdPred</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.fill_between.html#matplotlib.axes.Axes.fill_between" title="matplotlib.axes.Axes.fill_between" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span></a><span class="p">(</span>
        <span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanLV</span> <span class="o">-</span> <span class="n">predSTDLV</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanLV</span> <span class="o">+</span> <span class="n">predSTDLV</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xLoc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yLoc</span><span class="p">,</span> <span class="s2">&quot;r*&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yPltInd</span><span class="p">,</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">predMeanInd</span><span class="p">,</span> <span class="s2">&quot;b-&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.fill_between.html#matplotlib.axes.Axes.fill_between" title="matplotlib.axes.Axes.fill_between" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span></a><span class="p">(</span>
        <span class="n">xPltInd</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanInd</span> <span class="o">-</span> <span class="n">predSTDInd</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="p">(</span><span class="n">predMeanInd</span> <span class="o">+</span> <span class="n">predSTDInd</span><span class="p">)</span><span class="o">.</span><span class="n">asPoint</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.legend.html#matplotlib.axes.Axes.legend" title="matplotlib.axes.Axes.legend" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">legend</span></a><span class="p">(</span>
    <span class="p">[</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainingData</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trueFunction</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D" title="matplotlib.lines.Line2D" class="sphx-glr-backref-module-matplotlib-lines sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">prediction</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/collections_api.html#matplotlib.collections.FillBetweenPolyCollection" title="matplotlib.collections.FillBetweenPolyCollection" class="sphx-glr-backref-module-matplotlib-collections sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stdPred</span></a><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Training data&quot;</span><span class="p">,</span> <span class="s2">&quot;True function&quot;</span><span class="p">,</span> <span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="s2">&quot;Prediction standard deviation&quot;</span><span class="p">],</span>
<span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s2">&quot;Mixed continuous-categorical modeling&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s2">&quot;Separate modeling&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_gpr_categorical_001.svg" srcset="../../_images/sphx_glr_plot_gpr_categorical_001.svg" alt="Mixed continuous-categorical modeling, Separate modeling" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Text(99.7171875, 0.5, &#39;y&#39;)
</pre></div>
</div>
<p>It can be seen that the joint modeling of categorical and continuous variables
improves the overall prediction accuracy, as the Gaussian process model is
able to exploit the information provided by the entire training data set.</p>
<p>We now consider a more complex function which is a modified version of the Goldstein function,
taken from <a class="reference internal" href="../../bibliography.html#pelamatti2020" id="id2"><span>[pelamatti2020]</span></a>. This function depends on 2 continuous variables and 2 categorical ones.
Each categorical variable is characterized by 3 levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">h</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mf">53.3108</span>
        <span class="o">+</span> <span class="mf">0.184901</span> <span class="o">*</span> <span class="n">x1</span>
        <span class="o">-</span> <span class="mf">5.02914</span> <span class="o">*</span> <span class="n">x1</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">7.72522</span> <span class="o">*</span> <span class="n">x1</span><span class="o">**</span><span class="mi">4</span> <span class="o">*</span> <span class="mf">1e-8</span>
        <span class="o">-</span> <span class="mf">0.0870775</span> <span class="o">*</span> <span class="n">x2</span>
        <span class="o">-</span> <span class="mf">0.106959</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">+</span> <span class="mf">7.98772</span> <span class="o">*</span> <span class="n">x3</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">0.00242482</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">1.32851</span> <span class="o">*</span> <span class="n">x4</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="mf">1e-6</span> <span class="o">*</span> <span class="mf">0.00146393</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span>
        <span class="o">-</span> <span class="mf">0.00301588</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">-</span> <span class="mf">0.00272291</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">0.0017004</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span>
        <span class="o">+</span> <span class="mf">0.0038428</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">-</span> <span class="mf">0.000198969</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span>
        <span class="o">+</span> <span class="mf">1.86025</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="mf">1e-5</span>
        <span class="o">-</span> <span class="mf">1.88719</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-6</span>
        <span class="o">+</span> <span class="mf">2.50923</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-5</span>
        <span class="o">-</span> <span class="mf">5.62199</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">*</span> <span class="n">x4</span> <span class="o">*</span> <span class="mf">1e-5</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span><span class="w"> </span><span class="nf">Goldstein</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">z1</span><span class="p">,</span> <span class="n">z2</span> <span class="o">=</span> <span class="n">inp</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">x2</span>

    <span class="k">if</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="k">elif</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="k">elif</span> <span class="n">z1</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error, no matching category z1&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="k">elif</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="k">elif</span> <span class="n">z2</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x4</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;error, no matching category z2&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">h</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">)]</span>


<span class="n">dim</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">fun</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">PythonFunction</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Goldstein</span><span class="p">)</span>
<span class="n">numberOfZLevels1</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Number of categorical levels for z1</span>
<span class="n">numberOfZLevels2</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Number of categorical levels for z2</span>
<span class="c1"># Input distribution</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">))),</span>
        <span class="n">ot</span><span class="o">.</span><span class="n">UserDefined</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">))),</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>As in the previous example, we start here by defining the product kernel,
which combines <a class="reference internal" href="../../user_manual/_generated/openturns.SquaredExponential.html#openturns.SquaredExponential" title="openturns.SquaredExponential"><code class="xref py py-class docutils literal notranslate"><span class="pre">SquaredExponential</span></code></a> kernels for the continuous variables, and
<a class="reference internal" href="../../user_manual/_generated/openturns.LatentVariableModel.html#openturns.LatentVariableModel" title="openturns.LatentVariableModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableModel</span></code></a> for the categorical ones.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">latDim</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Dimension of the latent space</span>
<span class="n">activeCoord</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">2</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span><span class="n">numberOfZLevels1</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">latDim</span> <span class="o">*</span> <span class="p">(</span><span class="n">numberOfZLevels2</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># Nb ative coordinates in the latent space</span>
<span class="n">kx1</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kx2</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kz1</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kz2</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">LatentVariableModel</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">,</span> <span class="n">latDim</span><span class="p">)</span>
<span class="n">kLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ProductCovarianceModel</span><span class="p">([</span><span class="n">kx1</span><span class="p">,</span> <span class="n">kx2</span><span class="p">,</span> <span class="n">kz1</span><span class="p">,</span> <span class="n">kz2</span><span class="p">])</span>
<span class="n">kLV</span><span class="o">.</span><span class="n">setNuggetFactor</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="c1"># Bounds for the hyperparameter optimization</span>
<span class="n">lowerBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="n">upperBoundLV</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="mf">10.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">activeCoord</span>
<span class="c1"># Distribution for the hyperparameters initialization</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">)):</span>
    <span class="n">initDistLV</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundLV</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span><span class="n">initDistLV</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, we consider a purely continuous kernel for independent Gaussian processes.
one for each combination of categorical variables levels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">kIndependent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">lowerBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">]</span>
<span class="n">upperBoundInd</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">DistributionCollection</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">)):</span>
    <span class="n">initDistInd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lowerBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">upperBoundInd</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">initDistInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">JointDistribution</span><span class="p">(</span><span class="n">initDistInd</span><span class="p">)</span>
<span class="n">initSampleInd</span> <span class="o">=</span> <span class="n">initDistInd</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">optAlgInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Cobyla</span><span class="p">(),</span> <span class="n">initSampleInd</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to assess their respective robustness with regards to the training data set,
we repeat the experiments 3 times with different training of size 72,
and compute each time the normalized prediction Root Mean Squared Error (RMSE) on a
test data set of size 1000.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">rmseLVList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">rmseIndList</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="c1"># Generate the normalized training data set</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">72</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">yMax</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">getMax</span><span class="p">()</span>
    <span class="n">yMin</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">getMin</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yMin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">yMin</span> <span class="o">-</span> <span class="n">yMax</span><span class="p">)</span>

    <span class="c1"># Initialize and parameterize the optimization algorithm</span>
    <span class="n">initSampleLV</span> <span class="o">=</span> <span class="n">initDistLV</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">optAlgLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MultiStart</span><span class="p">(</span><span class="n">ot</span><span class="o">.</span><span class="n">Cobyla</span><span class="p">(),</span> <span class="n">initSampleLV</span><span class="p">)</span>

    <span class="c1"># Create and train the Gaussian process models</span>
    <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">fitterLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessFitter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kLV</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
    <span class="n">fitterLV</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgLV</span><span class="p">)</span>
    <span class="n">fitterLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">regressionLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessRegression</span><span class="p">(</span><span class="n">fitterLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">())</span>
    <span class="n">regressionLV</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="n">resLV</span> <span class="o">=</span> <span class="n">regressionLV</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

    <span class="c1"># Compute the models predictive performances on a validation data set</span>
    <span class="n">xVal</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">yVal</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">xVal</span><span class="p">)</span>
    <span class="n">yVal</span> <span class="o">=</span> <span class="p">(</span><span class="n">yVal</span> <span class="o">-</span> <span class="n">yMin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">yMin</span> <span class="o">-</span> <span class="n">yMax</span><span class="p">)</span>

    <span class="n">valLV</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MetaModelValidation</span><span class="p">(</span><span class="n">yVal</span><span class="p">,</span> <span class="n">resLV</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">()(</span><span class="n">xVal</span><span class="p">))</span>
    <span class="n">rmseLV</span> <span class="o">=</span> <span class="n">valLV</span><span class="o">.</span><span class="n">getResidualSample</span><span class="p">()</span><span class="o">.</span><span class="n">computeStandardDeviation</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rmseLVList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmseLV</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">z1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">z2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numberOfZLevels2</span><span class="p">):</span>
            <span class="c1"># Select the training samples corresponding to the correct combination</span>
            <span class="c1"># of categorical levels</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span> <span class="o">==</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">xLoc</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">yLoc</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>

            <span class="c1"># Create and train the Gaussian process models</span>
            <span class="n">basis</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">ConstantBasisFactory</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="n">fitter_independent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessFitter</span><span class="p">(</span>
                <span class="n">xLoc</span><span class="p">,</span> <span class="n">yLoc</span><span class="p">,</span> <span class="n">kIndependent</span><span class="p">,</span> <span class="n">basis</span>
            <span class="p">)</span>
            <span class="n">fitter_independent</span><span class="o">.</span><span class="n">setOptimizationAlgorithm</span><span class="p">(</span><span class="n">optAlgInd</span><span class="p">)</span>
            <span class="n">fitter_independent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="n">regression_independent</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">GaussianProcessRegression</span><span class="p">(</span>
                <span class="n">fitter_independent</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">regression_independent</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="n">resInd</span> <span class="o">=</span> <span class="n">regression_independent</span><span class="o">.</span><span class="n">getResult</span><span class="p">()</span>

            <span class="c1"># Compute the models predictive performances on a validation data set</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xVal</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span> <span class="o">==</span> <span class="p">[</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">xValInd</span> <span class="o">=</span> <span class="n">xVal</span><span class="p">[</span><span class="n">ind</span><span class="p">][:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">yValInd</span> <span class="o">=</span> <span class="n">yVal</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
            <span class="n">valInd</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">MetaModelValidation</span><span class="p">(</span><span class="n">yValInd</span><span class="p">,</span> <span class="n">resInd</span><span class="o">.</span><span class="n">getMetaModel</span><span class="p">()(</span><span class="n">xValInd</span><span class="p">))</span>
            <span class="n">error</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">valInd</span><span class="o">.</span><span class="n">getResidualSample</span><span class="p">())</span>
    <span class="n">rmseInd</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">computeStandardDeviation</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rmseIndList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmseInd</span><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">()</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html#matplotlib.pyplot.boxplot" title="matplotlib.pyplot.boxplot" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span></a><span class="p">([</span><span class="n">rmseLVList</span><span class="p">,</span> <span class="n">rmseIndList</span><span class="p">])</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xticks.html#matplotlib.pyplot.xticks" title="matplotlib.pyplot.xticks" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span></a><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Mixed continuous-categorical GP&quot;</span><span class="p">,</span> <span class="s2">&quot;Independent GPs&quot;</span><span class="p">])</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel" title="matplotlib.pyplot.ylabel" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span></a><span class="p">(</span><span class="s2">&quot;RMSE&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_gpr_categorical_002.svg" srcset="../../_images/sphx_glr_plot_gpr_categorical_002.svg" alt="plot gpr categorical" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Text(24.334375, 0.5, &#39;RMSE&#39;)
</pre></div>
</div>
<p>The obtained results show, for this test-case, a better modeling performance
when modeling the function as a mixed categorical/continuous function, rather
than relying on multiple purely continuous Gaussian processes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-surrogate-modeling-gaussian-process-regression-plot-gpr-categorical-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/080704bdf764c923e5f6a5a5d053a542/plot_gpr_categorical.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_gpr_categorical.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a3574b07a53e1165d20b824397ffb74d/plot_gpr_categorical.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_gpr_categorical.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/6a6d8602c255611f09d0380601b62623/plot_gpr_categorical.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_gpr_categorical.zip</span></code></a></p>
</div>
</div>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../fields_surrogate_models/index.html" title="Fields surrogate models"
             >next</a> |</li>
        <li class="right" >
          <a href="plot_gpr_choose_trend.html" title="Gaussian Process Regression: choose a polynomial trend"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.27dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Surrogate modeling</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" >Gaussian Process Regression</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Gaussian Process Regression: surrogate model with continuous and categorical variables</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2005-2026 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Jan 01, 2022.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    </div>
  </body>
</html>