
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Low Discrepancy Sequence &#8212; OpenTURNS 1.14dev documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Design of Experiments" href="design_experiment.html" />
    <link rel="prev" title="Reliability, sensitivity" href="reliability_sensitivity.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="design_experiment.html" title="Design of Experiments"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="reliability_sensitivity.html" title="Reliability, sensitivity"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.14dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="reliability_sensitivity.html" accesskey="U">Reliability, sensitivity</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="reliability_sensitivity.html"
                        title="previous chapter">Reliability, sensitivity</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="design_experiment.html"
                        title="next chapter">Design of Experiments</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/reliability_sensitivity/low_discrepancy_sequence.rst"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="low-discrepancy-sequence">
<span id="id1"></span><h1>Low Discrepancy Sequence<a class="headerlink" href="#low-discrepancy-sequence" title="Permalink to this headline">¶</a></h1>
<div class="line-block">
<div class="line">A low-discrepancy sequence is a sequence with the property that for
all values of <img class="math" src="../../_images/math/6bed8a44f63e1eb8e61608a5c93374a505943eec.svg" alt="N" style="vertical-align: 0px"/>, its subsequence <img class="math" src="../../_images/math/8d4e8ca44ed212649407b5b0098d96340a9dfd5f.svg" alt="(x_1, \hdots, x_N)" style="vertical-align: -4px"/>
has a low discrepancy.</div>
<div class="line">The discrepancy of a sequence is low if the number of points in the
sequence falling into an arbitrary set B is close to proportional to
the measure of B, as would happen on average (but not for particular
samples) in the case of a uniform distribution. Specific definitions
of discrepancy differ regarding the choice of B (hyperspheres,
hypercubes, etc.) and how the discrepancy for every B is computed
(usually normalized) and combined (usually by taking the worst value).</div>
<div class="line">Low-discrepancy sequences are also called quasi-random or sub-random
sequences, due to their common use as a replacement of uniformly
distributed random numbers. The “quasi” modifier is used to denote
more clearly that the values of a low-discrepancy sequence are neither
random nor pseudorandom, but such sequences share some properties of
random variables and in certain applications such as the quasi-Monte
Carlo method their lower discrepancy is an important advantage.</div>
</div>
<p>At least three methods of numerical integration can be phrased as
follows. Given a set <img class="math" src="../../_images/math/c27f9fb9adbf2a35dc096f8576a4988a18b2fcbd.svg" alt="\{x_1, \hdots, x_N\}" style="vertical-align: -4px"/> in the interval [0,1],
approximate the integral of a function f as the average of the function
evaluated at those points:</p>
<div class="math">
<p><img src="../../_images/math/d71a4178ba718595d2ee8341071f2a0a25d2f26f.svg" alt="\begin{aligned}
    \int_0^1 f(u)\,du \approx \frac{1}{N}\,\sum_{i=1}^N f(x_i).
  \end{aligned}"/></p>
</div><ul class="simple">
<li><p>If the points are chosen as <img class="math" src="../../_images/math/4f2a31a650495e4f5c66d96f05fbc144a5358c8c.svg" alt="x_i = i/N" style="vertical-align: -4px"/>, this is the rectangle
rule.</p></li>
<li><p>If the points are chosen to be randomly distributed, this is the
Monte Carlo method.</p></li>
<li><p>If the points are chosen as elements of a low-discrepancy sequence,
this is the quasi-Monte Carlo method.</p></li>
</ul>
<p>The <strong>discrepancy</strong> of a set <img class="math" src="../../_images/math/546fa4ca47eb9d1f2f5822df56d18e8ae777743b.svg" alt="P = \{x_1, \hdots, x_N\}" style="vertical-align: -4px"/> is
defined, using Niederreiter’s notation, as</p>
<div class="math">
<p><img src="../../_images/math/a17ae9b9d6f0ee9ab03c73816355c8918305b55d.svg" alt="\begin{aligned}
    D_N(P) = \sup_{B\in J} \left| \frac{A(B;P)}{N} - \lambda_s(B) \right|
  \end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/e8f3d9771f95a4c228bfae91753c6a482ce1082b.svg" alt="\lambda-s" style="vertical-align: -1px"/> is the s-dimensional Lebesgue measure,
<img class="math" src="../../_images/math/2347c050d0fcdde7002eaa562377c463d85bd609.svg" alt="A(B;P)" style="vertical-align: -4px"/> is the number of points in <img class="math" src="../../_images/math/451a3d9a99f2dcc2293b7b30519b42cf46cb38ac.svg" alt="P" style="vertical-align: 0px"/> that fall into
<img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B" style="vertical-align: 0px"/>, and <img class="math" src="../../_images/math/d071d98281e6567114c0cdedc83b8b308820f3c8.svg" alt="J" style="vertical-align: 0px"/> is the set of s-dimensional intervals or boxes
of the form:</p>
<div class="math">
<p><img src="../../_images/math/f0639c2d0455dda10f9dd4e037591def57acbaf3.svg" alt="\begin{aligned}
    \prod_{i=1}^s [a_i, b_i) = \{ \mathbf{x} \in \mathbf{R}^s : a_i \le x_i &lt; b_i \} \,
  \end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/40b768e9fcf7d3e1beec504459b9390c7858b413.svg" alt="0 \le a_i &lt; b_i \le 1" style="vertical-align: -2px"/> .</p>
<p>The star-discrepancy D*N(P) is defined similarly, except that the
supremum is taken over the set J* of intervals of the form</p>
<div class="math">
<p><img src="../../_images/math/a2dfdf58a987e909267ee0212b70358665ae528d.svg" alt="\begin{aligned}
    \prod_{i=1}^s [0, u_i)
  \end{aligned}"/></p>
</div><p>where <img class="math" src="../../_images/math/2c73ef2a5ee8bd64dcdd341cb771c487c507beee.svg" alt="u_i" style="vertical-align: -2px"/> is in the half-open interval <img class="math" src="../../_images/math/a559ad9ec4faa48e1fe3034946bcea7069927654.svg" alt="[0, 1)" style="vertical-align: -4px"/>.</p>
<p>The two are related by</p>
<div class="math">
<p><img src="../../_images/math/84cf956fc39d3513309c9bc217eea02cc8337fca.svg" alt="\begin{aligned}
      D^*_N \le D_N \le 2^s D^*_N . \,
    \end{aligned}"/></p>
</div><div class="line-block">
<div class="line">The <strong>Koksma-lawka inequality</strong>, shows that the error of such a method
can be bounded by the product of two terms, one of which depends only
on f, and the other one is the discrepancy of the set
<img class="math" src="../../_images/math/c27f9fb9adbf2a35dc096f8576a4988a18b2fcbd.svg" alt="\{x_1, \hdots, x_N\}" style="vertical-align: -4px"/>.</div>
<div class="line">Let <img class="math" src="../../_images/math/47cb4383f31b8432aa715988bd42b74353194c4b.svg" alt="\bar I^s" style="vertical-align: 0px"/> be the s-dimensional unit cube,
<img class="math" src="../../_images/math/9620a0262dc28e92bc722dbb1ba42198cb6cc7fb.svg" alt="\bar I^s = [0, 1] \times ... \times [0, 1]" style="vertical-align: -4px"/>. Let <img class="math" src="../../_images/math/51916a9aa71f574e1426044f0bc2d637b6160cde.svg" alt="f" style="vertical-align: -3px"/> have
bounded variation <img class="math" src="../../_images/math/f6fbeb685dd837a7f2ff3b2c504330ea669664a9.svg" alt="V(f)" style="vertical-align: -4px"/> on <img class="math" src="../../_images/math/b2e92ad74313f86bc8f587a3a2f25fab76a7bc76.svg" alt="I^s" style="vertical-align: 0px"/> in the sense of Hardy
and Krause. Then for any <img class="math" src="../../_images/math/8d4e8ca44ed212649407b5b0098d96340a9dfd5f.svg" alt="(x_1, \hdots, x_N)" style="vertical-align: -4px"/> in
<img class="math" src="../../_images/math/01199f3c5f730add1d6800dbd94d2fe928cf9662.svg" alt="I^s = [0, 1) \times ... \times [0, 1)" style="vertical-align: -4px"/>,</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/a4a2c563d7305d1d04ca49bc0b1d56909ba01b09.svg" alt="\begin{aligned}
          \left| \frac{1}{N} \sum_{i=1}^N f(x_i) - \int_{\bar I^s} f(u)\,du \right| \le V(f)\, D_N^* (x_1,\ldots,x_N).
        \end{aligned}"/></p>
</div></div></blockquote>
<p>The Koksma-Hlawka inequality is sharp in the following sense: For any
point set <img class="math" src="../../_images/math/c27f9fb9adbf2a35dc096f8576a4988a18b2fcbd.svg" alt="\{x_1, \hdots, x_N\}" style="vertical-align: -4px"/> in <img class="math" src="../../_images/math/b2e92ad74313f86bc8f587a3a2f25fab76a7bc76.svg" alt="I^s" style="vertical-align: 0px"/> and any
<img class="math" src="../../_images/math/b589caa12c3b7bfc1d071b3c096f0688ff16642f.svg" alt="\varepsilon &gt;0" style="vertical-align: 0px"/> &gt; 0, there is a function <img class="math" src="../../_images/math/51916a9aa71f574e1426044f0bc2d637b6160cde.svg" alt="f" style="vertical-align: -3px"/> with bounded
variation and <img class="math" src="../../_images/math/09326cbb31e89463b44f8489361a94298435fa48.svg" alt="V(f)=1" style="vertical-align: -4px"/> such that:</p>
<div class="math">
<p><img src="../../_images/math/c1af4da80c6743f2ea25d4956e7636b2395af153.svg" alt="\begin{aligned}
          \left| \frac{1}{N} \sum_{i=1}^N f(x_i) - \int_{\bar I^s} f(u)\,du \right|&gt;D_{N}^{*}(x_1,\ldots,x_N)-\varepsilon.
        \end{aligned}"/></p>
</div><p>Therefore, the quality of a numerical integration rule depends only on
the discrepancy <img class="math" src="../../_images/math/e1a681190f014ffb8350c1a11c2af9df813cc7d7.svg" alt="D^*_N(x_1,\hdots,x_N)" style="vertical-align: -4px"/>.</p>
<div class="line-block">
<div class="line">Constructions of sequence are known, due to Faure, Halton, Hammersley,
Sobol’, Niederreiter and van der Corput, such that:</div>
</div>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/d0b9348b2a8b9a98bbda48c3bee23fa9944e2941.svg" alt="\begin{aligned}
          D_{N}^{*}(x_1,\ldots,x_N)\leq C\frac{(\ln N)^{s}}{N}.
        \end{aligned}"/></p>
</div></div></blockquote>
<p>where <img class="math" src="../../_images/math/3b3be2405d41848960032b917a9b3d6e64e3ea81.svg" alt="C" style="vertical-align: 0px"/> is a certain constant, depending on the sequence.
These sequences are believed to have the best possible order of
convergence. See also: van der Corput sequence, Halton sequences,
Sobol sequences. In the case of the Haselgrove sequence, we have:</p>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/9cfad9b627e83dbbf7a6db03b26cea1a9cdc55f0.svg" alt="\begin{aligned}
          \forall \varepsilon&gt;0,\exists C_{\varepsilon}&gt;0\mbox{ such that }D_{N}^{*}(x_1,\ldots,x_N)\leq \frac{C_{\varepsilon}}{N^{1-\varepsilon}}.
        \end{aligned}"/></p>
</div></div></blockquote>
<p>which means a worse asymptotic performance than the previous
sequence, but can be interesting for finite sample size.</p>
<p><strong>Remark 1</strong>:</p>
<div class="line-block">
<div class="line">If <img class="math" src="../../_images/math/c27f9fb9adbf2a35dc096f8576a4988a18b2fcbd.svg" alt="\{x_1, \hdots, x_N\}" style="vertical-align: -4px"/> is a low-discrepancy sequence, then
<img class="math" src="../../_images/math/8c22ffd64799967ede513b37dc04f8442224dc7a.svg" alt="\displaystyle \frac{1}{N} \sum_{i=1}^{N} \delta_{x_i}" style="vertical-align: -19px"/>
converges weakly towards <img class="math" src="../../_images/math/857a8f9675de801acd1eace7fb8ded4fdd317612.svg" alt="\lambda^s" style="vertical-align: 0px"/> the <img class="math" src="../../_images/math/29350e76247bfe6a307c4a905d5a756c0cd41091.svg" alt="s" style="vertical-align: 0px"/>-dimensional
Lebesgue measure on <img class="math" src="../../_images/math/8c489cd432be3769615f66328090792d684cf3be.svg" alt="[0,1]^s" style="vertical-align: -4px"/>, which garanties that for all test
function (continuous and bounded) <img class="math" src="../../_images/math/6d353192a782c86b102a50240f5691b8b7cb88a3.svg" alt="\phi" style="vertical-align: -3px"/>,
<img class="math" src="../../_images/math/1195ce85b25eab2e928709cde8bf122a56b0e4dd.svg" alt="\displaystyle &lt;\frac{1}{N} \sum_{i=1}^{N} \delta_{x_i},\phi&gt;" style="vertical-align: -19px"/>
converges towards <img class="math" src="../../_images/math/4cdfb1fda6f54dc34384b7f0567db8f5b3747d6c.svg" alt="&lt;\lambda^s, \phi&gt; = \int \phi \, d\lambda^s" style="vertical-align: -5px"/>.</div>
</div>
<p>We then obtain:</p>
<blockquote>
<div><div class="math">
<p><img src="../../_images/math/c2c25e99df6424f84896d9b9dbb8cd0f61ddae85.svg" alt="\begin{aligned}
  \displaystyle \frac{1}{N} \sum_{i=1}^{N} \phi(x_i) \longrightarrow \int \phi \, dx
\end{aligned}"/></p>
</div></div></blockquote>
<p>Be careful: using low discrepancy sequences instead of random
distributed points do not lead to the same control of the variance of
the approximation: in the case of random distributed points, this
control is given by the Central Limit Theorem that provides confidence
intervals. In the case of low discrepancy sequences, it is given by
the Koksma-Hlawka inequality.</p>
<p><strong>Remark 2</strong>:</p>
<div class="line-block">
<div class="line">It is possible to generate low discrepancy sequence according to
measures different from the Lebesgue one, by using the inverse CDF
technique. But be careful: the inverse CDF technique
is not the one used in all the cases (some distributions are generated
thanks to the rejection method for example): that’s why it is not
recommended, in the general case, to substitute a low discrepancy
sequence to the uniform random generator.</div>
</div>
<p><strong>Remark 3</strong>:</p>
<div class="line-block">
<div class="line">The low-discrepancy sequences have performances that deteriorate
rapidly with the problem dimension, as the bound on the discrepancy
increases exponentially with the dimension. This behaviour is shared
by all the low discrepancy sequences, even if all the standard
low-discrepancy sequences don’t exhibit this behaviour with the same
intensity. According to the given reference, the following
recommandation can be made:</div>
</div>
<ul class="simple">
<li><p>The Sobol can be used for dimensions up to several hundreds (but
our implementation of the Sobol sequence is limited to
dimension less or equal to 40).</p></li>
<li><p>The Halton or reverse Halton sequences should preferably not be used for dimensions greater than 8;</p></li>
<li><p>The Faure sequences should preferably not be used for dimensions greater than 25;</p></li>
<li><p>Use Haselgrove sequences should preferably not be used for dimensions greater than 50;</p></li>
</ul>
<p>Low-discrepancy sequences are also called quasi-random or sub-random
sequences, but it can be confusing as they are deterministic and that
they don’t have the same statistical properties as traditional
pseudo-random sequences.</p>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../user_manual/designs_of_experiments.html#low-discrepancy-sequence-api"><span class="std std-ref">low discrepancy sequences</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../examples/reliability_sensitivity/low_discrepancy_sequence.html"><span class="doc">Generate low discrepancy sequences</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li><p>Inna Krykova, <em>Evaluating of path-dependent securities with low discrepancy methods</em>, Master of Science Thesis, Worcester Polytechnic Institute, 2003.</p></li>
<li><p>Wikipedia contributors, <em>Low-discrepancy sequence.</em>, Wikipedia, The Free Encyclopedia, 10 April 2012, 17:48 UTC, <a class="reference external" href="https://en.wikipedia.org/wiki/Low-discrepancy_sequence">https://en.wikipedia.org/wiki/Low-discrepancy_sequence</a></p></li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="design_experiment.html" title="Design of Experiments"
             >next</a> |</li>
        <li class="right" >
          <a href="reliability_sensitivity.html" title="Reliability, sensitivity"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.14dev documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="reliability_sensitivity.html" >Reliability, sensitivity</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2018 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Jan 01, 2018.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.0+/cfda47921.
    </div>
  </body>
</html>