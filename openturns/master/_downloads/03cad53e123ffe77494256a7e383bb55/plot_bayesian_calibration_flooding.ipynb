{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bayesian calibration of the flooding model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract\n\nThe goal of this example is to present the Bayesian calibration of the\n`flooding model<use-case-flood-model>`.\nWe use the :class:`~openturns.RandomWalkMetropolisHastings` and\n:class:`~openturns.Gibbs` classes\nand simulate a sample of the posterior distribution using\n`metropolis_hastings`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters to calibrate\n\nThe vector of parameters to calibrate is:\n\n\\begin{align}\\vect{\\theta} = (K_s,Z_v,Z_m).\\end{align}\n\n\nThe reference values are:\n\n\\begin{align}K_s = 30, \\qquad Z_v = 50, \\qquad Z_m = 55.\\end{align}\n\n\n## Observations\n\nWe consider the probabilistic model:\n\n\\begin{align}H =  \\model(Q,K_s,Z_v,Z_m) + \\epsilon\\end{align}\n\nwhere:\n\n\\begin{align}\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\\end{align}\n\nThus, the error of the water height follows a normal distribution with a zero mean and a standard variation $\\sigma$.\n\nWe have some observations $\\{(Q_i,h_i)\\}_{i=1,...,\\sampleSize}$. Each observation is a couple made of the flowrate\nand the corresponding river height. We assume that the observations are associated to independent errors.\nWe consider a sample size equal to:\n\n\\begin{align}\\sampleSize = 10.\\end{align}\n\n\n## Variables\n\n- $Q$ : Input. Observed.\n- $K_s$, $Z_v$, $Z_m$ : Input. Calibrated.\n- $h$: Output. Observed.\n\n## Analysis\n\nIn the description of the `flooding model<use-case-flood-model>`, we see that only one parameter\ncan be identified.\nHence, calibrating this model requires some regularization.\nIn this example, we use Bayesian methods as a way to regularize the model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate the observations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nfrom openturns.usecases import flood_model\nimport openturns.viewer as otv\nimport numpy as np\nimport openturns as ot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A basic implementation of the probabilistic model is available in the usecases module :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fm = flood_model.FloodModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the model $\\model$ which has 4 inputs and one output $h$.\n\nThe non linear least squares algorithm does not take into account bounds in the parameters.\nTherefore, we ensure that the output is computed whatever the inputs.\nThe model fails into two situations:\n\n* if $K_s<0$,\n* if $Z_v-Z_m<0$.\n\nIn these cases, we return an infinite number.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def functionFlooding(X):\n    L = 5.0e3\n    B = 300.0\n    Q, K_s, Z_v, Z_m = X\n    alpha = (Z_m - Z_v) / L\n    if alpha < 0.0 or K_s <= 0.0:\n        H = np.inf\n    else:\n        H = (Q / (K_s * B * np.sqrt(alpha))) ** (3.0 / 5.0)\n    return [H]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = ot.PythonFunction(4, 1, functionFlooding)\ng = ot.MemoizeFunction(g)\ng.setOutputDescription([\"H (m)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the input distribution for the flow $Q$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Q = fm.Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the parameters to be calibrated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "K_s = ot.Dirac(30.0)\nZ_v = ot.Dirac(50.0)\nZ_m = ot.Dirac(55.0)\nK_s.setDescription([\"Ks (m^(1/3)/s)\"])\nZ_v.setDescription([\"Zv (m)\"])\nZ_m.setDescription([\"Zm (m)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the joint input distribution of $(Q, K_s, Z_v, Z_m)$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inputRandomVector = ot.JointDistribution([Q, K_s, Z_v, Z_m])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We import some noisy observations of the flow rate (column 0) and the height (column 1) already\nstored of the  `flooding model<use-case-flood-model>` in the field *data*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Q_H_obs = fm.data\nQobs = Q_H_obs.getMarginal(0)\nHobs = Q_H_obs.getMarginal(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = ot.Graph(\"Observations\", \"Q (m3/s)\", \"h (m)\", True)\ncloud = ot.Cloud(Q_H_obs)\n# cloud = ot.Cloud(Qobs, Hobs)\ngraph.add(cloud)\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting the calibration parameters\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We assume that the output of the model $H$ is random and follows a normal distribution with the standard\ndeviation $\\sigma = 0.5$ and centered on $\\mu = \\model(Q, K_s, Z_v, Z_m)$.\n\nThen, we define the parametric model $\\vect z = f_Q(\\vect\\theta)$ that associates each observation\n$Q$ and value of the parameters $\\vect \\theta = (K_s, Z_v, Z_m)$\nto the parameters $\\vect z=(\\mu, \\sigma)$.\nWe want to get the posterior distribution of the random vector $\\vect \\Theta$ that fits the best to the\nobservations $(Q_i, h_i)_i$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def fullModelPy(X):\n    Q, K_s, Z_v, Z_m = X\n    mu = g(X)[0]\n    sigma = 0.5  # (m^2) The standard deviation of the observation error.\n    return [mu, sigma]\n\n\nfullModel = ot.PythonFunction(4, 2, fullModelPy)\nlinkFunction = ot.ParametricFunction(fullModel, [0], [np.nan])\nprint(linkFunction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the prior distribution of  $\\vect\\Theta$. We assume that it is a normal distribution.\nIn the Bayesian framework, this is called the *prior* normal distribution. In the data assimilation framework, this\nis called the *background*.\nWe assume that the prior distribution has independent components, that the mean marginal values are equal to the reference values\nand that the marginal standard deviations are known.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "KsInitial = 20.0\nZvInitial = 49.0\nZmInitial = 51.0\nparameterPriorMean = [KsInitial, ZvInitial, ZmInitial]\nparamDim = len(parameterPriorMean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigmaKs = 5.0\nsigmaZv = 1.0\nsigmaZm = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameterPriorCovariance = ot.CovarianceMatrix(paramDim)\nparameterPriorCovariance[0, 0] = sigmaKs**2\nparameterPriorCovariance[1, 1] = sigmaZv**2\nparameterPriorCovariance[2, 2] = sigmaZm**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the prior distribution of $\\vect\\Theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prior = ot.Normal(parameterPriorMean, parameterPriorCovariance)\nprior.setDescription([\"Ks\", \"Zv\", \"Zm\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the distribution of the output $H | \\vect{z}$ conditional on model predictions.\nNote that its parameter dimension is the one of $\\vect{z}$, so the model must be adjusted accordingly.\nIn other words, the input argument of the `setParameter` method of the conditional distribution must be equal to the dimension of the output of the `model`.\nHence, we do not have to set the actual parameters: only the type of distribution is used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conditional = ot.Normal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The proposed steps for $K_s$ $Z_v$ and $Z_m$\nwill all follow uniform distributions,\nbut with different supports.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "proposal = [ot.Uniform(-5.0, 5.0), ot.Uniform(-1.0, 1.0), ot.Uniform(-1.0, 1.0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a Gibbs sampler\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "initialState = parameterPriorMean\nmh_coll = [\n    ot.RandomWalkMetropolisHastings(prior, initialState, proposal[i], [i])\n    for i in range(paramDim)\n]\nfor mh in mh_coll:\n    mh.setLikelihood(conditional, Hobs, linkFunction, Qobs)\nsampler = ot.Gibbs(mh_coll)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a sample from the posterior distribution of $\\vect \\Theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize = 1000\nsample = sampler.getSample(sampleSize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at the acceptance rates of the random walk Metropolis-Hastings samplers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "[mh.getAcceptanceRate() for mh in sampler.getMetropolisHastingsCollection()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the posterior distribution of $\\vect \\Theta$ by kernel smoothing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel = ot.KernelSmoothing()\nposterior = kernel.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display prior vs posterior for each parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_bayesian_prior_vs_posterior_pdf(prior, posterior):\n    \"\"\"\n    Plot the prior and posterior distribution of a Bayesian calibration\n\n    Parameters\n    ----------\n    prior : ot.Distribution(dimension)\n        The prior.\n    posterior : ot.Distribution(dimension)\n        The posterior.\n\n    Return\n    ------\n    grid : ot.GridLayout(1, dimension)\n        The prior and posterior PDF for each marginal.\n    \"\"\"\n    paramDim = prior.getDimension()\n    grid = ot.GridLayout(1, paramDim)\n    parameterNames = prior.getDescription()\n    for parameter_index in range(paramDim):\n        graph = ot.Graph(\"\", parameterNames[parameter_index], \"PDF\", True)\n        # Prior\n        curve = prior.getMarginal(parameter_index).drawPDF().getDrawable(0)\n        curve.setLineStyle(\n            ot.ResourceMap.GetAsString(\"CalibrationResult-PriorLineStyle\")\n        )\n        curve.setLegend(\"Prior\")\n        graph.add(curve)\n        # Posterior\n        curve = posterior.getMarginal(parameter_index).drawPDF().getDrawable(0)\n        curve.setLineStyle(\n            ot.ResourceMap.GetAsString(\"CalibrationResult-PosteriorLineStyle\")\n        )\n        curve.setLegend(\"Posterior\")\n        graph.add(curve)\n        #\n        if parameter_index < paramDim - 1:\n            graph.setLegends([\"\"])\n        if parameter_index > 0:\n            graph.setYTitle(\"\")\n        graph.setLegendPosition(\"upper right\")\n        grid.setGraph(0, parameter_index, graph)\n    grid.setTitle(\"Bayesian calibration\")\n    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sphinx_gallery_thumbnail_number = 2\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = plot_bayesian_prior_vs_posterior_pdf(prior, posterior)\notv.View(\n    grid,\n    figure_kw={\"figsize\": (8.0, 3.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.8, bottom=0.2, wspace=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}