{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gaussian Process Regression : cantilever beam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we create a Gaussian Process Regression (GPR) metamodel of the `cantilever beam <use-case-cantilever-beam>`.\nWe use a squared exponential covariance kernel for the Gaussian process. In order to estimate the hyper-parameters, we use a design of experiments of size 20.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from openturns.usecases import cantilever_beam\nimport openturns as ot\nimport openturns.experimental as otexp\nimport openturns.viewer as viewer\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of the model\n\nWe load the cantilever beam use case :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cb = cantilever_beam.CantileverBeam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the function which evaluates the output depending on the inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = cb.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the distribution of the input random vector.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "myDistribution = cb.distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the design of experiments\n\nWe consider a simple Monte-Carlo sample as a design of experiments.\nThis is why we generate an input sample using the method :meth:`~openturns.Distribution.getSample` of the\ndistribution. Then we evaluate the output using the `model` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_train = 20\nX_train = myDistribution.getSample(sampleSize_train)\nY_train = model(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following figure presents the distribution of the vertical deviations Y on the training sample. We observe that the large deviations occur less often.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "histo = ot.HistogramFactory().build(Y_train).drawPDF()\nhisto.setXTitle(\"Vertical deviation (cm)\")\nhisto.setTitle(\"Distribution of the vertical deviation\")\nhisto.setLegends([\"\"])\nview = viewer.View(histo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the metamodel\n\nIn order to create the GPR metamodel, we first select a constant trend with the :class:`~openturns.ConstantBasisFactory` class. Then we use a squared exponential covariance kernel.\nThe :class:`~openturns.SquaredExponential` kernel has one amplitude coefficient and 4 scale coefficients.\nThis is because this covariance kernel is anisotropic : each of the 4 input variables is associated with its own scale coefficient.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basis = ot.ConstantBasisFactory(cb.dim).build()\ncovarianceModel = ot.SquaredExponential(cb.dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Typically, the optimization algorithm is quite good at setting sensible optimization bounds.\nIn this case, however, the range of the input domain is extreme.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Lower and upper bounds of X_train:\")\nprint(X_train.getMin(), X_train.getMax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to manually define sensible optimization bounds.\nNote that since the amplitude parameter is computed analytically (this is possible when the output dimension is 1), we only need to set bounds on the scale parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scaleOptimizationBounds = ot.Interval(\n    [1.0, 1.0, 1.0, 1.0e-10], [1.0e11, 1.0e3, 1.0e1, 1.0e-5]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use the :class:`~openturns.experimental.GaussianProcessFitter` and `GaussianProcessRegression` classes to create the GPR metamodel.\nIt requires a training sample, a covariance kernel and a trend basis as input arguments.\nWe need to set the initial scale parameter for the optimization. The upper bound of the input domain is a sensible choice here.\nWe must not forget to actually set the optimization bounds defined above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covarianceModel.setScale(X_train.getMax())\nfitter_algo = otexp.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nfitter_algo.setOptimizationBounds(scaleOptimizationBounds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method :meth:`~openturns.experimental.GaussianProcessFitter.run`  of\nthe class :class:`~openturns.experimental.GaussianProcessFitter.run` optimizes the Gaussian process\nhyperparameters and the method :meth:`~openturns.experimental.GaussianProcessRegression.run` of the class\n:class:`~openturns.experimental.GaussianProcessRegression` conditions the\nGaussian process to the data set.\n\nWe can then print the constant trend of the metamodel, estimated using the least squares method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fitter_algo.run()\nfitter_result = fitter_algo.getResult()\ngpr_algo = otexp.GaussianProcessRegression(fitter_result)\ngpr_algo.run()\ngpr_result = gpr_algo.getResult()\ngprMetamodel = gpr_result.getMetaModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method :meth:`~openturns.experimental.GaussianProcessRegressionResult.getTrendCoefficients` of\nthe class\n:class:`~openturns.experimental.GaussianProcessRegressionResult` returns the coefficients of the trend.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gpr_result.getTrendCoefficients())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the hyperparameters of the covariance model, which have been estimated by maximizing the likelihood.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gpr_result.getCovarianceModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate the metamodel\n\nWe finally want to validate the GPR metamodel. This is why we generate a validation sample with size 100 and we evaluate the output of the model on this sample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_test = 100\nX_test = myDistribution.getSample(sampleSize_test)\nY_test = model(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The class :class:`~openturns.MetaModelValidation`  makes the validation easy. To create it, we use the validation samples and the metamodel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "val = ot.MetaModelValidation(Y_test, gprMetamodel(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method :meth:`~openturns.MetaModelValidation.computeR2Score` computes the R2 score.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "R2 = val.computeR2Score()[0]\nprint(R2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The residuals are the difference between the model and the metamodel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r = val.getResidualSample()\ngraph = ot.HistogramFactory().build(r).drawPDF()\ngraph.setXTitle(\"Residuals (cm)\")\ngraph.setTitle(\"Distribution of the residuals\")\ngraph.setLegends([\"\"])\nview = viewer.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the negative residuals occur with nearly the same frequency of the positive residuals: this is a first sign of good quality.\nThe method :meth:`~openturns.MetaModelValidation.drawValidation` compares the observed outputs and the metamodel outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = val.drawValidation()\ngraph.setTitle(\"R2 = %.2f%%\" % (100 * R2))\nview = viewer.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display all figures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "viewer.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}