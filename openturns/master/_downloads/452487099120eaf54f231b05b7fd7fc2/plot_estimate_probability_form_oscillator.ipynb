{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using the FORM - SORM algorithms on a nonlinear function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we estimate a failure probability with the `FORM` and `SORM` algorithms on the `oscillator <use-case-oscillator>` example.\nThis test-case is highly non linear with a significant curvature near the design point.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model definition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from openturns.usecases import oscillator\nimport openturns as ot\nfrom matplotlib import pylab as plt\nimport numpy as np\n\not.Log.Show(ot.Log.NONE)\not.RandomGenerator.SetSeed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the model from the usecases module:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "osc = oscillator.Oscillator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the input parameters distribution from the data class:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distribution = osc.distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = osc.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the event whose probability we want to estimate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vect = ot.RandomVector(distribution)\nG = ot.CompositeRandomVector(model, vect)\nevent = ot.ThresholdEvent(G, ot.Less(), 0.0)\nevent.setName(\"failure\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross cuts in the physical space\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s have a look on 2D cross cuts of the limit state function. For each 2D cross cut, the other variables are fixed to the input distribution mean values.\nThis graph allows one to have a first idea of the variations of the function in pairs of dimensions. The colors of each contour plot are comparable.\nThe number of contour levels are related to the amount of variation of the function in the corresponding coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 12))\nlowerBound = [1e-5] * 8\nupperBound = distribution.getRange().getUpperBound()\n\n# Definition of number of meshes in x and y axes for the 2D cross cut plots\nnX = 50\nnY = 50\nfor i in range(distribution.getDimension()):\n    for j in range(i):\n        crossCutIndices = []\n        crossCutReferencePoint = []\n        for k in range(distribution.getDimension()):\n            if k != i and k != j:\n                crossCutIndices.append(k)\n                # Definition of the reference point\n                crossCutReferencePoint.append(distribution.getMean()[k])\n        # Definition of 2D cross cut function\n        crossCutFunction = ot.ParametricFunction(\n            model, crossCutIndices, crossCutReferencePoint\n        )\n        crossCutLowerBound = [lowerBound[j], lowerBound[i]]\n        crossCutUpperBound = [upperBound[j], upperBound[i]]\n        # Definition of the mesh\n        inputData = ot.Box([nX, nY]).generate()\n        inputData *= ot.Point(crossCutUpperBound) - ot.Point(crossCutLowerBound)\n        inputData += ot.Point(crossCutLowerBound)\n        meshX = np.array(inputData)[:, 0].reshape(nX + 2, nY + 2)\n        meshY = np.array(inputData)[:, 1].reshape(nX + 2, nY + 2)\n        data = crossCutFunction(inputData)\n        meshZ = np.array(data).reshape(nX + 2, nY + 2)\n        levels = [(150 + 3 * i) for i in range(101)]\n\n        # Creation of the contour\n        index = 1 + i * distribution.getDimension() + j\n\n        ax = fig.add_subplot(\n            distribution.getDimension(), distribution.getDimension(), index\n        )\n        ax.pcolormesh(meshX, meshY, meshZ, cmap=\"hsv\", vmin=-5, vmax=50, shading=\"auto\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        # Creation of axes title\n        if j == 0:\n            ax.set_ylabel(distribution.getDescription()[i])\n        if i == 7:\n            ax.set_xlabel(distribution.getDescription()[j])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computation of reference probability with Monte-Carlo simulation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The target probability is supposed to be extremely low ($3.78\\times 10^{-7}$).\nIndeed, when performing Monte-Carlo simulation with a simulation budget of 100000 points, no sample are in the failure state, that induces a probability estimate of zero.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "experiment = ot.MonteCarloExperiment()\nalgo = ot.ProbabilitySimulationAlgorithm(event, experiment)\nalgo.setMaximumOuterSampling(int(1e5))\nalgo.run()\n\nresult = algo.getResult()\nprobability = result.getProbabilityEstimate()\nprint(\"Failure probability = \", probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get an accurate estimate of this probability, a billion of simulations are necessary.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FORM Analysis\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a first idea of the failure probability with reduced simulation budget, one can use the First Order Reliability Method (FORM).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a solver:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimAlgo = ot.Cobyla()\noptimAlgo.setStartingPoint(distribution.getMean())\noptimAlgo.setMaximumCallsNumber(1000)\noptimAlgo.setMaximumAbsoluteError(1.0e-3)\noptimAlgo.setMaximumRelativeError(1.0e-3)\noptimAlgo.setMaximumResidualError(1.0e-3)\noptimAlgo.setMaximumConstraintError(1.0e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run FORM initialized at the mean of the distribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.FORM(optimAlgo, event)\nalgo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probability of failure:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"FORM estimate of the probability of failure: \", result.getEventProbability())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Design point in the standard space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "designPointStandardSpace = result.getStandardSpaceDesignPoint()\nprint(\"Design point in standard space : \", designPointStandardSpace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Design point in the physical space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Design point in physical space : \", result.getPhysicalSpaceDesignPoint())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this test case, in order to validate the results obtained by FORM, we can plot the cross cuts in the standard space near the design point found by FORM.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distributionStandard = ot.Normal(distribution.getDimension())\ninverseIsoProbabilistic = distribution.getInverseIsoProbabilisticTransformation()\nstandardSpaceLimitState = ot.ComposedFunction(model, inverseIsoProbabilistic)\nstandardSpaceLimitStateFunction = ot.PythonFunction(8, 1, standardSpaceLimitState)\n\nfig = plt.figure(figsize=(12, 12))\nlowerBound = [-4] * 8\nupperBound = [4] * 8\n\n# sphinx_gallery_thumbnail_number = 2\n\n# Definition of number of meshes in x and y axes for the 2D cross cut plots\nnX = 50\nnY = 50\nmy_labels = {\n    \"MPP\": \"Design Point\",\n    \"O\": \"Origin in Standard Space\",\n    \"TLSF\": \"True Limit State Function\",\n    \"ALSF\": \"Approximated Limit State Function\",\n}\nfor i in range(distribution.getDimension()):\n    for j in range(i):\n        crossCutIndices = []\n        crossCutReferencePoint = []\n        for k in range(distribution.getDimension()):\n            if k != i and k != j:\n                crossCutIndices.append(k)\n                # Definition of the reference point\n                crossCutReferencePoint.append(designPointStandardSpace[k])\n        # Definition of 2D cross cut function\n        crossCutFunction = ot.ParametricFunction(\n            standardSpaceLimitStateFunction, crossCutIndices, crossCutReferencePoint\n        )\n\n        crossCutLowerBound = [\n            lowerBound[j] + designPointStandardSpace[j],\n            lowerBound[i] + designPointStandardSpace[i],\n        ]\n        crossCutUpperBound = [\n            upperBound[j] + designPointStandardSpace[j],\n            upperBound[i] + designPointStandardSpace[i],\n        ]\n        # Definition of the mesh\n        inputData = ot.Box([nX, nY]).generate()\n        inputData *= ot.Point(crossCutUpperBound) - ot.Point(crossCutLowerBound)\n        inputData += ot.Point(crossCutLowerBound)\n        meshX = np.array(inputData)[:, 0].reshape(nX + 2, nY + 2)\n        meshY = np.array(inputData)[:, 1].reshape(nX + 2, nY + 2)\n        data = crossCutFunction(inputData)\n        meshZ = np.array(data).reshape(nX + 2, nY + 2)\n        levels = [(150 + 3 * i) for i in range(101)]\n\n        # Creation of the contour\n        index = 1 + i * distribution.getDimension() + j\n\n        ax = fig.add_subplot(\n            distribution.getDimension(), distribution.getDimension(), index\n        )\n\n        graph = ot.Graph()\n\n        ax.pcolormesh(meshX, meshY, meshZ, cmap=\"hsv\", vmin=-5, vmax=50, shading=\"auto\")\n\n        cs0 = ax.plot(\n            designPointStandardSpace[j],\n            designPointStandardSpace[i],\n            \"o\",\n            label=my_labels[\"MPP\"],\n        )\n        cs1 = ax.plot(0.0, 0.0, \"rs\", label=my_labels[\"O\"])\n        cs2 = ax.contour(meshX, meshY, meshZ, [0.0])\n\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n        u0 = [designPointStandardSpace[j], designPointStandardSpace[i]]\n        algo = ot.LinearTaylor(u0, crossCutFunction)\n        algo.run()\n        responseSurface = algo.getMetaModel()\n        data2 = responseSurface(inputData)\n        meshZ2 = np.array(data2).reshape(nX + 2, nY + 2)\n\n        cs3 = ax.contour(meshX, meshY, meshZ2, [0.0], linestyles=\"dotted\")\n\n        # Creation of axes title\n        if j == 0:\n            ax.set_ylabel(distribution.getDescription()[i])\n        if i == 7:\n            ax.set_xlabel(distribution.getDescription()[j])\n\n        if i == 1 and j == 0:\n            h2, l2 = cs2.legend_elements()\n            h3, l3 = cs3.legend_elements()\n            lg = ax.legend(\n                [h2[0], h3[0]],\n                [my_labels[\"TLSF\"], my_labels[\"ALSF\"]],\n                frameon=False,\n                loc=\"upper center\",\n                bbox_to_anchor=(8, -1.5),\n            )\n        elif i == 2 and j == 0:\n            lg1 = ax.legend(\n                frameon=False, loc=\"upper center\", bbox_to_anchor=(7.65, -0.8)\n            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As it can be seen, the curvature of the limit state function near the design point is significant.\nIn that way, FORM provides poor estimate since it linearly approximates the limit state function.\nThus, SORM can be used in order to refine this probability estimation by approximating the limit state function with a quadratic model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SORM Analysis\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run SORM initialized at the mean of the distribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver = ot.Cobyla()\nsolver.setStartingPoint(distribution.getMean())\nalgoSORM = ot.SORM(solver, event)\nalgoSORM.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analysis of SORM results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resultSORM = algoSORM.getResult()\nprint(\n    \"Probability estimate with SORM (Breitung correction) =\",\n    resultSORM.getEventProbabilityBreitung(),\n)\n\nprint(\n    \"Probability estimate with SORM (Hohenbichler correction) =\",\n    resultSORM.getEventProbabilityHohenbichler(),\n)\n\noptim_res = resultSORM.getOptimizationResult()\nprint(\"Simulation budget:\", optim_res.getCallsNumber())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can see that the probability estimate has been decreased by a factor 10 compared to the FORM estimate.\nThis probability is quite close to the reference probability and obtained with less than 1000 evaluations of the model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to visualize the SORM limit state approximation, we can draw cross cuts of SORM oscultating parabola using second order Taylor approximation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 12))\nlowerBound = [-4] * 8\nupperBound = [4] * 8\n\n# Definition of number of meshes in x and y axes for the 2D cross cut plots\nnX = 50\nnY = 50\n\nmy_labels = {\n    \"MPP\": \"Design Point\",\n    \"O\": \"Origin in Standard Space\",\n    \"TLSF\": \"True Limit State Function\",\n    \"ALSF\": \"Approximated Limit State Function\",\n}\n\nfor i in range(distribution.getDimension()):\n    for j in range(i):\n        crossCutIndices = []\n        crossCutReferencePoint = []\n        for k in range(distribution.getDimension()):\n            if k != i and k != j:\n                crossCutIndices.append(k)\n                # Definition of the reference point\n                crossCutReferencePoint.append(designPointStandardSpace[k])\n        # Definition of 2D cross cut function\n        crossCutFunction = ot.ParametricFunction(\n            standardSpaceLimitStateFunction, crossCutIndices, crossCutReferencePoint\n        )\n\n        crossCutLowerBound = [\n            lowerBound[j] + designPointStandardSpace[j],\n            lowerBound[i] + designPointStandardSpace[i],\n        ]\n        crossCutUpperBound = [\n            upperBound[j] + designPointStandardSpace[j],\n            upperBound[i] + designPointStandardSpace[i],\n        ]\n        # Definition of the mesh\n        inputData = ot.Box([nX, nY]).generate()\n        inputData *= ot.Point(crossCutUpperBound) - ot.Point(crossCutLowerBound)\n        inputData += ot.Point(crossCutLowerBound)\n        meshX = np.array(inputData)[:, 0].reshape(nX + 2, nY + 2)\n        meshY = np.array(inputData)[:, 1].reshape(nX + 2, nY + 2)\n        data = crossCutFunction(inputData)\n        meshZ = np.array(data).reshape(nX + 2, nY + 2)\n        levels = [(150 + 3 * i) for i in range(101)]\n\n        # Creation of the contour\n        index = 1 + i * distribution.getDimension() + j\n\n        ax = fig.add_subplot(\n            distribution.getDimension(), distribution.getDimension(), index\n        )\n\n        graph = ot.Graph()\n        ax.pcolormesh(meshX, meshY, meshZ, cmap=\"hsv\", vmin=-5, vmax=50, shading=\"auto\")\n        cs0 = ax.plot(\n            designPointStandardSpace[j],\n            designPointStandardSpace[i],\n            \"o\",\n            label=my_labels[\"MPP\"],\n        )\n        cs1 = ax.plot(0.0, 0.0, \"rs\", label=my_labels[\"O\"])\n        cs2 = ax.contour(meshX, meshY, meshZ, [0.0])\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n        u0 = [designPointStandardSpace[j], designPointStandardSpace[i]]\n        algo = ot.QuadraticTaylor(u0, crossCutFunction)\n        algo.run()\n        responseSurface = algo.getMetaModel()\n        data2 = responseSurface(inputData)\n        meshZ2 = np.array(data2).reshape(nX + 2, nY + 2)\n        cs3 = ax.contour(meshX, meshY, meshZ2, [0.0], linestyles=\"dotted\")\n\n        # Creation of axes title\n        if j == 0:\n            ax.set_ylabel(distribution.getDescription()[i])\n        if i == 7:\n            ax.set_xlabel(distribution.getDescription()[j])\n\n        if i == 1 and j == 0:\n            h2, l2 = cs2.legend_elements()\n            h3, l3 = cs3.legend_elements()\n            lg = ax.legend(\n                [h2[0], h3[0]],\n                [my_labels[\"TLSF\"], my_labels[\"ALSF\"]],\n                frameon=False,\n                loc=\"upper center\",\n                bbox_to_anchor=(8, -1.5),\n            )\n        elif i == 2 and j == 0:\n            lg1 = ax.legend(\n                frameon=False, loc=\"upper center\", bbox_to_anchor=(7.65, -0.8)\n            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that this approximation is very appropriate, explaining the accuracy of the obtained results.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimation with post analytical Importance Sampling\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Different algorithms exist for the reliability analysis by Importance Sampling.\nOne way is to perform post analytical Importance Sampling by defining the auxiliary density centered at the design point found by FORM.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "postAnalyticalIS = ot.PostAnalyticalImportanceSampling(result)\npostAnalyticalIS.setMaximumCoefficientOfVariation(0.05)\npostAnalyticalIS.run()\nresultPostAnalyticalIS = postAnalyticalIS.getResult()\nprint(\n    \"Probability of failure with post analytical IS = \",\n    resultPostAnalyticalIS.getProbabilityEstimate(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that this post-treatment of FORM result allows one to greatly improve the quality of the probability estimation.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}