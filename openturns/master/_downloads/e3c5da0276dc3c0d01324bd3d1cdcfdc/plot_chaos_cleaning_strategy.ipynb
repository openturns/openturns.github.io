{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Create a sparse chaos by integration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this example is to show how to create a sparse polynomial chaos\nexpansion (PCE) when we estimate its coefficients by integration. We show\nhow to use the :class:`~openturns.CleaningStrategy` class.\n\n## Polynomial chaos expansion\n\nLet $g : \\mathcal{X} \\rightarrow \\mathbb{R}$ be a function\nwhere $\\mathcal{X} \\subseteq \\mathbb{R}^p$ is the domain of $g$.\nLet $f$ be a probability density function on $\\mathcal{X}$.\nLet $T$ be the iso-probabilistic transformation from the physical\nspace $\\mathcal{X}$ to the standard space $\\mathcal{\\bar{X}}$:\n\n\\begin{align}\\xi = T(\\boldsymbol{x}) \\in \\mathcal{\\bar{X}}\\end{align}\n\nfor any $\\boldsymbol{x} \\in \\mathcal{X}$.\nLet $h$ be the function defined by the equation :\n\n\\begin{align}h(\\boldsymbol{\\xi}) = \\left(g \\circ T^{-1}\\right)(\\boldsymbol{\\xi})\\end{align}\n\nfor any $\\boldsymbol{\\xi} \\in \\mathcal{\\bar{X}}$.\nThe polynomial chaos decomposition of $h$ is ([blatman2009]_ page 73) :\n\n\\begin{align}h(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{\\alpha} \\in \\mathbb{N}^p}\n  a_{\\boldsymbol{\\alpha}} \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) + \\epsilon\\end{align}\n\nwhere $\\boldsymbol{\\alpha} = (\\alpha_1, ..., \\alpha_p) \\in \\mathbb{N}^p$\nis a multiindex, $a_{\\boldsymbol{\\alpha}} \\in \\mathbb{R}$ is the\ncoefficient,  $\\psi_{\\boldsymbol{\\alpha}} : \\mathcal{\\bar{X}} \\rightarrow \\mathbb{R}$\nis a multivariate polynomial and $\\epsilon$ is a random variable.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Truncated expansion\nIn practice, we cannot consider an infinite series and must truncate\nthe decomposition at a given order. Only a selection of coefficients must\nbe kept. This leads to a subset of all possible multiindices. In the\nremainder of this text, we call this selection the *multiindex set*.\n\nSeveral multiindex sets can be considered. A simple method is to truncate\nthe polynomial up to a given maximum total degree $d \\in \\mathbb{N}$.\nLet $\\mathcal{A}^{d}$ be the multi-index set defined by\n\n\\begin{align}\\mathcal{A}^{d} = \\left\\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}^p\n  \\; | \\; \\|\\boldsymbol{\\alpha}\\|_1 \\leq d\\right\\}\\end{align}\n\nwhere\n\n\\begin{align}\\|\\boldsymbol{\\alpha}\\|_d = \\alpha_1 + ... + \\alpha_p\\end{align}\n\nis the 1-norm of the multi-index $\\boldsymbol{\\alpha}$.\nTherefore, the truncated polynomial chaos expansion is:\n\n\\begin{align}h(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}^{d}}\n  a_{\\boldsymbol{\\alpha}} \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) + \\epsilon.\\end{align}\n\nIn order to ensure a low error, we may choose a large value of the\nparameter $P$. This, however, leads to a large number of\ncoefficients $\\boldsymbol{\\alpha} \\in \\mathcal{A}^{d}$ to\nestimate. More precisely, the number of coefficients to estimate\nis ([blatman2009]_ page 73) :\n\n\\begin{align}\\textrm{card}\\left(\\mathcal{A}^{d}\\right) = {p + d \\choose d}\n  = \\frac{(p + d)!}{p! d!}\\end{align}\n\nwhere $p!$ is the factorial number of $p$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Low-rank polynomial chaos expansion\nFor any $\\boldsymbol{\\alpha} \\in \\mathbb{N}^p$, let\n$\\|\\boldsymbol{\\alpha}\\|_0$ be the rank of the multiindex, that is,\nthe number of nonzero components:\n\n\\begin{align}\\|\\boldsymbol{\\alpha}\\|_0 = \\sum_{i = 1}^p \\boldsymbol{1}_{\\alpha_i > 0}\\end{align}\n\nwhere $\\boldsymbol{1}$ is the indicator function.\nThe multiindex set of maximum total degree $d \\in \\mathbb{N}$\nand maximum rank $j \\in \\mathbb{N}$ is ([blatman2009]_ page 74):\n\n\\begin{align}\\mathcal{A}^{d,j} = \\left\\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}^p\n  \\; | \\; \\|\\boldsymbol{\\alpha}\\|_1 \\leq d, \\;\n  \\; \\|\\boldsymbol{\\alpha}\\|_0 \\leq j\\right\\}.\\end{align}\n\nTherefore, the rank-`j` polynomial chaos expansion is:\n\n\\begin{align}h(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{\\alpha} \\in\n  \\mathcal{A}^{d,j}} a_{\\boldsymbol{\\alpha}}\n  \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) + \\epsilon.\\end{align}\n\nThe rank is now a hyperparameter of the model: [blatman2009]_ suggests\nto use $j = 2, 3, 4$. An example of low-rank PCE for the G-Sobol'\nfunction is given in [blatman2009]_ page 75.\n\n*Note.* It is currently not possible to create a low-rank PCE.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model selection\nIf $\\textrm{card}\\left(\\mathcal{A}^{d}\\right)$ is large, many coefficients\nmay be poorly estimated, which may reduce the quality of the metamodel. We may\nwant to select a subset of the coefficients which best predict the output.\nIn other words, we may compute a subset\n\n\\begin{align}\\mathcal{A} \\subseteq \\mathcal{A}^{d}\\end{align}\n\nsuch that ([blatman2009]_ page 86) :\n\n\\begin{align}h(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}}\n  a_{\\boldsymbol{\\alpha}} \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\n  + \\epsilon.\\end{align}\n\nAn enumeration rule is a function from the set of integers $k$ to\nthe corresponding set of multiindices $\\boldsymbol{\\alpha}$. More\nprecisely, let $r : \\mathbb{N} \\rightarrow \\mathbb{N}^p$ be the\nfunction such that :\n\n\\begin{align}r(k) = \\boldsymbol{\\alpha}\\end{align}\n\nfor any $k \\geq 0$.\nLet $K \\in \\mathbb{N}$ be a parameter representing the number of\ncoefficients considered in the selection. Given an enumeration rule for\nthe multiindices $\\boldsymbol{\\alpha}$, at most $K$ multiindices\nwill be considered. Let $\\mathcal{A}_K$ be the corresponding multiindex set :\n\n\\begin{align}\\mathcal{A}_K = \\left\\{ \\boldsymbol{\\alpha}\n  \\; | \\; r^{-1}(\\boldsymbol{\\alpha}) = k \\leq K \\right\\}.\\end{align}\n\n\nLet $\\epsilon > 0$ be a parameter representing the minimum relative\nvalue of a significant coefficient $a_{\\boldsymbol{\\alpha}}$.\nThe :class:`~openturns.CleaningStrategy` uses the following criteria to select the coefficients :\n\n\\begin{align}\\mathcal{A}_\\epsilon =\n  \\left\\{\n  |a_{\\boldsymbol{\\alpha}}| \\geq \\epsilon \\max_{ a_{\\boldsymbol{\\alpha}}\n  \\in \\mathcal{A}_K } |a_{\\boldsymbol{\\alpha}}| \\right\\}\\end{align}\n\nwhere $\\epsilon$ is the significance factor, which by default is\n$\\epsilon = 10^{-4}$. This rule selects only the coefficients which\nare significantly different from zero.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sparsity index\nThe sparsity index of a multiindex set is the ratio of the cardinality of\nthe multiindex set to the cardinality of the multiindex set of the\nequivalent multiindex with maximum total degree. For a given multiindex\nset $\\mathcal{A}$, let $d$ be the maximum 1-norm of multiindices\nin the set :\n\n\\begin{align}d := \\textrm{max}_{\\boldsymbol{\\alpha} \\in \\mathcal{A}}\n  \\|\\boldsymbol{\\alpha}\\|_1.\\end{align}\n\nThe index of sparsity of $\\mathcal{A}$ is ([blatman2009]_  eq. 4.42 page 86) :\n\n\\begin{align}\\textrm{IS}(\\mathcal{A})\n  = \\frac{\\textrm{card}(\\mathcal{A})}{\\textrm{card}\\left(\\mathcal{A}^d\\right)}.\\end{align}\n\n\n*Note.* The index of sparsity as defined by [blatman2009]_ is close to zero when\nthe model is very sparse. The following complementary indicator is close\nto 1 when the model is very sparse:\n\n\\begin{align}\\textrm{IS}_{\\textrm{c}}(\\mathcal{A})\n  = 1 - \\frac{\\textrm{card}(\\mathcal{A})}{\\textrm{card}\\left(\\mathcal{A}^d\\right)}.\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as otv\nfrom openturns.usecases import ishigami_function\nimport itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function takes a polynomial chaos result as input and prints a\ngiven maximum number of coefficients of this polynomial. It can take into account\na threshold, so that we can avoid to print coefficients which are very close to zero.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def printCoefficientsTable(\n    polynomialChaosResult, maximum_number_of_printed_coefficients=10, threshold=0.0\n):\n    \"\"\"\n    Print the coefficients of the polynomial chaos.\n\n    Parameters\n    ----------\n    polynomialChaosResult : ot.FunctionalChaosResult\n        The polynomial chaos expansion.\n    maximum_number_of_printed_coefficients : int\n        The maximum number of printed coefficients.\n    threshold : float, strictly positive\n        If a coefficient has an absolute value strictly greater than the\n        threshold, it is printed.\n    \"\"\"\n    basis = polynomialChaosResult.getOrthogonalBasis()\n    coefficients = polynomialChaosResult.getCoefficients()\n    enumerate_function = basis.getEnumerateFunction()\n    indices = polynomialChaosResult.getIndices()\n    nbcoeffs = indices.getSize()\n    print(\"Total number of coefficients : \", nbcoeffs)\n    print(\"# Indice, Multi-indice, Degree : Value\")\n    print_index = 0\n    for k in range(nbcoeffs):\n        multiindex = enumerate_function(indices[k])\n        degree = sum(multiindex)\n        c = coefficients[k][0]\n        if abs(c) > threshold:\n            print(\"#%d, %s (%s) : %s\" % (k, multiindex, degree, c))\n            print_index += 1\n        if print_index > maximum_number_of_printed_coefficients:\n            break\n    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next function computes the polynomial chaos Q2 score using simple validation\non a test sample generated by Monte-Carlo sampling. The actual computation\nis performed by the :class:`~openturns.MetaModelValidation` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_polynomial_chaos_Q2(\n    polynomialchaos_result, g_function, input_distribution, n_valid=1000\n):\n    \"\"\"\n    Compute the Q2 score of the polynomial chaos.\n\n\n    Parameters\n    ----------\n    polynomialChaosResult : ot.FunctionalChaosResult\n        The polynomial chaos expansion.\n    g_function : ot.Function\n        The function.\n    input_distribution : ot.Distribution\n        The input distribution.\n    n_valid : int\n        The number of simulations to compute the Q2 score.\n\n    Returns\n    -------\n    Q2 : float\n        The Q2 score\n    \"\"\"\n    ot.RandomGenerator.SetSeed(1976)\n    metamodel = polynomialchaos_result.getMetaModel()\n    inputTest = input_distribution.getSample(n_valid)\n    outputTest = g_function(inputTest)\n    val = ot.MetaModelValidation(inputTest, outputTest, metamodel)\n    Q2 = val.computePredictivityFactor()[0]\n    return Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function creates a validation plot using the\n:meth:`~openturns.MetaModelValidation.drawValidation` method\nof the `MetaModelValidation` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def draw_polynomial_chaos_validation(\n    polynomialchaos_result, g_function, input_distribution, n_valid=1000\n):\n    \"\"\"\n    Validate the polynomial chaos.\n\n    Create the validation plot.\n\n\n    Parameters\n    ----------\n    polynomialChaosResult : ot.FunctionalChaosResult\n        The polynomial chaos expansion.\n    g_function : ot.Function\n        The function.\n    input_distribution : ot.Distribution\n        The input distribution.\n    n_valid : int\n        The number of simulations to compute the Q2 score.\n\n    Returns\n    -------\n    Q2 : float\n        The Q2 score\n    \"\"\"\n    metamodel = polynomialchaos_result.getMetaModel()\n    inputTest = input_distribution.getSample(n_valid)\n    outputTest = g_function(inputTest)\n    val = ot.MetaModelValidation(inputTest, outputTest, metamodel)\n    Q2 = val.computePredictivityFactor()[0]\n    graph = val.drawValidation()\n    graph.setTitle(\"Q2=%.2f%%\" % (Q2 * 100))\n    view = otv.View(graph, figure_kw={\"figsize\": (5.0, 4.0)})\n    return view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider the Ishigami model.\nIts three inputs are i.i.d. random variables that follow the uniform distribution on the\n$[-\\pi, \\pi]$ interval. This is an interesting example for our\npurpose because it is highly non linear, so that a high polynomial degree\nwill be required in order to produce a polynomial chaos expansion with Q2\nscore sufficiently close to 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "im = ishigami_function.IshigamiModel()\n\nim.distributionX.setDescription([\"`X_0`\", \"`X_1`\", \"`X_2`\"])\nim.model.setOutputDescription([\"`Y`\"])\nprint(im.distributionX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create the multivariate basis onto which the function is expanded.\nBy default, it is associated with the linear enumeration rule. Since our\nmarginals are uniform, the :class:`~openturns.OrthogonalProductPolynomialFactory` class\nproduces Legendre polynomials.\nIn order to create the multivariate basis of polynomials, we must specify the\nnumber of functions in the basis. In this particular case, we compute that\nnumber depending on the total degree.\nThe :meth:`~openturns.EnumerateFunction.getMaximumDegreeStrataIndex` method\nof the enumeration function computes the number of layers necessary to achieve\nthat total degree. Then the number of functions up to that layer is computed\nwith the :meth:`~openturns.EnumerateFunction.getStrataCumulatedCardinal` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dimension = im.distributionX.getDimension()\nmultivariateBasis = ot.OrthogonalProductPolynomialFactory(\n    [im.distributionX.getMarginal(i) for i in range(dimension)]\n)\n\ntotalDegree = 5  # Polynomial degree\nenumerate_function = multivariateBasis.getEnumerateFunction()\nstrataIndex = enumerate_function.getMaximumDegreeStrataIndex(totalDegree)\nprint(\"strataIndex = \", strataIndex)\nnumber_of_terms_in_basis = enumerate_function.getStrataCumulatedCardinal(strataIndex)\nprint(\"number_of_terms_in_basis = \", number_of_terms_in_basis)\nadaptiveStrategy = ot.FixedStrategy(multivariateBasis, number_of_terms_in_basis)\nprint(adaptiveStrategy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the coefficients using a multivariate tensor product Gaussian\nquadrature rule. Since the coefficients are computed in the standardized\nspace, we first use the `getMeasure` method of the multivariate basis in\norder to get that standardized distribution. Then we use the\n:class:`~openturns.GaussProductExperiment` class to create the quadrature,\nusing 6 nodes on each\nof the dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "standard_distribution = multivariateBasis.getMeasure()\nprint(standard_distribution)\n\nmarginal_number_of_nodes = 6\ndim_input = im.model.getInputDimension()\nmarginalDegrees = [marginal_number_of_nodes] * dim_input\nexperiment = ot.GaussProductExperiment(im.distributionX, marginalDegrees)\nX, W = experiment.generateWithWeights()\nY = im.model(X)\nprint(\"Sample size = \", X.getSize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that 216 nodes are involved in this quadrature rule, which is the result\nof $6^3 = 216$.\n\nIn the next cell, we compute the coefficients of the polynomial chaos expansion\nusing integration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "projectionStrategy = ot.IntegrationStrategy()\nchaosalgo = ot.FunctionalChaosAlgorithm(\n    X, W, Y, im.distributionX, adaptiveStrategy, projectionStrategy\n)\nchaosalgo.run()\nresult = chaosalgo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now validate the metamodel by drawing the validation graph. We see that\nmany points are close to the red test line, which indicates that the\npredictions of the polynomial chaos expansion are close to the output\nobservations from the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view = draw_polynomial_chaos_validation(result, im.model, im.distributionX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to have a closer look on the result, we use the\n`printCoefficientsTable` function in order to print the first 10 coefficients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "printCoefficientsTable(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there are 56 coefficients in the metamodel and that many of\nthese coefficients are close to zero.\n\nIf we print only coefficients greater than $10^{-14}$, we see that\nonly a fraction of them are significant and that these significant coefficients\nhave a relatively large polynomial degree.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "printCoefficientsTable(result, threshold=1.0e-14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous experiments suggest to keep only the coefficients which are\nsignificant in the model: this is the topic of the next section.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use a model selection method\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `CleaningStrategy` has the following algorithm. On input, it considers\nonly the first `maximumConsideredTerms` coefficients\n$a_{\\boldsymbol{\\alpha}}$. On output it selects the `mostSignificant`\nmost significant coefficients. To do this, it uses the\n`significanceFactor` parameter.\n\nThe following function will help to create a sparse PCE using the\n`CleaningStrategy`. It takes into account the number of considered coefficients\nin the expansion, the number of significant coefficients to keep and the\nrelative factor and returns the Q2 score.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_cleaning_PCE(\n    maximumConsideredTerms, mostSignificant, significanceFactor, verbose=False\n):\n    \"\"\"\n    Compute a PCE using CleaningStrategy.\n\n    Parameters\n    ----------\n    maximumConsideredTerms : int\n        The maximum number of coefficients considered by the algorithm during\n        intermediate steps.\n\n    mostSignificant : int\n        The maximum number of coefficients selected by the algorithm in\n        the final PCE.\n\n    significanceFactor : float\n        The relative part of any coefficient with respect to the maximum\n        coefficient.\n\n    verbose : bool\n        If set to True, print intermediate messages.\n\n    Returns\n    -------\n    Q2 : float\n        The Q2 score\n    \"\"\"\n    adaptiveStrategy = ot.CleaningStrategy(\n        multivariateBasis,\n        maximumConsideredTerms,\n        mostSignificant,\n        significanceFactor,\n    )\n    chaosalgo = ot.FunctionalChaosAlgorithm(\n        X, W, Y, im.distributionX, adaptiveStrategy, projectionStrategy\n    )\n    chaosalgo.run()\n    result = chaosalgo.getResult()\n    score_Q2 = compute_polynomial_chaos_Q2(result, im.model, im.distributionX)\n    if verbose:\n        print(\"Q2 = %.2f%%\" % (100.0 * score_Q2))\n        printCoefficientsTable(result)\n    return score_Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next cell, we consider at most 500 coefficients and keep only\nthe 5 most significant coefficients. The factor is set to a relatively low value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximumConsideredTerms = 500\nmostSignificant = 5\nsignificanceFactor = 1.0e-10\nscore_Q2 = compute_cleaning_PCE(\n    maximumConsideredTerms, mostSignificant, significanceFactor, verbose=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that when we keep only 5 coefficients among the first 500 ones,\nthese coefficients have a very high polynomial degree. Indeed, it occurs that\nthese poorly estimated coefficients have a high absolute value. Hence, the\ncriteria selects them as significant coefficients, which leads to a poor metamodel.\n\nLet us reduce the number of considered coefficients and increase the number\nof selected coefficients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximumConsideredTerms = 56\nmostSignificant = 10\nsignificanceFactor = 1.0e-10\nscore_Q2 = compute_cleaning_PCE(\n    maximumConsideredTerms, mostSignificant, significanceFactor, verbose=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we keep only 10 coefficients among the first 56 ones, the polynomial\nchaos metamodel is much better: the coefficients are associated with a low\npolynomial degree, so that the quadrature rule estimates them with greater accuracy.\n\nWe would like to know which combination is best. In the following loop, we\nconsider the maximum number of considered coefficients from 1 to 500 and the\nnumber of selected coefficients from 1 to 30. In order to produce the\ncombinations, we use the `product` function from the `itertools` module.\nFor each combination, we compute the $Q^2$ score and select the\ncombination with highest $Q^2$ coefficient. As shown in [muller2016]_\npage 268, the computed $Q^2$ may be optimistic, but this is not the\npoint of the current example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximumConsideredTerms_list = list(range(1, 500, 50))\nmostSignificant_list = list(range(1, 30, 5))\niterator = itertools.product(maximumConsideredTerms_list, mostSignificant_list)\nbest_score = 0.0\nbest_parameters = []\nfor it in iterator:\n    maximumConsideredTerms, mostSignificant = it\n    score_Q2 = compute_cleaning_PCE(\n        maximumConsideredTerms, mostSignificant, significanceFactor\n    )\n    if score_Q2 > best_score:\n        best_score = score_Q2\n        best_parameters = [maximumConsideredTerms, mostSignificant]\n\nprint(\"Best Q2 = %.2f%%\" % (100.0 * best_score))\n\nmaximumConsideredTerms, mostSignificant = best_parameters\nprint(\"Number of considered coefficients : \", maximumConsideredTerms)\nprint(\"Number of selected coefficients : \", mostSignificant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the best solution could be to select at most 16 significant\ncoefficients among the first 101 ones. Let us see the Q2 score and the\ncoefficients in this situation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score_Q2 = compute_cleaning_PCE(\n    maximumConsideredTerms, mostSignificant, significanceFactor, verbose=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These parameters lead to a total number of coefficients equal to 12. Among\nthe 16 most significant coefficients, only 12 satisfy the criteria. Most of\nthe coefficients have a small polynomial degree although some have a total\ndegree as large as 7.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intermediate steps of the algorithm\n\nIf we set the `verbose` optional input argument of the\n`compute_cleaning_PCE` function to `True`, then intermediate messages are\nprinted in the Terminal. For each step of\nthe adaptivity algorithm, the code prints some of the internal parameters\nof the algorithm. The datastructure uses several variables that we now describe.\n\n- `Psi_k_p_` : the collection of functions in the current active polynomial multiindex set,\n- `I_p_` : the list of indices of the selected coefficients based according to the enumeration rule,\n- `addedPsi_k_ranks_` : the list of indices to add the multiindex set,\n- `removedPsi_k_ranks_` : the list of indices to remove to the multiindex set,\n- `conservedPsi_k_ranks_` : the index of the first polynomial in the selected multiindex set,\n- `currentVectorIndex_` : the current value of the index in the full multiindex set, according to the enumeration rule.\n\nEach time the selection method is called, it is passed a\ncoefficient $a_{\\boldsymbol{\\alpha}}$ which is a new candidate to be\nconsidered by the algorithm. The first time the method is evaluated, the\nactive multiindex set is empty, so that it must be filled with the first\ncoefficients in the multiindex set, according to the enumeration rule. The\nsecond time (and up to the end of the algorithm), the candidate coefficient\nis considered to be added to the multiindex set.\n\nExecuting the function prints messages that we can process to produce the\nfollowing listing. On each step, we print the list of integers corresponding\nto the indices of the coefficients in the active multiindex set.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\nStep 1:  [0, 1, 7, 10, 15, 16]\nStep 2:  [0, 1, 7, 10, 15, 17]\nStep 3:  [0, 1, 7, 10, 15, 18]\nStep 4:  [0, 1, 7, 10, 15, 19]\nStep 5:  [0, 1, 7, 10, 15, 20]\nStep 6:  [0, 1, 7, 10, 15, 21]\nStep 7:  [0, 1, 7, 10, 15, 22]\nStep 8:  [0, 1, 7, 10, 15, 23]\nStep 9:  [0, 1, 7, 10, 15, 24]\nStep 10: [0, 1, 7, 10, 15, 25]\n[...]\nStep 15: [0, 1, 7, 10, 15, 30]\nStep 16: [0, 1, 7, 10, 15, 30, 31]\n[...]\nStep 20: [0, 1, 7, 10, 15, 30, 35]\nStep 21: [0, 1, 7, 10, 15, 30, 35, 36]\n[...]\nStep 25: [0, 1, 7, 10, 15, 30, 35, 40]\nStep 26: [0, 1, 7, 10, 15, 30, 35, 40, 41]\n[...]\nStep 34: [0, 1, 7, 10, 15, 30, 35, 40, 49]\nStep 35: [0, 1, 7, 10, 15, 30, 35, 40, 49, 50]\n[...]\nStep 69: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84]\nStep 70: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 85]\n[...]\nStep 74: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89]\nStep 75: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 90]\n[...]\nStep 83: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98]\nStep 84: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98, 99]\nStep 85: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98, 100]\nStep 86: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98]\nStep 87: [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98]\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous text (and a detailed analysis of the output file) allows one to\nunderstand what exactly happens in the algorithm. To understand each step,\nnote that the significant threshold is equal to $\\epsilon = 10^{-10}$.\n\n- During the initialization, the initial basis is empty and filled with the\n  indices [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15].\n  The coefficient with index equal to 0 corrresponds to the mean of the\n  polynomial chaos expansion. As a result, we always want to select that\n  coefficient in the active set.\n  Hence, the calculation of the largest coefficient in absolute value is\n  performed from the indices from 1 to 15.\n  The largest coefficient in absolute value is $a_1 = 1.625$, which leads\n  to the threshold $\\epsilon |a_1| = 1.625 \\times 10^{-10}$. Most of\n  the considered coefficient are, however, too close to zero. This is why only\n  the coefficients [0, 1, 7, 10, 15] are kept in the basis. The\n  corresponding coefficients are [3.505, 1.625,-0.6414, -1.291, 1.372].\n- On step 1, the candidate index 16 is considered. Its coefficient is\n  $a_{16} = -1.197 \\times 10^{-15}$, which is much too low to be\n  selected. Hence, the basis is unchanged and the active multiindex set\n  is [0, 1, 7, 10, 15] on the end of this step.\n- From the step 3 to the step 15, the active multiindex set is unchanged,\n  because no considered coefficient becomes greater than the threshold.\n- On step 16, the candidate index 30 is considered, with corresponding\n  coefficient $a_{30} = -1.612$. Since this coefficient has an absolute\n  value greater than the threshold, it gets selected and the active multiindex\n  set is [0, 1, 7, 10, 15, 30] on the end of this step. From this step to the\n  end, the index 30 will not leave the active set.\n- On the step 20, the index 35 enters the active set.\n- On the step 25, the index 40 enters the active set.\n- On the step 34, the index 49 enters the active set.\n- On the step 69, the index 84 enters the active set.\n- On the step 74, the index 89 enters the active set.\n- On the step 83, the index 98 enters the active set.\n- On the last step, the active multiindex set contains the indices\n  [0, 1, 7, 10, 15, 30, 35, 40, 49, 84, 89, 98] and the corresponding\n  coefficients are [3.508, 1.625, -0.6414, -1.291, 1.372, -1.613, 0.2076,\n  -1.090, 0.4092, -0.2078, 0.1753, -0.3250].\n\nWe see that the algorithm was able so select 12 coefficients in the first\n101 coefficients considered by the algorithm. It could have selected\nmore coefficients since we provided 16 slots to fill thanks to the\n`mostSignificant` parameter. The considered coefficients were, however,\ntoo close to zero and were below the threshold.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nWe see that the :class:`~openturns.CleaningStrategy` class performs correctly in\nthis particular case. We have seen how to select the hyperparameters which\nproduce the best Q2 score.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}