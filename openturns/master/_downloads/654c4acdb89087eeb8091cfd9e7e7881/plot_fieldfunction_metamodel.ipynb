{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Metamodel of a field function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we are going to create a metamodel of a field function following these steps:\n\n- Creation of a field model over an 1-d mesh\n- Creation of a Gaussian process\n- Karhunen-Loeve decomposition of a process with known covariance function\n- Karhunen-Loeve decomposition of a process with known trajectories\n- Projection of Fields\n- Functional chaos decomposition between the coefficients of the input and output processes\n- Build a metamodel of the whole field model\n- Validate the metamodel\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\nimport openturns as ot\nimport openturns.viewer as viewer\nfrom matplotlib import pylab as plt\not.Log.Show(ot.Log.NONE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Create the input process\")\n# Domain bound\na = 1\n# Reference correlation length\nb = 0.5\n# Number of vertices in the mesh\nN = 100\n# Bandwidth of the smoothers\nh = 0.05\n\nmesh = ot.IntervalMesher([N - 1]).build(ot.Interval(-a, a))\ncovariance_X = ot.AbsoluteExponential([b])\nprocess_X = ot.GaussianProcess(covariance_X, mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "for some pretty graphs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def drawKL(scaledKL, KLev, mesh, title=\"Scaled KL modes\"):\n    graph_modes = scaledKL.drawMarginal()\n    graph_modes.setTitle(title + \" scaled KL modes\")\n    graph_modes.setXTitle('$x$')\n    graph_modes.setYTitle(r'$\\sqrt{\\lambda_i}\\phi_i$')\n    data_ev = [[i, KLev[i]] for i in range(scaledKL.getSize())]\n    graph_ev = ot.Graph()\n    graph_ev.add(ot.Curve(data_ev))\n    graph_ev.add(ot.Cloud(data_ev))\n    graph_ev.setTitle(title + \" KL eigenvalues\")\n    graph_ev.setXTitle('$k$')\n    graph_ev.setYTitle(r'$\\lambda_i$')\n    graph_ev.setAxes(True)\n    graph_ev.setGrid(True)\n    graph_ev.setLogScale(2)\n    bb = graph_ev.getBoundingBox()\n    lower = bb.getLowerBound()\n    lower[1] = 1.0e-7\n    bb = ot.Interval(lower, bb.getUpperBound())\n    graph_ev.setBoundingBox(bb)\n    return graph_modes, graph_ev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Karhunen-Loeve decomposition of the input process\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Compute the decomposition of the input process\")\nthreshold = 0.0001\nalgo_X = ot.KarhunenLoeveP1Algorithm(\n    mesh, process_X.getCovarianceModel(), threshold)\nalgo_X.run()\nresult_X = algo_X.getResult()\nphi_X = result_X.getScaledModesAsProcessSample()\nlambda_X = result_X.getEigenvalues()\n\ngraph_modes_X, graph_ev_X = drawKL(phi_X, lambda_X, mesh, \"X\")\nview = viewer.View(graph_modes_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input database generation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Sample the input process\")\nsize = 1000\nsample_X = process_X.getSample(size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The field model: convolution over an 1-d mesh\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ConvolutionP1(ot.OpenTURNSPythonFieldFunction):\n    def __init__(self, p, mesh):\n        # 1 = input dimension, the dimension of the input field\n        # 1 = output dimension, the dimension of the output field\n        # 1 = mesh dimension\n        super(ConvolutionP1, self).__init__(mesh, 1, mesh, 1)\n        # Here we define some constants and we set-up the invariant part of the execution\n        self.setInputDescription([\"x\"])\n        self.setOutputDescription([\"y\"])\n        vertices = mesh.getVertices()\n        size = vertices.getSize()\n        self.mat_W_ = ot.SquareMatrix(size)\n        for i in range(size):\n            x_minus_t = (vertices - vertices[i]) * (-1.0)\n            values_w = p(x_minus_t)\n            for j in range(size):\n                self.mat_W_[i, j] = values_w[j, 0]\n        G = mesh.computeP1Gram()\n        self.mat_W_ = self.mat_W_ * G\n\n    def _exec(self, X):\n        point_X = [val[0] for val in X]\n        values_Y = self.mat_W_ * point_X\n        return [[v] for v in values_Y]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dynamical model: convolution wrt kernel p\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Create the convolution function\")\np = ot.SymbolicFunction(\"x\", \"exp(-(x/\" + str(h) + \")^2)\")\nmyConvolution = ot.FieldFunction(ConvolutionP1(p, mesh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output database generation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Sample the output process\")\nsample_Y = myConvolution(sample_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Karhunen-Loeve decomposition of the output process\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Compute the decomposition of the output process\")\nalgo_Y = ot.KarhunenLoeveSVDAlgorithm(sample_Y, threshold)\nalgo_Y.run()\nresult_Y = algo_Y.getResult()\nphi_Y = result_Y.getScaledModesAsProcessSample()\nlambda_Y = result_Y.getEigenvalues()\ngraph_modes_Y, graph_ev_Y = drawKL(phi_Y, lambda_Y, mesh, \"Y\")\nview = viewer.View(graph_modes_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare eigenvalues of X and Y\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_ev_X.add(graph_ev_Y)\ngraph_ev_X.setTitle(\"Input/ouput eigenvalues comparison\")\ngraph_ev_X.setYTitle(r\"$\\lambda_X, \\lambda_Y$\")\ngraph_ev_X.setColors([\"blue\", \"blue\", \"red\", \"red\"])\ngraph_ev_X.setLegends([r\"$\\lambda_X$\", \"\", r\"$\\lambda_Y$\", \"\"])\ngraph_ev_X.setLegendPosition(\"topright\")\nview = viewer.View(graph_ev_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Polynomial chaos between KL coefficients\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"project sample_X\")\nsample_xi_X = result_X.project(sample_X)\n\nprint(\"project sample_Y\")\nsample_xi_Y = result_Y.project(sample_Y)\n\nprint(\"Compute PCE between coefficients\")\ndegree = 1\ndimension_xi_X = sample_xi_X.getDimension()\ndimension_xi_Y = sample_xi_Y.getDimension()\nenumerateFunction = ot.LinearEnumerateFunction(dimension_xi_X)\nbasis = ot.OrthogonalProductPolynomialFactory(\n    [ot.HermiteFactory()] * dimension_xi_X, enumerateFunction)\nbasisSize = enumerateFunction.getStrataCumulatedCardinal(degree)\nadaptive = ot.FixedStrategy(basis, basisSize)\nprojection = ot.LeastSquaresStrategy(\n    ot.LeastSquaresMetaModelSelectionFactory(ot.LARS(), ot.CorrectedLeaveOneOut()))\not.ResourceMap.SetAsScalar(\n    \"LeastSquaresMetaModelSelection-ErrorThreshold\", 1.0e-7)\nalgo_chaos = ot.FunctionalChaosAlgorithm(\n    sample_xi_X, sample_xi_Y, basis.getMeasure(), adaptive, projection)\nalgo_chaos.run()\nresult_chaos = algo_chaos.getResult()\nmeta_model = result_chaos.getMetaModel()\nprint(\"myConvolution=\", myConvolution.getInputDimension(),\n      \"->\", myConvolution.getOutputDimension())\npreprocessing = ot.KarhunenLoeveProjection(result_X)\nprint(\"preprocessing=\", preprocessing.getInputDimension(),\n      \"->\", preprocessing.getOutputDimension())\nprint(\"meta_model=\", meta_model.getInputDimension(),\n      \"->\", meta_model.getOutputDimension())\npostprocessing = ot.KarhunenLoeveLifting(result_Y)\nprint(\"postprocessing=\", postprocessing.getInputDimension(),\n      \"->\", postprocessing.getOutputDimension())\nmeta_model_field = ot.FieldToFieldConnection(\n    postprocessing, ot.FieldToPointConnection(meta_model, preprocessing))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Meta_model validation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "iMax = 10\nsample_X_validation = process_X.getSample(iMax)\nsample_Y_validation = myConvolution(sample_X_validation)\n\ngraph_sample_Y_validation = sample_Y_validation.drawMarginal(0)\nsample_Y_hat = meta_model_field(sample_X_validation)\ngraph = sample_Y_hat.drawMarginal(0)\nfor i in range(iMax):\n    dr = graph.getDrawable(i)\n    dr.setLineStyle(\"dashed\")\n    graph_sample_Y_validation.add(dr)\ngraph_sample_Y_validation.setTitle(r\"Comparison $Y_i$ and $\\tilde{Y}_i$\")\ngraph_sample_Y_validation.setXTitle(r\"$t$\")\ngraph_sample_Y_validation.setYTitle(r\"$Y$, $\\tilde{Y}$\")\nview = viewer.View(graph_sample_Y_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_sample_X = sample_X_validation.drawMarginal(0)\ngraph_sample_X.setTitle(r\"Trajectory $X$\")\ngraph_sample_X.setXTitle(r\"$t$\")\ngraph_sample_X.setYTitle(r\"$X$\")\nview = viewer.View(graph_sample_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_sample_Y = sample_Y_validation.drawMarginal(0)\ngraph_sample_Y.setTitle(r\"Trajectory $Y$\")\ngraph_sample_Y.setXTitle(r\"$t$\")\ngraph_sample_Y.setYTitle(r\"$Y$\")\nview = viewer.View(graph_sample_Y)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}