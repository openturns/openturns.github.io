{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# An illustrated example of a FORM probability estimate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract\n\nIn this example we illustrate the different steps of a FORM/SORM analysis on a\nsimple example. We focus on the different steps and compare them with an analytic\ncomputation whenever possible.\n\nSee `FORM <form_approximation>` and `SORM <sorm_approximation>` and to get more theoretical details.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as otv\nimport numpy as np\n\n# sphinx_gallery_thumbnail_number = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context\n\nWe consider a bivariate random vector $\\inputRV = (X_1, X_2)$ with the following independent components that follow:\n\n- the exponential distribution with parameter $\\lambda=1$, $X_1 \\sim \\mathcal{E}(1.0)$ ;\n- the standard unit normal distribution $X_2 \\sim \\mathcal{N}(0,1)$.\n\nThe support of the input vector is $[0, +\\infty[ \\times \\Rset$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dist_X1 = ot.Exponential(1.0)\ndist_X2 = ot.Normal()\ndist_X = ot.JointDistribution([dist_X1, dist_X2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can draw the isolines of the PDF of the distribution `dist_X`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ot.ResourceMap.SetAsUnsignedInteger(\"Contour-DefaultLevelsNumber\", 8)\ngraph_PDF = dist_X.drawPDF([0.0, -10.0], [20.0, 10.0])\ngraph_PDF.setTitle(r\"2D-PDF of the input variables $(X_1, X_2)$\")\ngraph_PDF.setXTitle(r\"$x_1$\")\ngraph_PDF.setYTitle(r\"$x_2$\")\ngraph_PDF.setLegendPosition(\"lower right\")\ncontours = graph_PDF.getDrawable(0).getImplementation()\ncontours.setColorMapNorm(\"rank\")\ncontours.setIsFilled(True)\ncontours.buildDefaultLevels(50)\ngraph_PDF.setDrawable(0, contours)\nview = otv.View(graph_PDF, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider the model from $\\Rset^2$ into  $\\Rset$ defined by:\n\n\\begin{align}\\model : (x_1, x_2) \\mapsto x_1 x_2\\end{align}\n\nWe start by drawing the isolines of the model $\\model$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = ot.SymbolicFunction([\"x1\", \"x2\"], [\"x1 * x2\"])\ngraph_model = g.draw([0.0, -10.0], [20.0, 10.0])\ngraph_model.setXTitle(r\"$x_1$\")\ngraph_model.setYTitle(r\"$x_2$\")\ngraph_model.setTitle(r\"Isolines of the model : $g$\")\ncontours = graph_model.getDrawable(0).getImplementation()\ncontours.setColorMapNorm(\"rank\")\ncontours.setIsFilled(True)\ncontours.buildDefaultLevels(50)\ngraph_model.setDrawable(0, contours)\nview = otv.View(graph_model, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider  the univariate output variable :\n\n\\begin{align}Y = \\model(\\inputRV)\\end{align}\n\nWe want to estimate the probability $P_f$ of the output variable to be greater than a\nprescribed threshold $s=10$ : this is the failure event.\nThis probability is simply expressed for a continuous random vector $\\inputRV$ as:\n\n\\begin{align}:label: PfDef\n\n   P_f = \\Prob{Y \\geq s} = \\int_{\\set{D}} \\mathbf{1}_{\\set{D}}(x) \\pdf d\\vect{x}\\end{align}\n\nwhere:\n\n\\begin{align}\\end{align}\n\n \\set{D} = \\{ (x_1, x_2) \\in [0,+\\infty[ \\times \\Rset \\, | \\,  \\model(x_1, x_2) \\geq s \\}\n\nis the failure domain and $\\inputMeasure$ is the probability density function (PDF)\nof $\\inputRV$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first define random vectors\nand the failure event associated to the output random variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vector_X = ot.RandomVector(dist_X)\nvector_Y = ot.CompositeRandomVector(g, vector_X)\ns = 10.0\nevent = ot.ThresholdEvent(vector_Y, ot.Greater(), s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The boundary of the failure domain can easily be represented as it is a branch of an hyperbole: the\nboundary is the graph of the function defined from $\\Rset$ into  $\\Rset$ by:\n\n\\begin{align}:label: defH\n\n   h : x_1 \\mapsto x_2 = \\frac{s}{x_1}\\end{align}\n\nThe boundary of the failure domain is also the isoline of the model $\\model$ associated to the\nlevel $s$:\n\n\\begin{align}\\partial \\set{D} =  \\{(x_1, x_2)\\, |\\, \\model(x_1, x_2) = s \\}\\end{align}\n\nWe can draw it with the `draw` method of the function $\\model$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nb_points = 101\ngraph_g = g.draw([0.0, -10.0], [20.0, 10.0], [nb_points] * 2)\ndraw_boundary = graph_g.getDrawable(0)\ndraw_boundary.setLevels([s])\ndraw_boundary.setLegend(r\"Boundary $\\partial \\mathcal{D}$\")\ngraph_g.setDrawables([draw_boundary])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "texts = [r\" $\\mathcal{D} = \\{(x_1, x_2)\\, |\\, g(x_1, x_2) \\geq 10 \\}$\"]\ntext_graph = ot.Text([[10.0, 3.0]], texts)\ntext_graph.setTextSize(1)\ntext_graph.setColor(\"black\")\ngraph_g.add(text_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_g.setTitle(\"Failure domain in the physical space\")\ngraph_g.setXTitle(r\"$x_1$\")\ngraph_g.setYTitle(r\"$x_2$\")\ngraph_g.setLegendPosition(\"topright\")\n\nview = otv.View(graph_g, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can superimpose the event boundary with the bivariate PDF insolines of the input distribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "draw_boundary.setColor(\"black\")\ngraph_PDF.add(draw_boundary)\ngraph_PDF.setLegendPosition(\"lower right\")\nview = otv.View(graph_PDF, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the previous figure, we observe that in the failure domain, the PDF takes small\n(and even very small) values.\nConsequently the failure probability $P_f$ is also expected to be small.\nThe FORM/SORM methods estimate the failure probability.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The FORM/SORM approximations\n\nThe basic steps of the FORM and SORM algorithms are:\n\n- use an isoprobabilistic transformation to map the input random vector into the standard space;\n- find the design point which is the nearest point to the origin in the standard space;\n- estimate the probability.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Isoprobabilistic transformation\n\nThe interest of the  isoprobabilistic transformation is the rotational\ninvariance of the distribution in the standard space. This property reduces the dimension\nof the problem to 1. See `Isoprobabilistic transformation <isoprobabilistic_transformation>` for more theoretical details.\n\nOpenTURNS has several isoprobabilistic transformations, depending on the distribution of the input random vector:\n\n- the Nataf transformation is used if the input distribution has a normal copula,\n- the Generalized Nataf transformation is used if the input distribution has an elliptical copula,\n- the Rosenblatt transformation is used in any other cases.\n\nThe Nataf and  Rosenblatt transformations map the input random vector into a vector that follows a\nnormal distribution with zero mean and unit variance. The Generalized Nataf transformation maps the\ninput random vector into a vector that follows the standard elliptical distribution associated to the\nelliptical copula of the input distribution.\n\nIn this example, the input distribution is not elliptical so the isoprobabilistic transformation is the\nRosenblatt transformation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Is Elliptical ? \", dist_X.isElliptical())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Rosenblatt transformation $T$ is defined by:\n\n\\begin{align}:label: defT\n\n   T : \\vect{x} \\mapsto \\vect{z}\\end{align}\n\nsuch that the random vector $\\standardRV = T(\\inputRV)$ follows a bivariate normal distribution\nwith zero mean and unit variance. It follows that the components $Z_1$ and\n$Z_2$ are independent.\n\nWe detail the Rosenblatt transform in this simple case where the input random vector $\\inputRV$\nhas independent components. Then, the Rosenblatt transform is defined by:\n\n\\begin{align}z_i = \\Phi^{-1} \\circ F_i(x_i)\\end{align}\n\nwhere $F_i$ is the cumulative distribution function (CDF) of $X_i$ and\n$\\Phi$ the CDF of the univariate normal distribution with zero mean and unit variance.\nNote that in this example, $\\Phi^{-1} \\circ F_2 = I_d$ as $F_2 = \\Phi$.\nThe isoprobabilistic transform and its inverse are methods of the distribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transformation = dist_X.getIsoProbabilisticTransformation()\ninverse_transformation = dist_X.getInverseIsoProbabilisticTransformation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us detail this transformation, step by step.\nWe draw a realization of the random input vector. This point is said to be in the physical space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xi = vector_X.getRealization()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We build `zi` the mapping of `xi` through the Rosenblatt transformation.\nThe point `zi` is said to be in the standard space. Note that the second component remained unchanged.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ui = [dist_X1.computeCDF(xi[0]), dist_X2.computeCDF(xi[1])]\nzi = [ot.Normal().computeQuantile(ui[0])[0], ot.Normal().computeQuantile(ui[1])[0]]\nprint(xi, \"->\", ui, \"->\", zi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also build the isoprobabilistic transform $T_1$ and its inverse $T_1^{-1}$ for the\nfirst marginal:\n\n\\begin{align}:label: detT1\n\n   T_1 = \\Phi^{-1} \\circ F_1\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform_X1 = dist_X1.getIsoProbabilisticTransformation()\ninverse_transform_X1 = dist_X1.getInverseIsoProbabilisticTransformation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can implement the transformation using $T_1$ on the first components\ndirectly using $T$ on both components `xi`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "zi1D = [transform_X1([xi[0]])[0], xi[1]]\nzi2D = transformation(xi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check the result of our experiment : we observe the results are the same.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"zi = \", zi)\nprint(\"zi1D = \", zi1D)\nprint(\"zi2D = \", zi2D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model in the standard space is defined by:\n\n\\begin{align}\\widetilde{\\model} = \\model \\circ T^{-1}\\end{align}\n\nWe can define it using the capacities of the composition of functions implemented in the library.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g_tilde = ot.ComposedFunction(g, inverse_transformation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The failure domain in the standard space is defined by:\n\n\\begin{align}\\end{align}\n\n \\set{\\widetilde{D}} = \\{ (z_1, z_2) \\in [0,+\\infty[ \\times \\Rset \\, | \\,  \\widetilde{\\model}(z_1, z_2) \\geq s \\}\n\nand its boundary is defined by:\n\n\\begin{align}\\partial \\set{\\widetilde{D}} = \\{ (z_1, z_2) \\in [0,+\\infty[ \\times \\Rset \\, | \\,\n      \\widetilde{\\model}(z_1, z_2) = s \\}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We draw the graph of $\\widetilde{g}$ in the standard space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_standard_space = g_tilde.draw([0.0, 0.0], [7.0, 7.0], [101] * 2)\n\ndraw_boundary_stand_space = graph_standard_space.getDrawable(0)\ndraw_boundary_stand_space.setLevels([s])\ndraw_boundary_stand_space.setLegend(r\"Boundary $\\partial \\mathcal{\\tilde{D}}$\")\ngraph_standard_space.setDrawables([draw_boundary_stand_space])\n\ngraph_standard_space.setXTitle(r\"$z_1$\")\ngraph_standard_space.setYTitle(r\"$z_2$\")\ngraph_standard_space.setTitle(\"Failure domain in the standard space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We add some annotations\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "texts = [r\"$\\mathcal{\\tilde{D}} = \\{(z_1, z_2)\\, |\\, \\tilde{g}(z_1, z_2) \\geq 10 \\}$\"]\ntext_graph = ot.Text([[4.0, 3.0]], texts)\ntext_graph.setTextSize(1)\ntext_graph.setColor(\"black\")\ngraph_standard_space.add(text_graph)\n\ngraph_standard_space.setLegendPosition(\"topright\")\nview = otv.View(graph_standard_space, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The design point\n\nDue to the spherical distribution in the standard space, the area that contributes\nthe most to the integral defining the probability is the vicinity of the closest point\nof the failure domain to the origin of the standard space.\nThen the second step of the method is to find this point, *the design point*, through a\nminimization problem under constraints.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We configure the Cobyla solver that we use for the optimization :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver = ot.Cobyla()\nsolver.setMaximumIterationNumber(10000)\nsolver.setMaximumAbsoluteError(1.0e-3)\nsolver.setMaximumRelativeError(1.0e-3)\nsolver.setMaximumResidualError(1.0e-3)\nsolver.setMaximumConstraintError(1.0e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We build the FORM algorithm with its basic constructor. The starting point for the optimization\nalgorithm is the mean of the input distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.setStartingPoint(dist_X.getMean())\nalgo_FORM = ot.FORM(solver, event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are ready to run the algorithm and store the result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo_FORM.run()\nresult = algo_FORM.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The design point can be retrieved in both physical and standard space with respectively the\n`getPhysicalSpaceDesignPoint` and `getStandardSpaceDesignPoint` methods. We denote them respectively\n$\\vect{x}^*$ and $\\vect{z}^*$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_point_physical_space = result.getPhysicalSpaceDesignPoint()\ndesign_point_standard_space = result.getStandardSpaceDesignPoint()\nprint(\"Design point in physical space : \", design_point_physical_space)\nprint(\"Design point in standard space : \", design_point_standard_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can get the Hasofer index with the `getHasoferReliabilityIndex` method which is the distance of\nthe design point to the origin:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beta_HL = result.getHasoferReliabilityIndex()\nprint(\"Hasofer index : \", beta_HL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We visualize the design point on the previous graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cloud = ot.Cloud([design_point_standard_space])\ncloud.setColor(\"red\")\ncloud.setPointStyle(\"fcircle\")\ncloud.setLegend(r\"design point $z^*$\")\ngraph_standard_space.add(cloud)\ngraph_standard_space.setGrid(True)\ngraph_standard_space.setLegendPosition(\"lower right\")\ncc = ot.Curve(\n    [0.0, design_point_standard_space[0]],\n    [0.0, design_point_standard_space[1]],\n    r\"$\\beta_{HL}$ distance\",\n)\ncc.setLineStyle(\"dashed\")\ncc.setColor(\"black\")\ngraph_standard_space.add(cc)\ngraph_standard_space.setLegendPosition(\"topright\")\nview = otv.View(graph_standard_space, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The FORM approximation\n\nThe last step of the FORM algorithm is to replace the failure domain boundary by the hyperplane\nwhich is tangent to the failure domain at the design point in the standard space.\nTo draw this hyperplane $\\mathcal{P}_{\\vect{z}^*}$, we define the function from\n$\\Rset^2$ to $\\Rset$ defined by:\n\n\\begin{align}M \\rightarrow \\scalarproduct{\\nabla \\widetilde{\\model}(\\vect{z}^*)}{\\vect{Z^*M}}\\end{align}\n\nwhere $\\nabla \\vect{\\widetilde{\\model}(\\vect{z}^*)}$ is the gradient of the\nfunction $\\widetilde{\\model}$\nat the design point $Z^*(\\vect{z}^*)$.\nThen, the tangent hyperplane is the isoline associated to the zero level of the previous function :\n\n\\begin{align}\\mathcal{P}_{z^*} = \\{ \\vect{z} \\in \\Rset^2 \\, | \\,\n               \\scalarproduct{\\nabla\\widetilde{\\model}(\\vect{z}^*)}{\\vect{Z^*M}} = 0\\}\\end{align}\n\nWe can use the :class:`~openturns.LinearFunction` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "center = design_point_standard_space\ngrad_design_point = g_tilde.gradient(design_point_standard_space)\nconstant = [0.0]\nlinear_mat = ot.Matrix(1, 2)\nlinear_mat[0, 0] = grad_design_point[0, 0]\nlinear_mat[0, 1] = grad_design_point[1, 0]\nlinear_proj = ot.LinearFunction(center, constant, linear_mat)\n\ngraph_tangent = linear_proj.getMarginal(0).draw([0.0, 0.0], [7.0, 7.0], [101] * 2)\ndraw_tangent = graph_tangent.getDrawable(0)\ndraw_tangent.setLevels([0])\ndraw_tangent.setLegend(r\"$\\mathcal{\\Pi}_{z^*}$ (FORM)\")\ndraw_tangent.setColor(\"green\")\ndraw_tangent.setLineStyle(\"dashed\")\ngraph_standard_space.add(draw_tangent)\ngraph_standard_space.setLegendPosition(\"topright\")\nview = otv.View(graph_standard_space, square_axes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on whether the origin of the standard space $\\vect{0}$ belongs to the failure domain,\nthe FORM probability is defined by:\n\n\\begin{align}P_{FORM} =  \\begin{cases}\n                  E(+\\beta_{HL}) & \\text{ if }  \\vect{0} \\in \\set{\\widetilde{D}} \\\\\n                   E(-\\beta_{HL}) & \\text{ otherwise.}\n                \\end{cases}\\end{align}\n\nwhere $E(.)$ is the marginal cumulative distribution function along any direction of\nthe spherical distribution in the standard space. In this example, this is the normal distribution.\nSo we have:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "isOriginFail = result.getIsStandardPointOriginInFailureSpace()\nnormal = ot.Normal()\nif isOriginFail:\n    pf_FORM = normal.computeCDF(beta_HL)\nelse:\n    pf_FORM = normal.computeCDF(-beta_HL)\nprint(\"FORM : Pf_FORM = \", pf_FORM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This failure probability is implemented but the FORM algorithm and can be obtained\nwith the `getEventProbability` method. We check we have the same result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pf = result.getEventProbability()\nprint(\"Probability of failure (FORM) Pf_FORM  = \", pf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The SORM approximation\n\nThe SORM approximation uses the main curvatures $\\kappa_i^0$ of the homothetic of the failure domain\nat distance 1 from the origin. These curvatures are calculated  at the design point.\nThey are linked to the curvatures $\\kappa_i$ of the failure domain by:\n\n\\begin{align}\\kappa_i^0 = \\beta_{HL} \\kappa_i\\end{align}\n\nThe Breitung approximation is valid for $\\beta_{HL} \\rightarrow +\\infty$ and is defined by :\n\n\\begin{align}P_{SORM, Breitung} = \\begin{cases}\n                E(+\\beta_{HL}) \\prod_{i=1}^{d-1} \\dfrac{1}{\\sqrt{1+\\kappa_i^0}} & \\text{ if }\n                        \\vect{0} \\in \\set{\\widetilde{D}} \\\\\n                   E(-\\beta_{HL}) \\prod_{i=1}^{d-1} \\dfrac{1}{\\sqrt{1+\\kappa_i^0}} & \\text{ otherwise. }\n                \\end{cases}\\end{align}\n\nand approximates the boundary by the osculating paraboloid at the design point.\n\nNote that the term $\\kappa_i^0$ does not depend on $\\beta_{HL}$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we can easily implement the boundary of the failure domain in the\nphysical space, using the function $h$ defined in :eq:`defH`.\n\nIn the standard space, the boundary is defined by the composed function\n$z_1 \\mapsto h \\circ T_1^{-1}(z_1)$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "failure_boundary_physical_space = ot.SymbolicFunction([\"x\"], [\"10.0 / x\"])\nfailure_boundary_standard_space = ot.ComposedFunction(\n    failure_boundary_physical_space, inverse_transform_X1\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need the value of the second derivative of the failure boundary function\nat the abscissa of the design point in the standard space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z1_star = [design_point_standard_space[0]]\ndz1_star = failure_boundary_standard_space.getGradient().gradient(z1_star)\nd2z1_star = failure_boundary_standard_space.getHessian().hessian(z1_star)\nprint(\"first component of the design point = \", z1_star[0])\nprint(\n    \"second component of the design point = \",\n    failure_boundary_standard_space(z1_star)[0],\n)\nprint(\n    \"value of the hessian of the failure boundary at this abscissa= \",\n    d2z1_star[0, 0, 0],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the standard space, the osculating parabola $\\mathcal{P}_{\\vect{z}^*}$\nat $\\vect{z}^*$ is the graph of the function defined by:\n\n\\begin{align}z_1 \\mapsto   h \\circ T_1^{-1} (z_1^*) + \\frac{d}{du_1} (h \\circ T_1^{-1})(z_1^*) (z_1-z_1^*) +\n    \\frac{1}{2} \\frac{d^2}{dz_1^2} (h \\circ T_1^{-1})(z_1^*) (z_1-z_1^*)^2\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = np.linspace(1.1, 4.0, 100)\nparabola = (\n    failure_boundary_standard_space(z1_star)[0]\n    + dz1_star[0, 0] * (z - z1_star)\n    + 0.5 * d2z1_star[0, 0, 0] * (z - z1_star) ** 2\n)\ncurve_parabola = ot.Curve(z, parabola, r\"$\\mathcal{P}_{z^*}$ (SORM)\")\ncurve_parabola.setLineStyle(\"dashed\")\ncurve_parabola.setColor(\"orange\")\ngraph_standard_space.add(curve_parabola)\ngraph_standard_space.setLegendPosition(\"topright\")\nview = otv.View(graph_standard_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step is to estimate the principal curvatures of the osculating paraboloid.\n\nFor any regular function $\\ell: \\Rset \\rightarrow \\Rset$ the curvature $\\kappa(x)$ at the point $x$ in\ncartesian coordinates reads as:\n\n\\begin{align}\\kappa(x) = \\frac{\\ell''(x)}{(1+[\\ell'(x)]^2)^{3/2}}.\\end{align}\n\nFor the osculating parabola of concern we use the previously computed gradient and Hessian previously computed:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "curvature = (d2z1_star[0, 0, 0]) / (1 + (dz1_star[0, 0]) ** 2) ** (3 / 2)\nprint(\"Curvature (analytic formula) = \", curvature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We build the SORM algorithm and run it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.setStartingPoint(dist_X.getMean())\nalgo_SORM = ot.SORM(solver, event)\nalgo_SORM.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SORM result is obtained with the `getResult` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_SORM = algo_SORM.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The principal curvatures of the osculating paraboloid at the design point is obtained by the\n`getSortedCurvatures` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Curvature (library) = \", result_SORM.getSortedCurvatures()[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the curvature is computed, there are several ways of approximating the failure probability $P_f$.\nThe library implements the Breitung, Hohenbichler and Tvedt estimates.\nWe detail here the calculus of the Breitung approximation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coeff = (1.0 + beta_HL * curvature) ** (-0.5)\nif isOriginFail:\n    pf_SORM = (normal.computeCDF(beta_HL)) * coeff\nelse:\n    pf_SORM = (normal.computeCDF(-beta_HL)) * coeff\nprint(\"SORM : Pf_SORM = \", pf_SORM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare with the different estimators:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pf_Breitung = result_SORM.getEventProbabilityBreitung()\npf_Hohenbichler = result_SORM.getEventProbabilityHohenbichler()\npf_Tvedt = result_SORM.getEventProbabilityTvedt()\n\nprint(\"Probability of failure (SORM Breintung) Pf = \", pf_Breitung)\nprint(\"Probability of failure (SORM Hohenbichler) Pf = \", pf_Hohenbichler)\nprint(\"Probability of failure (SORM Tvedt) Pf = \", pf_Tvedt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display all figures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}