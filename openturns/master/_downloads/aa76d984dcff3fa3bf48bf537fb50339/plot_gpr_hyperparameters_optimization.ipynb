{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gaussian process fitter: configure the optimization solver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this example is to show how to fine-tune the optimization solver used to estimate the hyperparameters of the covariance model of the Gaussian process regression.\n\n## Introduction\n\nIn a Gaussian process regression, there are various types of parameters which are estimated from the data.\n\n* The parameters ${\\bf \\beta}$ associated with the deterministic trend. These parameters are computed based on linear least squares.\n* The parameters of the covariance model.\n\nWe only consider the following parameters of the covariance model:\n\n* The magnitude parameter $\\sigma^2$ is estimated from the data.\n  If the output dimension is equal to one, this parameter is estimated using\n  the analytic variance estimator which maximizes the likelihood.\n  Otherwise, if output dimension is greater than one or analytical sigma disabled,\n  this parameter is estimated from numerical optimization.\n* The scale parameters ${\\bf \\theta}\\in\\mathbb{R}^d$ where $d$ is\n  the spatial dimension of the covariance model.\n  Often, the parameter ${\\bf \\theta}$ is a scale parameter.\n  This step involves an optimization algorithm.\n\nAll these parameters are estimated with the :class:`~openturns.GaussianProcessFitter` class.\n\nThe estimation of the $\\vect{\\theta}$ parameters is the step which has the highest CPU cost.\nMoreover, the maximization of likelihood may be associated with difficulties e.g. many local maximums or even the non convergence of the optimization algorithm.\nIn this case, it might be useful to fine tune the optimization algorithm so that the convergence of the optimization algorithm is, hopefully, improved.\n\nFurthermore, there are several situations in which the optimization can be initialized or completely bypassed.\nSuppose for example that we have already created an initial Gaussian process regression with $N$ points and we want to add a single new point.\n\n* It might be interesting to initialize the optimization algorithm with the optimum found for the previous Gaussian process regression:\n  this may reduce the number of iterations required to maximize the likelihood.\n* We may as well completely bypass the optimization step: if the previous covariance model was correctly estimated,\n  the update of the parameters may or may not significantly improve the estimates.\n\nThis is why the goal of this example is to see how to configure the optimization of the hyperparameters of a Gaussian process regression.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as otv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the symbolic function which evaluates the output `Y` depending on the inputs `E`, `F`, `L` and `I`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = ot.SymbolicFunction([\"E\", \"F\", \"L\", \"I\"], [\"F*L^3/(3*E*I)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the distribution of the input random vector.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Young's modulus `E`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "E = ot.Beta(0.9, 2.27, 2.5e7, 5.0e7)  # in N/m^2\nE.setDescription(\"E\")\n# Load F\nF = ot.LogNormal()  # in N\nF.setParameter(ot.LogNormalMuSigma()([30.0e3, 9e3, 15.0e3]))\nF.setDescription(\"F\")\n# Length L\nL = ot.Uniform(250.0, 260.0)  # in cm\nL.setDescription(\"L\")\n# Moment of inertia I\nII = ot.Beta(2.5, 1.5, 310, 450)  # in cm^4\nII.setDescription(\"I\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we define the dependency using a :class:`~openturns.NormalCopula`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dim = 4  # number of inputs\nR = ot.CorrelationMatrix(dim)\nR[2, 3] = -0.2\nmyCopula = ot.NormalCopula(ot.NormalCopula.GetCorrelationFromSpearmanCorrelation(R))\nmyDistribution = ot.JointDistribution([E, F, L, II], myCopula)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the design of experiments\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider a simple Monte-Carlo sampling as a design of experiments.\nThis is why we generate an input sample using the :meth:`~openturns.Distribution.getSample` method of the distribution.\nThen we evaluate the output using the `model` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_train = 10\nX_train = myDistribution.getSample(sampleSize_train)\nY_train = model(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the metamodel\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to create the Gaussian process regression, we first select a constant trend with the :class:`~openturns.LinearBasisFactory` class.\nThen we use a squared exponential covariance model.\nFinally, we use the :class:`~openturns.GaussianProcessFitter` class to calibrate a covariance model for a Gaussian process regression,\ntaking the training sample, the covariance model and the trend basis as input arguments.\nThe scale parameters must be positive.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dimension = myDistribution.getDimension()\nbasis = ot.LinearBasisFactory(dimension).build()\n\nx_range = X_train.computeRange()\nprint(\"x_range:\")\nprint(x_range)\nscale_max_factor = 4.0  # Must be > 1, tune this to match your problem\nscale_min_factor = 0.1  # Must be < 1, tune this to match your problem\nmaximum_scale_bounds = scale_max_factor * x_range\n\ncovarianceModel = ot.SquaredExponential([1.0] * dimension, [1.0])\nalgo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nalgo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianProcessFitter.run` method has optimized the hyperparameters of the metamodel.\n\nWe can then print the constant trend of the metamodel, which have been\nestimated using the least squares method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.getTrendCoefficients()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the hyperparameters of the covariance model, which have been estimated by maximizing the likelihood.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basic_covariance_model = result.getCovarianceModel()\nprint(basic_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the optimizer algorithm\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianProcessFitter.getOptimizationAlgorithm` method\nreturns the optimization algorithm used to optimize the\n$\\vect{\\theta}$ parameters of the\n:class:`~openturns.SquaredExponential` covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver = algo.getOptimizationAlgorithm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the default optimizer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solverImplementation = solver.getImplementation()\nsolverImplementation.getClassName()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianProcessFitter.getOptimizationBounds` method\nreturns the bounds.\nThe dimension of these bounds correspond to the spatial dimension of\nthe covariance model.\nIn the metamodeling context, this correspond to the input dimension of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bounds = algo.getOptimizationBounds()\nbounds.getDimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lbounds = bounds.getLowerBound()\nprint(\"lbounds\")\nprint(lbounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ubounds = bounds.getUpperBound()\nprint(\"ubounds\")\nprint(ubounds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianProcessFitter.getOptimizeParameters` method returns `True` if these parameters are to be optimized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "isOptimize = algo.getOptimizeParameters()\nprint(isOptimize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure the starting point of the optimization\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The starting point of the optimization is based on the parameters of the covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covarianceModel = ot.SquaredExponential(maximum_scale_bounds, [1.0])\nalgo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = algo.getResult()\nnew_covariance_model = result.getCovarianceModel()\nprint(new_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to see the difference with the default optimization, we print the previous optimized covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(basic_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We draw the graphs that validate the meta model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo_gpr = ot.GaussianProcessRegression(result)\nalgo_gpr.run()\nmetamodel = algo_gpr.getResult().getMetaModel()\nX_test = myDistribution.getSample(100)\nY_test = model(X_test)\nvalidation = ot.MetaModelValidation(Y_test, metamodel(X_test))\ng = validation.drawValidation()\nview = otv.View(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that this does not change much the values of the parameters in this case.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Disabling the optimization\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is sometimes useful to completely disable the optimization of the parameters.\nIn order to see the effect of this, we first initialize the parameters of\nthe covariance model with the arbitrary values `[12.0, 34.0, 56.0, 78.0]`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covarianceModel = ot.SquaredExponential([12.0, 34.0, 56.0, 78.0], [91.0])\nalgo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianProcessFitter.setOptimizeParameters` method can be\nused to disable the optimization of the parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.setOptimizeParameters(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we run the algorithm and get the result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the covariance model is unchanged:\nthe parameters have not been optimized, as required.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "updated_covariance_model = result.getCovarianceModel()\nprint(updated_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The trend, however, is still optimized, using linear least squares.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.getTrendCoefficients()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reuse the parameters from a previous optimization\n\nIn this example, we show how to reuse the optimized parameters of a previous Gaussian process fit and configure a new one.\nFurthermore, we disable the optimization so that the parameters of the covariance model are not updated.\nThis makes the process of adding a new point very fast:\nit improves the quality by adding a new point in the design of experiments without paying the price of the update of the covariance model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: Run a first Gaussian process fitter algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dimension = myDistribution.getDimension()\nbasis = ot.ConstantBasisFactory(dimension).build()\ncovarianceModel = ot.SquaredExponential(maximum_scale_bounds, [1.0])\nalgo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nalgo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now retrieve the optimized the covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covarianceModel = result.getCovarianceModel()\nprint(covarianceModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Create a new point and add it to the previous training design.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_new = myDistribution.getSample(20)\nY_new = model(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train.add(X_new)\nX_train.getSize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_train.add(Y_new)\nY_train.getSize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Create an updated Gaussian process fit, using the new point with the old covariance parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nalgo.setOptimizeParameters(False)\nalgo.run()\nresult = algo.getResult()\nnotUpdatedCovarianceModel = result.getCovarianceModel()\nprint(notUpdatedCovarianceModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def printCovarianceParameterChange(covarianceModel1, covarianceModel2):\n    parameters1 = covarianceModel1.getFullParameter()\n    parameters2 = covarianceModel2.getFullParameter()\n    for i in range(parameters1.getDimension()):\n        deltai = abs(parameters1[i] - parameters2[i])\n        print(f\"Change in the parameter #{i} = {deltai}\")\n    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "printCovarianceParameterChange(covarianceModel, notUpdatedCovarianceModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the parameters did not change *at all*: disabling the optimization allows one to keep a constant covariance model.\nIn a practical algorithm, we may, for example, add a block of 10 new points before updating the parameters of the covariance model.\nAt this point, we may reuse the previous covariance model so that the optimization starts from a better point, compared to the parameters default values.\nThis will reduce the cost of the optimization.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure the local optimization solver\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following example shows how to set the local optimization solver.\nWe choose the `SLSQP` algorithm from :class:`~openturns.NLopt`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = solver.getProblem()\nlocal_solver = ot.NLopt(problem, \"LD_SLSQP\")\ncovarianceModel = ot.SquaredExponential(maximum_scale_bounds, [1.0])\nalgo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nalgo.setOptimizationAlgorithm(local_solver)\nalgo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "finetune_covariance_model = result.getCovarianceModel()\nprint(finetune_covariance_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "printCovarianceParameterChange(finetune_covariance_model, basic_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure the global optimization solver\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following example checks the robustness of the optimization of the\nGaussian process fitter with respect to the optimization of the likelihood\nfunction in the covariance model parameters estimation.\nWe use a :class:`~openturns.MultiStart` algorithm in order to avoid to be trapped by a local minimum.\nFurthermore, we generate the design of experiments using a\n:class:`~openturns.LHSExperiment`, which guarantees that the points\nwill fill the space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_train = 10\nX_train = myDistribution.getSample(sampleSize_train)\nY_train = model(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we create a multivariate distribution, based on independent\n:class:`~openturns.Uniform` marginals which have the bounds required\nby the covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distributions = [ot.Uniform(lbounds[i], ubounds[i]) for i in range(dim)]\nboundedDistribution = ot.JointDistribution(distributions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first generate a Latin Hypercube Sampling (LHS) design made of 25 points in the sample space.\nThis LHS is optimized so as to fill the space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "K = 25  # design size\nLHS = ot.LHSExperiment(boundedDistribution, K)\nSA_profile = ot.GeometricProfile(10.0, 0.95, 20000)\nLHS_optimization_algo = ot.SimulatedAnnealingLHS(LHS, ot.SpaceFillingC2(), SA_profile)\nLHS_optimization_algo.generate()\nLHS_design = LHS_optimization_algo.getResult()\nstarting_points = LHS_design.getOptimalDesign()\nstarting_points.getSize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a :class:`~openturns.MultiStart` algorithm based on the LHS starting points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solver.setMaximumIterationNumber(10000)\nmultiStartSolver = ot.MultiStart(solver, starting_points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we configure the optimization algorithm so as to use the :class:`~openturns.MultiStart`\nalgorithm. The bounds of the algorithm are set to match the range of the distribution used to\ngenerate the starting points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.GaussianProcessFitter(X_train, Y_train, covarianceModel, basis)\nalgo.setOptimizationAlgorithm(multiStartSolver)\nalgo.run()\nresult = algo.getResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "finetune_covariance_model = result.getCovarianceModel()\nprint(finetune_covariance_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "printCovarianceParameterChange(finetune_covariance_model, basic_covariance_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there are changes in the estimated parameters.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display figures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}