
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_reliability_sensitivity/central_dispersion/plot_central_tendency.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_reliability_sensitivity_central_dispersion_plot_central_tendency.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_reliability_sensitivity_central_dispersion_plot_central_tendency.py:


Analyse the central tendency of a cantilever beam
=================================================

.. GENERATED FROM PYTHON SOURCE LINES 6-7

In this example we perform a central tendency analysis of a random variable Y using the various methods available. We consider the :ref:`cantilever beam <use-case-cantilever-beam>` example and show how to use the `TaylorExpansionMoments` and `ExpectationSimulationAlgorithm` classes.

.. GENERATED FROM PYTHON SOURCE LINES 9-16

.. code-block:: default

    from __future__ import print_function
    from openturns.usecases import cantilever_beam as cantilever_beam
    import openturns as ot
    import openturns.viewer as viewer
    from matplotlib import pylab as plt
    ot.Log.Show(ot.Log.NONE)








.. GENERATED FROM PYTHON SOURCE LINES 17-18

We first load the data class from the usecases module :

.. GENERATED FROM PYTHON SOURCE LINES 18-20

.. code-block:: default

    cb = cantilever_beam.CantileverBeam()








.. GENERATED FROM PYTHON SOURCE LINES 21-22

We want to create the random variable of interest Y=g(X) where :math:`g(.)` is the physical model and :math:`X` is the input vectors. For this example we consider independent marginals.

.. GENERATED FROM PYTHON SOURCE LINES 24-25

We set a `mean` vector and a unitary standard deviation :

.. GENERATED FROM PYTHON SOURCE LINES 25-30

.. code-block:: default

    dim = cb.dim
    mean = [50.0, 1.0, 10.0, 5.0]
    sigma = [1.0] * dim
    R = ot.IdentityMatrix(dim)








.. GENERATED FROM PYTHON SOURCE LINES 31-32

We create the input parameters distribution and make a random vector :

.. GENERATED FROM PYTHON SOURCE LINES 32-36

.. code-block:: default

    distribution = ot.Normal(mean, sigma, R)
    X = ot.RandomVector(distribution)
    X.setDescription(['E', 'F', 'L', 'I'])








.. GENERATED FROM PYTHON SOURCE LINES 37-38

`f` is the cantilever beam model :

.. GENERATED FROM PYTHON SOURCE LINES 38-40

.. code-block:: default

    f = cb.model








.. GENERATED FROM PYTHON SOURCE LINES 41-42

The random variable of interest Y is then

.. GENERATED FROM PYTHON SOURCE LINES 42-45

.. code-block:: default

    Y = ot.CompositeRandomVector(f, X)
    Y.setDescription('Y')








.. GENERATED FROM PYTHON SOURCE LINES 46-48

Taylor expansion
----------------

.. GENERATED FROM PYTHON SOURCE LINES 50-51

Perform Taylor approximation to get the expected value of Y and the importance factors.

.. GENERATED FROM PYTHON SOURCE LINES 53-65

.. code-block:: default

    taylor = ot.TaylorExpansionMoments(Y)
    taylor_mean_fo = taylor.getMeanFirstOrder()
    taylor_mean_so = taylor.getMeanSecondOrder()
    taylor_cov = taylor.getCovariance()
    taylor_if = taylor.getImportanceFactors()
    print('model evaluation calls number=', f.getGradientCallsNumber())
    print('model gradient calls number=', f.getGradientCallsNumber())
    print('model hessian calls number=', f.getHessianCallsNumber())
    print('taylor mean first order=', taylor_mean_fo)
    print('taylor variance=', taylor_cov)
    print('taylor importance factors=', taylor_if)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    model evaluation calls number= 1
    model gradient calls number= 1
    model hessian calls number= 1
    taylor mean first order= [1.33333]
    taylor variance= [[ 2.0096 ]]
    taylor importance factors= [E : 0.000353857, F : 0.884642, L : 0.079618, I : 0.0353857]




.. GENERATED FROM PYTHON SOURCE LINES 66-69

.. code-block:: default

    graph = taylor.drawImportanceFactors()
    view = viewer.View(graph)




.. image-sg:: /auto_reliability_sensitivity/central_dispersion/images/sphx_glr_plot_central_tendency_001.png
   :alt: Importance Factors from Taylor expansions - Y
   :srcset: /auto_reliability_sensitivity/central_dispersion/images/sphx_glr_plot_central_tendency_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 70-71

We see that, at first order, the variable :math:`F` explains 88.5% of the variance of the output :math:`Y`. On the other hand, the variable :math:`E` is not significant in the variance of the output: at first order, the random variable :math:`E` could be replaced by a constant with no change to the output variance.

.. GENERATED FROM PYTHON SOURCE LINES 73-75

Monte-Carlo simulation
----------------------

.. GENERATED FROM PYTHON SOURCE LINES 77-78

Perform a Monte Carlo simulation of Y to estimate its mean.

.. GENERATED FROM PYTHON SOURCE LINES 80-90

.. code-block:: default

    algo = ot.ExpectationSimulationAlgorithm(Y)
    algo.setMaximumOuterSampling(1000)
    algo.setCoefficientOfVariationCriterionType('NONE')
    algo.run()
    print('model evaluation calls number=', f.getEvaluationCallsNumber())
    expectation_result = algo.getResult()
    expectation_mean = expectation_result.getExpectationEstimate()
    print('monte carlo mean=', expectation_mean, 'var=',
          expectation_result.getVarianceEstimate())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    model evaluation calls number= 1001
    monte carlo mean= [1.45846] var= [0.00299836]




.. GENERATED FROM PYTHON SOURCE LINES 91-93

Central dispersion analysis based on a sample
---------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 95-96

Directly compute statistical moments based on a sample of Y. Sometimes the probabilistic model is not available and the study needs to start from the data.

.. GENERATED FROM PYTHON SOURCE LINES 98-104

.. code-block:: default

    Y_s = Y.getSample(1000)
    y_mean = Y_s.computeMean()
    y_stddev = Y_s.computeStandardDeviation()
    y_quantile_95p = Y_s.computeQuantilePerComponent(0.95)
    print('mean=', y_mean, 'stddev=', y_stddev, 'quantile@95%', y_quantile_95p)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    mean= [1.40943] stddev= [1.63795] quantile@95% [4.36899]




.. GENERATED FROM PYTHON SOURCE LINES 105-110

.. code-block:: default

    graph = ot.KernelSmoothing().build(Y_s).drawPDF()
    graph.setTitle("Kernel smoothing approximation of the output distribution")
    view = viewer.View(graph)

    plt.show()



.. image-sg:: /auto_reliability_sensitivity/central_dispersion/images/sphx_glr_plot_central_tendency_002.png
   :alt: Kernel smoothing approximation of the output distribution
   :srcset: /auto_reliability_sensitivity/central_dispersion/images/sphx_glr_plot_central_tendency_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.178 seconds)


.. _sphx_glr_download_auto_reliability_sensitivity_central_dispersion_plot_central_tendency.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_central_tendency.py <plot_central_tendency.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_central_tendency.ipynb <plot_central_tendency.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
