
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Random Mixture: affine combination of independent univariate distributions &#8212; OpenTURNS 1.13 documentation</title>
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Stochastic process definitions" href="process_definitions.html" />
    <link rel="prev" title="Copulas" href="copulas.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="process_definitions.html" title="Stochastic process definitions"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.13 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" accesskey="U">Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="copulas.html"
                        title="previous chapter">Copulas</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="process_definitions.html"
                        title="next chapter">Stochastic process definitions</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/probabilistic_modeling/random_mixture.rst"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="random-mixture-affine-combination-of-independent-univariate-distributions">
<span id="random-mixture"></span><h1>Random Mixture: affine combination of independent univariate distributions<a class="headerlink" href="#random-mixture-affine-combination-of-independent-univariate-distributions" title="Permalink to this headline">¶</a></h1>
<p>A multivariate random variable <img class="math" src="../../_images/math/913734e192ace9502183e13f27fa7cdaa278491c.svg" alt="\vect{Y}"/> may be defined as an
affine transform of <img class="math" src="../../_images/math/6dd74dfb7ff6eff513acaa90195f45bb6f794012.svg" alt="n"/> independent univariate random variable, as
follows:</p>
<div class="math" id="equation-randommixtureformula">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-randommixtureformula" title="Permalink to this equation">¶</a></span><img src="../../_images/math/31d9b6378226134a351e00eeaef4bacf9718f1b5.svg" alt="\displaystyle \vect{Y}=\vect{y}_0+\mat{M}\,\vect{X}"/></p>
</div><p>where <img class="math" src="../../_images/math/72a364dcf671d8c4ac030fd67cf6ae4ab1e58b06.svg" alt="\vect{y}_0\in\mathbb{R}^d"/> is a deterministic vector with
<img class="math" src="../../_images/math/d953a9c0555e44586616b1716a319d8a1af1def6.svg" alt="d\in\{1,2,3\}"/>, <img class="math" src="../../_images/math/f1a7b4380e2aa958962acf08c4b7ebaeede2356f.svg" alt="\mat{M}\in\mathcal{M}_{d,n}(\mathbb{R})"/> a
deterministic matrix and <img class="math" src="../../_images/math/5dd32ed5b0cf4f886fc1148f9c582e630b1d3a93.svg" alt="(X_k)_{ 1 \leq k \leq n}"/> are some
independent univariate distributions.</p>
<p>In such a case, it is possible to evaluate directly the distribution of
<img class="math" src="../../_images/math/913734e192ace9502183e13f27fa7cdaa278491c.svg" alt="\vect{Y}"/> and then to ask <img class="math" src="../../_images/math/913734e192ace9502183e13f27fa7cdaa278491c.svg" alt="\vect{Y}"/> any request compatible
with a distribution: moments, probability and cumulative density
functions, quantiles (in dimension 1 only) …</p>
<p><strong>Evaluation of the probability density function of the Random Mixture</strong></p>
<p>As the univariate random variables <img class="math" src="../../_images/math/0c49e7ab7fbccf79336de449852464b92997cebf.svg" alt="X_i"/> are independent, the
characteristic function of <img class="math" src="../../_images/math/913734e192ace9502183e13f27fa7cdaa278491c.svg" alt="\vect{Y}"/>, denoted <img class="math" src="../../_images/math/d4c7bef0027c36d987ee86aa07a13c6a3e916253.svg" alt="\phi_Y"/>, is
easily defined from the characteristic function of <img class="math" src="../../_images/math/2021bb9bcd3b560cee9b48615573386c3ec6688e.svg" alt="X_k"/> denoted
<img class="math" src="../../_images/math/c90500619c8467c4785fe317ff118b46bf1e2968.svg" alt="\phi_{X_k}"/> as follows :</p>
<div class="math" id="equation-charactfuncy">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-charactfuncy" title="Permalink to this equation">¶</a></span><img src="../../_images/math/937195032624546e0d0732a83101c2b86677b2ec.svg" alt="\displaystyle \phi_Y(u_1,\hdots,u_d)=\prod_{j=1}^de^{iu_j{y_0}_j}\prod_{k=1}^n\phi_{X_k}((M^tu)_k), \mbox{  for } \vect{u}\in\mathbb{R}^d"/></p>
</div><div class="line-block">
<div class="line">Once <img class="math" src="../../_images/math/d4c7bef0027c36d987ee86aa07a13c6a3e916253.svg" alt="\phi_Y"/> evaluated, it is possible to evaluate the
probability density function of <img class="math" src="../../_images/math/4ba98ea8d3f7155af1e417ab4b42772c0e55b77b.svg" alt="Y"/>, denoted <img class="math" src="../../_images/math/de5b9ca002680d3fc807c02a9c1d233b326272d0.svg" alt="p_Y"/> :
several techniques are possible, as the inversion of the Fourier
transformation. This technique is not easy to implement.</div>
<div class="line">Another technique is used, based on the Poisson sum
formulation, defined as follows:</div>
</div>
<blockquote>
<div><div class="math" id="equation-poissonsum">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-poissonsum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/5041ee2b8a51bae41373ad814ae1cfe507e8709a.svg" alt="\displaystyle \sum_{j_1\in\mathbb{Z}}\hdots\sum_{j_d\in\mathbb{Z}} p_Y\left(y_1+\frac{2\pi j_1}{h_1},\hdots,y_d+\frac{2\pi j_d}{h_d}\right)=
     \prod_{j=1}^d \frac{h_j}{2*\pi}\sum_{k_1\in\mathbb{Z}}\hdots\sum_{k_d\in\mathbb{Z}}\phi\left(k_1h_1,\hdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<div class="line-block">
<div class="line">By fixing <img class="math" src="../../_images/math/924589887f054393aab0830ed750fcc5e88bed71.svg" alt="h_1,\hdots,h_d"/> small enough,
<img class="math" src="../../_images/math/b093ba13fba151bb178f017f3ab405efa25435da.svg" alt="\frac{2k\pi}{h_j} \approx +\infty"/> and
<img class="math" src="../../_images/math/1b6111fac3970ecbe80b0c642e9ac0127622b8ae.svg" alt="p_Y(\hdots,\frac{2k\pi}{h_j},\hdots) \approx 0"/> because of the
decreasing properties of <img class="math" src="../../_images/math/de5b9ca002680d3fc807c02a9c1d233b326272d0.svg" alt="p_Y"/>. Thus the nested sums of the left
term of <a class="reference internal" href="#equation-poissonsum">(3)</a> are reduced to the central term
<img class="math" src="../../_images/math/9c877892e5adf6a6474f4cc1302defca284ca0dc.svg" alt="j_1=\hdots=j_d = 0"/>: the left term is approximatively equal to
<img class="math" src="../../_images/math/8fd8ca74656d07f9162e6a5297358b5c094ebd65.svg" alt="p_Y(y)"/>.</div>
<div class="line">Furthermore, the right term of <a class="reference internal" href="#equation-poissonsum">(3)</a> is a series which
converges very fast: only few terms of the series are enough to get
machine-precision accuracy. Let us note that the factors
<img class="math" src="../../_images/math/778b8dc966c07d30650631ef3bcb2ccfc551bdb4.svg" alt="\phi_Y(k_1 h_1,\hdots,k_d,h_d)"/>, which are expensive to
evaluate, do not depend on <img class="math" src="../../_images/math/402d8905ff602c0ce7eb39f8eeb3e22cba377458.svg" alt="y"/> and are evaluated once only.</div>
</div>
<div class="line-block">
<div class="line">It is also possible to greatly improve the performance of the
algorithm by noticing that equation  is linear between <img class="math" src="../../_images/math/de5b9ca002680d3fc807c02a9c1d233b326272d0.svg" alt="p_Y"/> and
<img class="math" src="../../_images/math/d4c7bef0027c36d987ee86aa07a13c6a3e916253.svg" alt="\phi_Y"/>. We denote <img class="math" src="../../_images/math/45e776cbb6e921ae302f897c160a3ca71f216ffc.svg" alt="q_Y"/> and <img class="math" src="../../_images/math/fa38d4f205646d6e9dc575cb7e8e67d133c3bcb0.svg" alt="\psi_Y"/> respectively
the density and the characteristic function of the multivariate normal
distribution with the same mean <img class="math" src="../../_images/math/11f544f586ee762775393fc0da4416d9252b840c.svg" alt="\vect{\mu}"/> and same covariance
matrix <img class="math" src="../../_images/math/e39843bf8885a11b1e7318f3e9267a681a6ae2b1.svg" alt="\vect{C}"/> as the random mixture. By applying this
multivariate normal distribution to the equation , we obtain by
subtraction:</div>
</div>
<blockquote>
<div><div class="math" id="equation-algopoisson">
<p><span class="eqno">(4)<a class="headerlink" href="#equation-algopoisson" title="Permalink to this equation">¶</a></span><img src="../../_images/math/2e5fd2351215fb818a989b57b40c3d5f5cec22d1.svg" alt="\displaystyle  p_Y\left(y\right) = \sum_{j\in\mathbb{Z}^d} q_Y\left(y_1+\frac{2\pi j_1}{h_1},\cdots,y_d+\frac{2\pi j_d}{h_d}\right)+
   \frac{H}{2^d\pi^d}\sum_{|k_1|\leq N}\cdots\sum_{|k_d|\leq N} \delta_Y\left(k_1h_1,\cdots,k_dh_d\right)e^{-\imath(\sum_{m=1}^{d}k_m h_m y_m)}"/></p>
</div></div></blockquote>
<p>where <img class="math" src="../../_images/math/b6ae953bb5169ed5769974c151270b355d32eac1.svg" alt="H = h_1\times\cdots\times h_d"/>,
<img class="math" src="../../_images/math/0f1e16b5971888dd9ed8943f7a686613034240c9.svg" alt="j=(j_1,\cdots,j_d)"/>, <img class="math" src="../../_images/math/57a6b19b2962eb4b5092ee5d586a6315a5a531ff.svg" alt="\delta_Y:=\phi_Y - \psi_Y"/></p>
<div class="line-block">
<div class="line">In the case where <img class="math" src="../../_images/math/bffe73cb85dc44d22919ada30bc19fab41e76218.svg" alt="n \gg 1"/>, using the limit central theorem,
the law of <img class="math" src="../../_images/math/913734e192ace9502183e13f27fa7cdaa278491c.svg" alt="\vect{Y}"/> tends to the normal distribution density
<img class="math" src="../../_images/math/3c10e814283ce7133a78f5358fc356e630645515.svg" alt="q"/>, which will drastically reduce <img class="math" src="../../_images/math/740219495c5b12f680f503149cd6a3d24d7374cb.svg" alt="N"/>. The sum on
<img class="math" src="../../_images/math/3c10e814283ce7133a78f5358fc356e630645515.svg" alt="q"/> will become the most CPU-intensive part, because in the
general case we will have to keep more terms than the central one in
this sum, since the parameters <img class="math" src="../../_images/math/27a39da76904020d80b953dd86f077c4b86e0c66.svg" alt="h_1, \dots  h_d"/> were
calibrated with respect to <img class="math" src="../../_images/math/e9249c6624ce2eed5d9b7699218488ba3379014e.svg" alt="p"/> and not <img class="math" src="../../_images/math/3c10e814283ce7133a78f5358fc356e630645515.svg" alt="q"/>.</div>
</div>
<p>The parameters <img class="math" src="../../_images/math/27a39da76904020d80b953dd86f077c4b86e0c66.svg" alt="h_1, \dots  h_d"/> are calibrated using the
following formula:</p>
<div class="math">
<p><img src="../../_images/math/092c42edf1735b9a3d2ac973ac4241bfed5f14f4.svg" alt="h_\ell = \frac{2\pi}{(\beta+4\alpha)\sigma_\ell}"/></p>
</div><p>where <img class="math" src="../../_images/math/f440ecffa9ba1148f347f30505ca52cf3b82aa4e.svg" alt="\sigma_\ell=\sqrt{\Cov{\vect{Y}}_{\ell,\ell}}"/> and
<img class="math" src="../../_images/math/b3ea4a8b66bdc26891f89769bec9e5f37f304158.svg" alt="\alpha"/>, <img class="math" src="../../_images/math/3cb3e8e0e4d1ad4f2c235e206213d16e20ebf7a0.svg" alt="\beta"/> are respectively the number of standard
deviations covered by the marginal distribution (<img class="math" src="../../_images/math/fb5ed3cf93c2239bf26e4e55401c6003fc689958.svg" alt="\alpha=5"/> by
default) and <img class="math" src="../../_images/math/3cb3e8e0e4d1ad4f2c235e206213d16e20ebf7a0.svg" alt="\beta"/> the number of marginal deviations beyond
which the density is negligible (<img class="math" src="../../_images/math/9b3fe6727216da33d29919b43bb01e5a117803f0.svg" alt="\beta=8.5"/> by default).</p>
<p>The <img class="math" src="../../_images/math/740219495c5b12f680f503149cd6a3d24d7374cb.svg" alt="N"/> parameter is dynamically calibrated: we start with
<img class="math" src="../../_images/math/1bcee8e26e8e8667b64a719de1422d1667c62af8.svg" alt="N=8"/> then we double <img class="math" src="../../_images/math/740219495c5b12f680f503149cd6a3d24d7374cb.svg" alt="N"/> value until the total contribution
of the additional terms is negligible.</p>
<p><strong>Evaluation of the moments of the Random Mixture</strong></p>
<p>The relation <a class="reference internal" href="#equation-randommixtureformula">(1)</a> enables to evaluate all the
moments of the random mixture, if mathematically defined. For example,
we have:</p>
<div class="math">
<p><img src="../../_images/math/59625a5826bb4a6053411b15eb66830c33757679.svg" alt="\left\{
\begin{array}{lcl}
  \Expect{\vect{Y}} &amp; = &amp; \vect{y_0} + \mat{M}\Expect{\vect{X}} \\
  \Cov{\vect{Y}} &amp; = &amp; \mat{M}\,\Cov{\vect{X}}\mat{M}^t
\end{array}\right\}"/></p>
</div><p><strong>Computation on a regular grid</strong></p>
<p>The interest is to compute the density function on a regular grid.
Purposes are to get an approximation quickly. The regular grid is of
form:</p>
<div class="math">
<p><img src="../../_images/math/6c6873e2a178f064a340d277e517107d2d51d653.svg" alt="\begin{aligned}
    \forall r\in\{1,\hdots,d\},\forall m\in\{0,\hdots,M-1\},\:y_{r,m}=\mu_r+b\left(\frac{2m+1}{M} - 1\right)\sigma_r
  \end{aligned}"/></p>
</div><p>By denoting <img class="math" src="../../_images/math/0d6abd4af6e9c919c322ad0de6dc6cac30807264.svg" alt="p_{m_1,\hdots,m_d}=p_{\vect{Y}}(y_{1,m_1},\hdots,y_{d,m_d})"/>:</p>
<div class="math">
<p><img src="../../_images/math/eab3fb146a5f0709a46248d78dc073a9603a1a31.svg" alt="\begin{aligned}
    p_{m_1,\hdots,m_d}= Q_{m_1,\hdots,m_d}+S_{m_1,\hdots,m_d}
  \end{aligned}"/></p>
</div><p>for which the term <img class="math" src="../../_images/math/3b96a73dd74ece3effb2f54999772f120a502232.svg" alt="S_{m_1,\hdots,m_d}"/> is the most CPU
consuming. This term rewrites:</p>
<div class="math">
<p><img src="../../_images/math/687b3e871a4f5dcf545f1b2053eeefee3d3a94d6.svg" alt="\begin{aligned}
  S_{m_1,\hdots,m_d}=&amp;\frac{H}{2^d\pi^d}\sum_{k_1=-N}^{N}\hdots\sum_{k_d=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right)
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \label{Eq:S}
  \end{aligned}"/></p>
</div><p>with:</p>
<div class="math">
<p><img src="../../_images/math/13c1227e2e716d6ebc45cf361fcc4656c13737d5.svg" alt="\begin{aligned}
    \delta\left(k_1h_1,\hdots,k_dh_d\right)&amp;=(\phi-\psi)\left(k_1h_1,\hdots,k_dh_d\right)\\
    E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^d k_jh_j\left(\mu_j+b\left(\frac{2m_j+1}{M}-1\right)\sigma_j\right)}
  \end{aligned}"/></p>
</div><p>The aim is to rewrite the previous expression as a <img class="math" src="../../_images/math/e850273a52c7b4f7137b8cd36bf72c0825f8a6d7.svg" alt="d"/>- discrete
Fourier transform, in order to apply Fast Fourier Transform (<em>FFT</em>) for
its evaluation.</p>
<p>We set <img class="math" src="../../_images/math/eaab41328b18690ecf83a1c720c76e1fba455b44.svg" alt="M=N"/> and
<img class="math" src="../../_images/math/6dc70c1e4735494d350985976b198e937d01838c.svg" alt="\forall j \in\{1,\hdots,d\},\: h_j=\frac{\pi}{b\sigma_j}"/> and
<img class="math" src="../../_images/math/0626771d9ad496819e6e3343692a850ba0374b1e.svg" alt="\tau_j=\frac{\mu_j}{b\sigma_j}"/>. For convenience, we introduce
the functions:</p>
<div class="math">
<p><img src="../../_images/math/34f69b9b505382b14daecf392f352680a17c7912.svg" alt="f_j(k) = e^{-i\pi (k+1)\left(\tau_j-1+\frac{1}{N}\right)}"/></p>
</div><p>We use <img class="math" src="../../_images/math/7cac362a436251f751e63568a69a48d1965c8668.svg" alt="k+1"/> instead of <img class="math" src="../../_images/math/f544e05e753d1c4bb22bd79ef7ff6cdfa9abf204.svg" alt="k"/> in this function to simplify
expressions below.</p>
<p>We obtain:</p>
<div class="math">
<p><img src="../../_images/math/03145180a54f21a476c896a0ae0360a8a9664574.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)&amp;=e^{-i\sum_{j=1}^{d} k_jh_jb\sigma_j\left(\frac{\mu_j}{b\sigma_j}+\frac{2m_j}{N}+\frac{1}{N}-1\right)}\notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)}e^{-i\pi\sum_{j=1}^{d} k_j\left(\tau_j-1+\frac{1}{N}\right)} \notag\\
    &amp;=e^{-2i\pi\left(\frac{\sum_{j=1}^{d}k_j m_j}{N}\right)} f_1(k_1-1) \times\hdots\times f_d(k_d-1) \label{Eq:E}
  \end{aligned}"/></p>
</div><p>For performance reasons, we want to use the discrete Fourier transform
with the following convention in dimension 1:</p>
<div class="math">
<p><img src="../../_images/math/f97841d76d4772c31087b8283bd5584293c628aa.svg" alt="A_m = \sum_{k=0}^{N-1} a_k e^{-2i\pi\frac{km}{N}}"/></p>
</div><p>which extension to dimensions 2 and 3 are respectively:</p>
<div class="math">
<p><img src="../../_images/math/ca8cc796ace178ffa4f2062c43244b6fc1772973.svg" alt="A_{m,n} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1} a_{k,l} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}}\\"/></p>
</div><div class="math">
<p><img src="../../_images/math/806d699cba8b946cadf8959cb8e62f13b3077fe5.svg" alt="A_{m,n,p} = \sum_{k=0}^{N-1}\sum_{l=0}^{N-1}\sum_{s=0}^{N-1} a_{k,l,s} e^{-2i\pi\frac{km}{N}} e^{-2i\pi\frac{ln}{N}} e^{-2i\pi\frac{sp}{N}}"/></p>
</div><p>We decompose sums of  on the interval <img class="math" src="../../_images/math/c6907f2130d0230a1dcb92472470c8e8e98a31aa.svg" alt="[-N,N]"/> into three parts:</p>
<div class="math" id="equation-decomposition-sum">
<p><span class="eqno">(5)<a class="headerlink" href="#equation-decomposition-sum" title="Permalink to this equation">¶</a></span><img src="../../_images/math/9059aeaebad9b48009332442a7e598591e712463.svg" alt="\begin{aligned}
    \sum_{k_j=-N}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
      = &amp; \sum_{k_j=-N}^{-1} \delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d) \notag\\
      &amp; + \delta\left(k_1h_1,\hdots,0,\hdots,k_dh_d\right) E_{m_1,\hdots,0,\hdots,m_d}(k_1,\hdots,0,\hdots,k_d) \notag\\
      &amp; + \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
    \end{aligned}"/></p>
</div><p>If we already computed <img class="math" src="../../_images/math/48c7a0639965f004990b84abef832ef3c61359dd.svg" alt="E"/> for dimension <img class="math" src="../../_images/math/c21e0766ef49d42322f8a94e45c4bdf8a058b37a.svg" alt="d-1"/>, then the
middle term in this sum is trivial.</p>
<p>To compute the last sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/26e18ee622ea363a0093fa119f8367d13a7373a0.svg" alt="k_j'=k_j-1"/>:</p>
<div class="math">
<p><img src="../../_images/math/d4cfcefc7df665a87fdb571b5ae5f2b00e3c2a58.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation gives:</p>
<div class="math">
<p><img src="../../_images/math/6daab59509f441970c2701975f7502d27e5837ac.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j+1,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} +\frac{m_j}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)\notag\\
  &amp;=
      e^{-2i\pi\left(\frac{m_j}{N}\right)}
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus</p>
<div class="math">
<p><img src="../../_images/math/335bce344a54def30f27fdf777be3ce25777d132.svg" alt="\begin{aligned}
  \sum_{k_j=1}^{N}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = e^{-2i\pi\left(\frac{m_j}{N}\right)} \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j+1)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma+}
  \end{aligned}"/></p>
</div><p>To compute the first sum of equation, we apply a change of variable
<img class="math" src="../../_images/math/5e21aa05eecdb9014fe62eaae08e5aabd06e8cc2.svg" alt="k_j'=N+k_j"/>:</p>
<div class="math">
<p><img src="../../_images/math/b8897c715c8ecd72cb1536b06ba524fca19fa69b.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}(k_1,\hdots,k_d)
  = &amp; \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; \hspace*{3cm} E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  \end{aligned}"/></p>
</div><p>Equation  gives:</p>
<div class="math">
<p><img src="../../_images/math/92bb0ae13fa3b9886945c67a9d58a77d718e4c8e.svg" alt="\begin{aligned}
  E_{m_1,\hdots,m_d}(k_1,\hdots,k_j-N,\hdots,k_d)
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N} -m_j\right)}
      f_1(k_1-1)\times\hdots\times f_j(k_j-1-N)\times\hdots\times f_d(k_d-1) \notag\\
  &amp;=
      e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1)
  \end{aligned}"/></p>
</div><p>Thus:</p>
<div class="math">
<p><img src="../../_images/math/ce964d5d8f86a9b4244d71c933bf5a100f193b8c.svg" alt="\begin{aligned}
  \sum_{k_j=-N}^{-1}\delta\left(k_1h_1,\hdots,k_dh_d\right) E_{m_1,\hdots,m_d}&amp;(k_1,\hdots,k_d)
    = \sum_{k_j=0}^{N-1}\delta\left(k_1h_1,\hdots,(k_j-N)h_j,\hdots,k_dh_d\right) \times\notag\\
    &amp; e^{-2i\pi\left(\frac{\sum_{l=1}^{d}k_l m_l}{N}\right)}
      f_1(k_1-1)\times\hdots\times \overline{f}_j(N-1-k_j)\times\hdots\times f_d(k_d-1) \label{Eq:j-sigma-}
  \end{aligned}"/></p>
</div><p>To summarize:</p>
<ol class="arabic simple">
<li><p>In order to compute sum from <img class="math" src="../../_images/math/aa6bef91bcf4e6b1059eeb446b5ef7ea5b82e653.svg" alt="k_1=1"/> to <img class="math" src="../../_images/math/740219495c5b12f680f503149cd6a3d24d7374cb.svg" alt="N"/>, we multiply
by <img class="math" src="../../_images/math/6cf10fd0738395845a461d3ea9989dd7557e0f2f.svg" alt="e^{-2i\pi\left(\frac{m_1}{N}\right)}"/> and consider
<img class="math" src="../../_images/math/2e9a47d541aa34922884e27f3c62ac63f5381c49.svg" alt="\delta((k_1+1)h,\hdots)f_1(k_1)"/></p></li>
<li><p>In order to compute sum from <img class="math" src="../../_images/math/2f4d377138385be7a5a31c7969c6fd60f1a46dd9.svg" alt="k_1=-N"/> to <img class="math" src="../../_images/math/40443e67288a66de04fc44e0f1e3eec87bd4b93b.svg" alt="-1"/>, we
consider <img class="math" src="../../_images/math/247b561d81088dc29e256a0c606767650fd72450.svg" alt="\delta((k_1-N)h,\hdots)\overline{f}_1(N-1-k_1)"/></p></li>
</ol>
<div class="topic">
<p class="topic-title first">API:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../user_manual/_generated/openturns.RandomMixture.html#openturns.RandomMixture" title="openturns.RandomMixture"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMixture</span></code></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution.html"><span class="doc">Create a random mixture of distributions</span></a></p></li>
<li><p>See <a class="reference internal" href="../../examples/probabilistic_modeling/random_mixture_distribution_discrete.html"><span class="doc">Create a discrete random mixture</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">References:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../bibliography.html#abate1992" id="id1"><span>[abate1992]</span></a></p></li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="process_definitions.html" title="Stochastic process definitions"
             >next</a> |</li>
        <li class="right" >
          <a href="copulas.html" title="Copulas"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.13 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="probabilistic_modeling.html" >Probabilistic modeling</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2019 Airbus-EDF-IMACS-Phimeca.
      Last updated on Jun 06, 2019.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.0.
    </div>
  </body>
</html>