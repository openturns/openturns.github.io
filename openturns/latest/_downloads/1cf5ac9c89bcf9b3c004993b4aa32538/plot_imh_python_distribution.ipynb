{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sampling from an unscaled probability density\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we show different ways to sample a distribution which PDF is known up to a normalization constant:\n\n- Case 1: computing the normalization factor and using a :class:`~openturns.PythonDistribution`,\n- Case 2: using the Ratio of Uniforms algorithm with the class :class:`~openturns.experimental.RatioOfUniforms`\n- Case 3: using some Metropolis-Hastings algorithms with the class :class:`~openturns.IndependentMetropolisHastings`\n  and :class:`~openturns.RandomWalkMetropolisHastings`.\n\nConsider a distribution whose\nprobability density function $p$ is known up to the normalization factor $c$:\nlet $f$ be a function such that\n$p = cf$ with $c \\in \\Rset^+_*$.\n\nWe illustrate the case with:\n\n\\begin{align}f(x) = \\frac{1}{2} (2 + \\sin(x)^2) \\exp \\left[- \\left(2 + \\cos(3x)^3 + \\sin(2x)^3 \\right) x\n    \\right]  \\mathbf{1}_{[0, 2 \\pi]}(x).\\end{align}\n\nFirst, we draw the unscaled probability density function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.experimental as otexp\nimport openturns.viewer as otv\nfrom math import pi\nfrom time import monotonic\n\not.RandomGenerator.SetSeed(1)\nf = ot.SymbolicFunction(\n    \"x\", \"0.5 * (2 + sin(x)^2) * exp( -( 2 + cos(3*x)^3 + sin(2*x)^3) * x )\"\n)\nlower_bound = 0.0\nupper_bound = 2.0 * pi\nrange_PDF = ot.Interval(lower_bound, upper_bound)\ngraph = f.draw(lower_bound, upper_bound, 512)\ngraph.setTitle(\n    r\"Christian Robert function: $f(x) =  0.5(2 + sin^2 x) e^{ -x( 2 + cos^33x + sin^3 2x)}, \\quad x \\in [0, 2\\pi]$\"\n)\ngraph.setXTitle(\"x\")\ngraph.setYTitle(r\"$f(x)$\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 1: Computation of the normalization factor\nThe best thing to do is to compute the normalization factor thanks to the integration algorithms of the library.\n\nWe show how to compute the normalization factor using a :class:`~openturns.GaussKronrod` quadrature formula.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "denom_fact = ot.GaussKronrod().integrate(f, range_PDF)[0]\nnorm_fact = 1.0 / denom_fact\nprint(\"normalization factor = \", norm_fact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, we can define the exact PDF expression:\n\n\\begin{align}p(x) = \\dfrac{f(x)}{\\int_0^{2\\pi} f(u)\\, du}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exact_PDF = ot.LinearCombinationFunction([f], [norm_fact])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define a :class:`~openturns.PythonDistribution` which:\n\n- *computePDF* is computed from the exact expression,\n- *computeCDF* is computed using an integration algorithm on the *computePDF*.\n\nDoing that way, we use the generic sampler of the distribution, based on the CDF inversion method,\nimplemented in the *getSample* method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NewDistribution(ot.PythonDistribution):\n    def __init__(self):\n        super(NewDistribution, self).__init__(1)\n        self.PDF_ = exact_PDF\n        self.logPDF_ = ot.ComposedFunction(\n            ot.SymbolicFunction(\"x\", \"log(x)\"), self.PDF_\n        )\n        self.rangeLow_ = 0.0\n        self.rangeUp_ = 2.0 * pi\n\n    def getRange(self):\n        return ot.Interval(self.rangeLow_, self.rangeUp_)\n\n    def computeLogPDF(self, X):\n        if X[0] < self.rangeLow_ or X[0] >= self.rangeUp_:\n            return -ot.SpecFunc.Infinity\n        return self.logPDF_(X)[0]\n\n    def computePDF(self, X):\n        if X[0] < self.rangeLow_ or X[0] >= self.rangeUp_:\n            return 0.0\n        return self.PDF_(X)[0]\n\n    def computeCDF(self, X):\n        if X[0] < self.rangeLow_:\n            return 0.0\n        if X[0] >= self.rangeUp_:\n            return 1.0\n        return ot.GaussLegendre([64]).integrate(\n            self.PDF_, ot.Interval(self.rangeLow_, X[0])\n        )[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the new distribution that uses the generic sampler:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "newDist_generic = ot.Distribution(NewDistribution())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can draw the exact PDF and the PDF estimated from a sample generated by the Ratio of Uniforms algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 500\nsample = newDist_generic.getSample(size)\n\nks_algo = ot.KernelSmoothing()\nks_algo.setBoundaryCorrection(True)\nks_algo.setLowerBound(lower_bound)\nks_algo.setUpperBound(upper_bound)\nks_pdf_GS = ks_algo.build(sample)\n\ng = ks_pdf_GS.drawPDF(-0.5, upper_bound * 1.1, 1001)\ndraw_exact = exact_PDF.draw(lower_bound, upper_bound, 1001).getDrawable(0)\ndraw_exact.setLineWidth(2)\ng.add(draw_exact)\ng.setLegends([\"GS size = \" + str(size), \"exact pdf\"])\ng.setLegendPosition(\"topright\")\ng.setTitle(\"Generic sampler (GS)\")\ng.setXTitle(\"x\")\nview = otv.View(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can change the sampler of that new distribution by implementing the method *getSample* and *getRealization* as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NewDistribution_RoU(ot.PythonDistribution):\n    def __init__(self):\n        super(NewDistribution_RoU, self).__init__(1)\n        self.PDF_ = exact_PDF\n        self.logPDF_ = ot.ComposedFunction(\n            ot.SymbolicFunction(\"x\", \"log(x)\"), self.PDF_\n        )\n        self.rangeLow_ = 0.0\n        self.rangeUp_ = 2.0 * pi\n        self.sampler_ = otexp.RatioOfUniforms(self.logPDF_, self.getRange())\n\n    def getRange(self):\n        return ot.Interval(self.rangeLow_, self.rangeUp_)\n\n    def computeLogPDF(self, X):\n        if X[0] < self.rangeLow_ or X[0] >= self.rangeUp_:\n            return -ot.SpecFunc.Infinity\n        return self.logPDF_(X)[0]\n\n    def computePDF(self, X):\n        if X[0] < self.rangeLow_ or X[0] >= self.rangeUp_:\n            return 0.0\n        return self.PDF_(X)[0]\n\n    def computeCDF(self, X):\n        if X[0] < self.rangeLow_:\n            return 0.0\n        if X[0] >= self.rangeUp_:\n            return 1.0\n        return ot.GaussLegendre([32]).integrate(\n            self.PDF_, ot.Interval(self.rangeLow_, X[0])\n        )[0]\n\n    def getRealization(self):\n        return self.sampler_.getRealization()\n\n    def getSample(self, n):\n        return self.sampler_.getSample(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the new distribution that uses the Ratio of Uniforms sampler:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "newDist_RoU = ot.Distribution(NewDistribution_RoU())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compare the sampling speed of the distribution with the Ratio of Uniforms algorithm to the generic sampling speed.\nThe Ratio of Uniforms algorithm proves to be much quicker than the generic method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sizeRoU = 10000\nsizeGeneric = 100\n\nt0 = monotonic()\nsample_RoU = newDist_RoU.getSample(sizeRoU)\nt1 = monotonic()\nsample_generic = newDist_generic.getSample(sizeGeneric)\nt2 = monotonic()\n\nspeedRoU = sizeRoU / (t1 - t0)\nspeedGeneric = sizeGeneric / (t2 - t1)\nprint(f\"Is Ratio of Uniforms faster ? {speedRoU > 10 * speedGeneric}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 2: Direct use the Ratio of Uniforms algorithm\nIn that case, we want to use the :class:`~openturns.experimental.RatioOfUniforms` algorithm to\nsample $p$. We need to compute the function $\\log f$ and its range.\n\nWe create the function $\\log f$ and the :class:`~openturns.experimental.RatioOfUniforms`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_UnscaledPDF = ot.ComposedFunction(ot.SymbolicFunction(\"x\", \"log(x)\"), f)\nratio_algo = otexp.RatioOfUniforms(log_UnscaledPDF, range_PDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can draw the exact PDF and the PDF estimated from a sample generated by the Ratio of Uniforms algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 100000\nsample = ratio_algo.getSample(size)\n\nks_algo = ot.KernelSmoothing()\nks_algo.setBoundaryCorrection(True)\nks_algo.setLowerBound(lower_bound)\nks_algo.setUpperBound(upper_bound)\nks_pdf = ks_algo.build(sample)\n\ng = ks_pdf.drawPDF(-0.5, upper_bound * 1.1, 1001)\ng.add(draw_exact)\ng.setLegends([\"RoU size = \" + str(size), \"exact PDF\"])\ng.setLegendPosition(\"topright\")\ng.setTitle(\"Ratio of Uniforms (RoU) \")\ng.setXTitle(\"x\")\nview = otv.View(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to facilitate the comparison with the use of Metropolis-Hastings\nbased algorithms, we generate\na sample of the same size and we draw the estimated PDF.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size2 = 500\nsample = ratio_algo.getSample(size2)\n\nks_algo = ot.KernelSmoothing()\nks_algo.setBoundaryCorrection(True)\nks_algo.setLowerBound(lower_bound)\nks_algo.setUpperBound(upper_bound)\nks_pdf_RoU = ks_algo.build(sample)\n\ndraw_RoU = ks_pdf_RoU.drawPDF(-0.5, upper_bound * 1.1, 1001).getDrawable(0)\ndraw_RoU.setLineWidth(2)\ng.add(draw_RoU)\ng.setLegends(\n    [\"RoU size = \" + str(size), \"exact PDF\", \"RoU (size = \" + str(size2) + \")\"]\n)\ng.setTitle(\"Ratio of Uniforms\")\nview = otv.View(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the parameter $r=1$. We can get the associated acceptance ratio:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Acceptance ratio = \", ratio_algo.getAcceptanceRatio())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can estimate the normalization factor with the  Ratio of Uniforms algorithm (see\nthe documenttaion of :class:`~openturns.experimental.RatioOfUniforms`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Normalization factor estimate = \", ratio_algo.getC())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can change the $r$ parameter and check the associated acceptance ratio:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r_new = 0.5\nratio_algo.setR(r_new)\nprint(\"New acceptance ratio = \", ratio_algo.getAcceptanceRatio())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 3(a): Use of Independent Metropolis-Hastings\nLet us use a mixture distribution to approximate the target distribution.\n\nThis approximation will serve as the instrumental distribution\nin the independent Metropolis-Hastings algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp = ot.Exponential(1.0)\nunif = ot.Normal(5.3, 0.4)\ninstrumental_dist = ot.Mixture([exp, unif], [0.9, 0.1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the instrumental density to the exact PDF.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = instrumental_dist.drawPDF(lower_bound, upper_bound, 512)\ngraph.add(draw_exact)\ngraph.setLegends([\"Instrumental PDF\", \"exact PDF\"])\ngraph.setLegendPosition(\"upper right\")\ngraph.setTitle(\"Independent Metropolis-Hastings: Instrumental PDF\")\ngraph.setXTitle(\"x\")\n_ = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":class:`~openturns.MetropolisHastings` and derived classes can work directly with the logarithm of the unscaled\ntarget density.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "log_density = ot.ComposedFunction(ot.SymbolicFunction(\"x\", \"log(x)\"), f)\n\ninitial_State = ot.Point([3.0])  # not important in this case\nindependent_IMH = ot.IndependentMetropolisHastings(\n    log_density, range_PDF, initial_State, instrumental_dist, [0]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get a sample\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_Size = 500\nsample_IMH = independent_IMH.getSample(sample_Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF of the sample to compare it to the target density\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ks_algo = ot.KernelSmoothing()\nks_algo.setBoundaryCorrection(True)\nks_algo.setLowerBound(0.0)\nks_algo.setUpperBound(2.0 * pi)\nposterior_IMH = ks_algo.build(sample_IMH)\n\ng_IMH = posterior_IMH.drawPDF(-0.5, upper_bound * 1.1, 1001)\ng_IMH.add(draw_exact)\ng_IMH.setLegends([\"IMH size = {}\".format(sample_Size), \"exact PDF\"])\ng_IMH.setTitle(\"Independent Metropolis-Hastings (IMH)\")\ng_IMH.setXTitle(\"x\")\ng_IMH.setLegendPosition(\"topright\")\nview = otv.View(g_IMH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even with very few sampling points (500),\nindependent Metropolis-Hastings\n(with a judiciously chosen instrumental distribution)\nmanages to capture the main features of the target density.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 3(b): Use of Random walk Metropolis-Hastings\nLet us use a normal instrumental distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "instrumental_dist = ot.Normal(0.0, 2.5)\nrandomwalk_MH = ot.RandomWalkMetropolisHastings(\n    log_density, range_PDF, initial_State, instrumental_dist, [0]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get a sample\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_RWMH = randomwalk_MH.getSample(sample_Size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF of the sample to compare it to the target density\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ks_algo = ot.KernelSmoothing()\nks_algo.setBoundaryCorrection(True)\nks_algo.setLowerBound(0.0)\nks_algo.setUpperBound(2.0 * pi)\nposterior_RWMH = ks_algo.build(sample_RWMH)\n\ng_RWMH = posterior_RWMH.drawPDF(-0.5, upper_bound * 1.1, 1001)\ng_RWMH.add(draw_exact)\ng_RWMH.setLegends([\"RWMH size = {}\".format(sample_Size), \"exact PDF\"])\ng_RWMH.setTitle(\"Random walk Metropolis-Hastings (RWMH)\")\ng_RWMH.setXTitle(\"x\")\ng_RWMH.setLegendPosition(\"topright\")\nview = otv.View(g_RWMH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final comparison\nWe plot on the same graph the estimated PDF with all the previous algorithms with the same sample size.\nsphinx_gallery_thumbnail_number = 8\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = ks_pdf_GS.drawPDF(-0.5, upper_bound * 1.1, 1001)\ng.add(posterior_RWMH.drawPDF(-0.5, upper_bound * 1.1, 1001))\ng.add(posterior_IMH.drawPDF(-0.5, upper_bound * 1.1, 1001))\ng.add(ks_pdf_RoU.drawPDF(-0.5, upper_bound * 1.1, 1001))\ndraw_exact.setLineStyle(\"dashed\")\ndraw_exact.setColor(\"black\")\ng.add(draw_exact)\ng.setLegends([\"GS\", \"RWMH\", \"IMH\", \"RoU\", \"exact PDF\"])\ng.setTitle(\"Comparison of samplers (size = 500)\")\ng.setXTitle(\"x\")\nview = otv.View(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view.ShowAll()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n[1] Marin , J.M. & Robert, C.P. (2007). *Bayesian Core: A Practical Approach to Computational Bayesian Statistics*. Springer-Verlag, New York\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}