
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_meta_modeling/kriging_metamodel/plot_gpr_choose_trend.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_meta_modeling_kriging_metamodel_plot_gpr_choose_trend.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_meta_modeling_kriging_metamodel_plot_gpr_choose_trend.py:


Gaussian Process Regression: choose a polynomial trend
======================================================

.. GENERATED FROM PYTHON SOURCE LINES 5-10

.. code-block:: Python


    import openturns as ot
    import openturns.experimental as otexp
    import openturns.viewer as otv








.. GENERATED FROM PYTHON SOURCE LINES 11-68

Introduction
------------

In this example, we build a metamodel using a Gaussian process regression whose trend is estimated on a
given data set. We illustrate the impact of the choice of the trend function basis on the metamodel.
This example focuses on three polynomial trends:

- :class:`~openturns.ConstantBasisFactory`;
- :class:`~openturns.LinearBasisFactory`;
- :class:`~openturns.QuadraticBasisFactory`.

At lats, we illustrate that far away from the data set, the Gaussian Process Regression metamodel is entirely
determined by the trend function. Depending on the trend, it might be a bad idea to use the Gaussian process
regression metamodel far away from the training data set.

Refer to :ref:`gaussian_process_regression` to get all the notations and the theoretical aspects.
In the :doc:`/auto_meta_modeling/kriging_metamodel/plot_gpr_beam_trend` example,
we give another example of this method.
In the :doc:`/auto_meta_modeling/kriging_metamodel/plot_gpr_beam_arbitrary_trend` example,
we show how to configure an arbitrary trend.

The model is the function :math:`g: \Rset \rightarrow \Rset` defined by:

.. math::
   \model(x) = x \sin \left( \frac{x}{2} \right), \quad \forall x \in [0,10].

We consider the :class:`~openturns.MaternModel` covariance model.
The covariance model is fixed but its parameters must be calibrated
depending on the data.
The Gaussian process regression metamodel is defined by:

.. math::

   \metaModel(\vect{x})  \Expect{Y(\omega, x)\, | \,  \cC}

where:

.. math::

   Y(\omega, x) = \mu(x) + W(\omega, x)

where :math:`\mu: \Rset \rightarrow \Rset` is the trend function and
:math:`\vect{W}` a Gaussian process of dimension 1 with zero mean and covariance function :math:`\mat{C}`.
We consider the :class:`~openturns.MaternModel` covariance model.

The trend is deterministic and the Gaussian process is probabilistic but they both contribute to the metamodel.
A special feature of the Gaussian process regression metamodel :math:`\metaModel` is the interpolation
property: the metamodel is exact at the training data set.

The objective is to estimate the trend function :math:`\mu` and the parameters of the covariance model,
labelled as *active*: by default, the active parameters are the scale and the amplitude :math:`\vect{\theta} = (\theta, \sigma)` but refer to
:class:`openturns.CovarianceModel` to get details on the activation of the estimation of the other parameters.

Define the model
----------------

We define the model :math:`\model` with a :class:`~openturns.SymbolicFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 68-70

.. code-block:: Python

    model = ot.SymbolicFunction(["x"], ["x * sin(0.5 * x)"])








.. GENERATED FROM PYTHON SOURCE LINES 71-72

We use the following sample to train our metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 72-78

.. code-block:: Python

    xmin = 0.0
    xmax = 10.0
    nTrain = 8
    Xtrain = ot.Uniform(xmin, xmax).getSample(nTrain).sort()
    Xtrain






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>v0</th></tr>
      <tr><th>0</th><td>0.3250275</td></tr>
      <tr><th>1</th><td>1.352764</td></tr>
      <tr><th>2</th><td>3.47057</td></tr>
      <tr><th>3</th><td>5.030402</td></tr>
      <tr><th>4</th><td>6.298766</td></tr>
      <tr><th>5</th><td>8.828052</td></tr>
      <tr><th>6</th><td>9.206796</td></tr>
      <tr><th>7</th><td>9.69423</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 79-80

The values of the model are also needed for training.

.. GENERATED FROM PYTHON SOURCE LINES 80-83

.. code-block:: Python

    Ytrain = model(Xtrain)
    Ytrain






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>y0</th></tr>
      <tr><th>0</th><td>0.05258924</td></tr>
      <tr><th>1</th><td>0.8467968</td></tr>
      <tr><th>2</th><td>3.423725</td></tr>
      <tr><th>3</th><td>2.94895</td></tr>
      <tr><th>4</th><td>-0.0490677</td></tr>
      <tr><th>5</th><td>-8.43802</td></tr>
      <tr><th>6</th><td>-9.152166</td></tr>
      <tr><th>7</th><td>-9.606383</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 84-85

We shall test the model on a set of points based on a regular grid.

.. GENERATED FROM PYTHON SOURCE LINES 85-89

.. code-block:: Python

    nTest = 100
    step = (xmax - xmin) / (nTest - 1)
    x_test = ot.RegularGrid(xmin, step, nTest).getVertices()








.. GENERATED FROM PYTHON SOURCE LINES 90-92

We draw the training points and the model at the testing points. We encapsulate it into a function to use it
again later.

.. GENERATED FROM PYTHON SOURCE LINES 92-111

.. code-block:: Python



    def plot_model(color):
        graph = ot.Graph("", "x", "", True, "")
        y_test = model(x_test)
        curveModel = ot.Curve(x_test, y_test)
        curveModel.setLineStyle("solid")
        curveModel.setColor(color)
        curveModel.setLegend("Model")
        graph.add(curveModel)
        cloud = ot.Cloud(Xtrain, Ytrain)
        cloud.setColor(color)
        cloud.setPointStyle("fsquare")
        cloud.setLegend("Data")
        graph.add(cloud)
        graph.setLegendPosition("bottom")
        return graph









.. GENERATED FROM PYTHON SOURCE LINES 112-117

.. code-block:: Python

    palette = ot.Drawable.BuildDefaultPalette(5)
    graph = plot_model(palette[0])
    graph.setTitle("Model and data set")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_001.svg
   :alt: Model and data set
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_001.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 118-129

Scale the input training sample
-------------------------------

We often have to apply a transform on the input data before performing the Gaussian process regression.
This makes the estimation of the hyperparameters of the Gaussian process regression metamodel
easier for the optimization algorithm.
To do so, we write a linear transform of our input data: we make it unit centered at its mean.
Then we fix the mean and the standard deviation to their values with the :class:`~openturns.ParametricFunction`.
We build the inverse transform as well.

We first compute the mean and standard deviation of the input data.

.. GENERATED FROM PYTHON SOURCE LINES 129-134

.. code-block:: Python

    mean = Xtrain.computeMean()[0]
    stdDev = Xtrain.computeStandardDeviation()[0]
    print("Xtrain, mean: %.3f" % mean)
    print("Xtrain, standard deviation: %.3f" % stdDev)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Xtrain, mean: 5.526
    Xtrain, standard deviation: 3.613




.. GENERATED FROM PYTHON SOURCE LINES 135-140

.. code-block:: Python

    trans_func = ot.SymbolicFunction(["mean", "sigma", "x"], ["(x - mean) / sigma"])
    inv_trans_func = ot.SymbolicFunction(["mean", "sigma", "x"], ["sigma * x + mean"])
    myTransform = ot.ParametricFunction(trans_func, [0, 1], [mean, stdDev])
    myInverseTransform = ot.ParametricFunction(inv_trans_func, [0, 1], [mean, stdDev])








.. GENERATED FROM PYTHON SOURCE LINES 141-142

Scale the input training sample.

.. GENERATED FROM PYTHON SOURCE LINES 142-146

.. code-block:: Python

    scaledXtrain = myTransform(Xtrain)
    scaledXtrain







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>y0</th></tr>
      <tr><th>0</th><td>-1.439601</td></tr>
      <tr><th>1</th><td>-1.15512</td></tr>
      <tr><th>2</th><td>-0.5689025</td></tr>
      <tr><th>3</th><td>-0.1371353</td></tr>
      <tr><th>4</th><td>0.2139527</td></tr>
      <tr><th>5</th><td>0.9140688</td></tr>
      <tr><th>6</th><td>1.018907</td></tr>
      <tr><th>7</th><td>1.15383</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 147-152

Constant basis
--------------

In this paragraph we choose a basis constant for the estimation of the trend.
The basis is built with the :class:`~openturns.ConstantBasisFactory` class.

.. GENERATED FROM PYTHON SOURCE LINES 152-155

.. code-block:: Python

    dimension = 1
    basis = ot.ConstantBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 156-164

We build the Gaussian process regression algorithm on the transformed data, the output data, the covariance
model and the basis.
First, we define the :class:`~openturns.MaternModel` covariance model. The two first parameters
(scale and amplitude) will be updated
but not the third one (which is the :math:`\nu` parameter).

First, we build the :math:`Y(\omega, x)` Gaussian process with the class
:class:`~openturns.experimental.GaussianProcessFitter`.

.. GENERATED FROM PYTHON SOURCE LINES 164-169

.. code-block:: Python

    covarianceModel = ot.MaternModel([1.0], [1.0], 2.5)
    algo_fit = otexp.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()








.. GENERATED FROM PYTHON SOURCE LINES 170-172

Then, we condition the process :math:`Y(\omega, x)` to the data set with the class
:class:`~openturns.experimental.GaussianProcessRegression`.

.. GENERATED FROM PYTHON SOURCE LINES 172-175

.. code-block:: Python

    algo_gpr = otexp.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 176-177

We can get the metamodel on the transformed data:

.. GENERATED FROM PYTHON SOURCE LINES 177-180

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()








.. GENERATED FROM PYTHON SOURCE LINES 181-183

The final metamodel on the initial input data is built with the class
:class:`~openturns.ComposedFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 183-185

.. code-block:: Python

    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 186-187

Define a function to plot the metamodel:

.. GENERATED FROM PYTHON SOURCE LINES 187-198

.. code-block:: Python



    def plot_metamodel(x_test, metamodel, color):
        y_test = metamodel(x_test)
        curve = ot.Curve(x_test, y_test)
        curve.setLineStyle("dashed")
        curve.setColor(color)
        curve.setLegend("Metamodel")
        return curve









.. GENERATED FROM PYTHON SOURCE LINES 199-200

We can draw the metamodel and the model on the same graph.

.. GENERATED FROM PYTHON SOURCE LINES 200-205

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.setTitle("Gaussian Process Regression metamodel: constant trend")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_002.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_002.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 206-209

We also observe the estimated values of the hyperparameters of the trained covariance model.
Note that the scale parameter is related to the transformed data. To get the scale parameter related to
the initial variables, you have to multiply it by the *stdDev* factor.

.. GENERATED FROM PYTHON SOURCE LINES 209-216

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 1.368e+00
    Amplitude parameter: 6.077e+00




.. GENERATED FROM PYTHON SOURCE LINES 217-221

We can display the trend function computed on the transformed data:
:math:`\mu \left(\dfrac{x-m}{\sigma}\right)` where :math:(m, \sigma)` is the mean and standard
deviation of the input data set. We use the method
:meth:`~openturns.experimental.GaussianProcessFitterResult.getTrendCoefficients`.

.. GENERATED FROM PYTHON SOURCE LINES 221-224

.. code-block:: Python

    c0 = fit_result.getTrendCoefficients()
    print("The trend is the curve mu((x-m)/sigma) = %.6e" % c0[0])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The trend is the curve mu((x-m)/sigma) = -2.726223e+00




.. GENERATED FROM PYTHON SOURCE LINES 225-228

We can also get the trend function acting on the transformed data using the method
:meth:`~openturns.experimental.GaussianProcessFitterResult.getMetaModel` of the
class :class:`~openturns.experimental.GaussianProcessFitterResult`.

.. GENERATED FROM PYTHON SOURCE LINES 228-231

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend_transformed_data






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <ul>
      <li> Input dimension = 1  </li>
      <li> Input description = [x0]  </li>
      <li> Output dimension = 1  </li>
      <li> Output description = [y0]  </li>
      <li> Parameter = []  </li>
    </ul>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 232-234

The trend function acting on the initial input data is built with the class
:class:`~openturns.ComposedFunction`.

.. GENERATED FROM PYTHON SOURCE LINES 234-236

.. code-block:: Python

    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 237-238

Define a function to plot the trend.

.. GENERATED FROM PYTHON SOURCE LINES 238-249

.. code-block:: Python



    def plot_trend(x_test, trend_func, color):
        y_test = trend_func(x_test)
        curve = ot.Curve(x_test, y_test)
        curve.setLineStyle("dotdash")
        curve.setColor(color)
        curve.setLegend("Trend")
        return curve









.. GENERATED FROM PYTHON SOURCE LINES 250-251

We draw the estimated trend function.

.. GENERATED FROM PYTHON SOURCE LINES 251-255

.. code-block:: Python

    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: constant trend")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_003.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_003.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 256-259

Now, we want to plot some confidence bounds of the metamodel. We use the class
:class:`~openturns.experimental.GaussianProcessConditionalCovariance` which is built from the Gaussian
Process Regression result. We create a function to plot confidence bounds.

.. GENERATED FROM PYTHON SOURCE LINES 259-284

.. code-block:: Python



    def plot_GPRConfidenceBounds(gpr_result, x_test, myTransform, color, alpha=0.05):
        bilateralCI = ot.Normal().computeBilateralConfidenceInterval(1.0 - alpha)
        quantileAlpha = bilateralCI.getUpperBound()[0]
        sqrt = ot.SymbolicFunction(["x"], ["sqrt(x)"])
        n_test = x_test.getSize()
        scaled_x_test = myTransform(x_test)
        gpr_condCov = otexp.GaussianProcessConditionalCovariance(gpr_result)
        conditionalVariance = gpr_condCov.getConditionalMarginalVariance(scaled_x_test)
        conditionalSigma = sqrt(conditionalVariance)
        metamodel_transf_data = gpr_result.getMetaModel()
        y_test = metamodel_transf_data(scaled_x_test)
        dataLower = [
            y_test[i, 0] - quantileAlpha * conditionalSigma[i, 0] for i in range(n_test)
        ]
        dataUpper = [
            y_test[i, 0] + quantileAlpha * conditionalSigma[i, 0] for i in range(n_test)
        ]
        boundsPoly = ot.Polygon.FillBetween(x_test.asPoint(), dataLower, dataUpper)
        boundsPoly.setColor(ot.Drawable.ConvertFromHSV(color[0], color[1], color[2]))
        boundsPoly.setLegend("%d%% C.I." % ((1.0 - alpha) * 100))
        return boundsPoly









.. GENERATED FROM PYTHON SOURCE LINES 285-286

We plot the bounds of three different confidence intervals of level :math:`1-\alpha`:

.. GENERATED FROM PYTHON SOURCE LINES 286-315

.. code-block:: Python

    alphas = [0.05, 0.1, 0.2]
    # three different green colors defined by HSV values:
    bounds_colors = [[120, 1.0, 1.0], [120, 1.0, 0.75], [120, 1.0, 0.5]]

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: constant trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_004.svg
   :alt: Gaussian Process Regression metamodel: constant trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_004.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 316-322

Linear basis
------------

With a linear basis, the vector space is defined by the basis :math:`\{1, z\}`: that is
all the function of type :math:`y(z) = az + b` where :math:`a` and :math:`b` are
real parameters.

.. GENERATED FROM PYTHON SOURCE LINES 322-324

.. code-block:: Python

    basis = ot.LinearBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 325-326

We build the :math:`Y(\omega, x)` Gaussian process, then we condition it to the data set.

.. GENERATED FROM PYTHON SOURCE LINES 326-333

.. code-block:: Python

    algo_fit = otexp.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()

    algo_gpr = otexp.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 334-335

We  get the metamodel on the transformed data and we build the final metamodel acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 335-339

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()
    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 340-341

We get the updated covariance model.

.. GENERATED FROM PYTHON SOURCE LINES 341-347

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 1.100e+00
    Amplitude parameter: 4.627e+00




.. GENERATED FROM PYTHON SOURCE LINES 348-349

We get the trend function acting on the transformed data and we build the trend function acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 349-352

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 353-354

We draw the model, the trained data set, the estimated trend function and the Gaussian Process Regression metamodel

.. GENERATED FROM PYTHON SOURCE LINES 354-360

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: linear basis")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_005.svg
   :alt: Gaussian Process Regression metamodel: linear basis
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_005.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 361-363

We plot some confidence bounds of the metamodel.
sphinx_gallery_thumbnail_number = 6

.. GENERATED FROM PYTHON SOURCE LINES 363-386

.. code-block:: Python

    graph = ot.Graph("Gaussian Process Regression metamodel: linear trend", "x", "y", True)
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_006.svg
   :alt: Gaussian Process Regression metamodel: linear trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_006.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 387-391

Quadratic basis
---------------

In this last section, we turn to the quadratic basis. All subsequent analysis should remain the same.

.. GENERATED FROM PYTHON SOURCE LINES 391-393

.. code-block:: Python

    basis = ot.QuadraticBasisFactory(dimension).build()








.. GENERATED FROM PYTHON SOURCE LINES 394-395

We build the :math:`Y(\omega, x)` Gaussian process, then we condition it to the data set.

.. GENERATED FROM PYTHON SOURCE LINES 395-402

.. code-block:: Python

    algo_fit = otexp.GaussianProcessFitter(scaledXtrain, Ytrain, covarianceModel, basis)
    algo_fit.run()
    fit_result = algo_fit.getResult()

    algo_gpr = otexp.GaussianProcessRegression(fit_result)
    algo_gpr.run()








.. GENERATED FROM PYTHON SOURCE LINES 403-404

We  get the metamodel on the transformed data and we build the final metamodel acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 404-408

.. code-block:: Python

    gpr_result = algo_gpr.getResult()
    metamodel_transformed_data = gpr_result.getMetaModel()
    metamodel_gpr = ot.ComposedFunction(metamodel_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 409-410

We get the updated covariance model.

.. GENERATED FROM PYTHON SOURCE LINES 410-416

.. code-block:: Python

    theta = gpr_result.getCovarianceModel().getScale()[0]
    print("Scale parameter: %.3e" % theta)

    sigma = gpr_result.getCovarianceModel().getAmplitude()[0]
    print("Amplitude parameter: %.3e" % sigma)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Scale parameter: 8.374e-02
    Amplitude parameter: 9.440e-01




.. GENERATED FROM PYTHON SOURCE LINES 417-418

We get the trend function acting on the transformed data and we build the trend acting on the initial input data.

.. GENERATED FROM PYTHON SOURCE LINES 418-421

.. code-block:: Python

    trend_transformed_data = fit_result.getMetaModel()
    trend = ot.ComposedFunction(trend_transformed_data, myTransform)








.. GENERATED FROM PYTHON SOURCE LINES 422-424

We draw the model, the trained data set, the estimated trend function and the Gaussian Process Regression
metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 424-430

.. code-block:: Python

    graph = plot_model(palette[0])
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setTitle("Gaussian Process Regression metamodel: quadratic basis")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_007.svg
   :alt: Gaussian Process Regression metamodel: quadratic basis
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_007.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 431-432

We plot some confidence bounds of the metamodel.

.. GENERATED FROM PYTHON SOURCE LINES 432-457

.. code-block:: Python

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: quadratic trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_008.svg
   :alt: Gaussian Process Regression metamodel: quadratic trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_008.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 458-464

And far away from the training data set?
----------------------------------------

We illustrate here that far away from the data set, the Gaussian Process Regression metamodel is entirely
determined by the trend function.
To do that, we define another input test sample.

.. GENERATED FROM PYTHON SOURCE LINES 464-495

.. code-block:: Python

    xmin = -10.0
    xmax = 20.0
    nTest = 500
    step = (xmax - xmin) / (nTest - 1)
    x_test = ot.RegularGrid(xmin, step, nTest).getVertices()

    graph = ot.Graph(
        "Gaussian Process Regression metamodel: quadratic trend", "x", "y", True
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[0], alphas[0]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[1], alphas[1]
        )
    )
    graph.add(
        plot_GPRConfidenceBounds(
            gpr_result, x_test, myTransform, bounds_colors[2], alphas[2]
        )
    )
    graph.add(plot_model(palette[0]))
    graph.add(plot_metamodel(x_test, metamodel_gpr, palette[1]))
    graph.add(plot_trend(x_test, trend, "red"))
    graph.setLegendCorner([1.0, 1.0])
    graph.setLegendPosition("upper left")
    view = otv.View(graph)




.. image-sg:: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_009.svg
   :alt: Gaussian Process Regression metamodel: quadratic trend
   :srcset: /auto_meta_modeling/kriging_metamodel/images/sphx_glr_plot_gpr_choose_trend_009.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 496-499

We observe that far away from the training data set, the Gaussian Process Regression metamodel is equal to the
trend function which is not a good approximation of the model. In that case, it is not a good idea to use the
Gaussian Process Regression metamodel far away from the training data set.

.. GENERATED FROM PYTHON SOURCE LINES 501-502

Display figures

.. GENERATED FROM PYTHON SOURCE LINES 502-503

.. code-block:: Python

    otv.View.ShowAll()








.. _sphx_glr_download_auto_meta_modeling_kriging_metamodel_plot_gpr_choose_trend.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_gpr_choose_trend.ipynb <plot_gpr_choose_trend.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_gpr_choose_trend.py <plot_gpr_choose_trend.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_gpr_choose_trend.zip <plot_gpr_choose_trend.zip>`
