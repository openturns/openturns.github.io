
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_probabilistic_modeling/distributions/plot_generate_by_inversion.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_probabilistic_modeling_distributions_plot_generate_by_inversion.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_probabilistic_modeling_distributions_plot_generate_by_inversion.py:


Generate random variates by inverting the CDF
=============================================

.. GENERATED FROM PYTHON SOURCE LINES 7-14

Abstract
--------

In this example, we show how to generate random variates by inversion of the cumulative distribution function.
In simple situations, this method is rarely used in practice because of problems with performance,
statistical quality of the generated random variates and numerical accuracy of the generated numbers when we use floating point numbers.
However, it is an interesting method to know about because it is a building block for other algorithms and can be used to visualize the distribution of the generated numbers.

.. GENERATED FROM PYTHON SOURCE LINES 17-41

The WeibullMin distribution
---------------------------

Let :math:`\beta>0` and :math:`\alpha>0` be two real parameters: :math:`\alpha` is a shape parameter and  :math:`\beta` is a scale parameter.

The cumulative distribution function of the WeibullMin distribution (also referred as `Weibull distribution`) is:

.. math::
   F(x) = 1 - \exp\left(-\frac{x-\gamma}{\beta}\right)^\alpha,


for any :math:`x\geq \gamma`. For the sake of simplicity, we set :math:`\gamma=0`

In some situations, this parameters are denoted by :math:`k=\beta` and :math:`\lambda=\alpha`.

The inverse of the CDF is:

.. math::
   F^{-1}(x) = \beta \left(-\log(1-p)\right)^{\frac{1}{\alpha}}


for any :math:`x\geq 0`.

This is the *quantile* function, because it computes the quantile :math:`F^{-1}(x)` depending on an outcome :math:`x`.

.. GENERATED FROM PYTHON SOURCE LINES 43-93

Loss of accuracy when the probability is close to 1
---------------------------------------------------

In practice, if the probability :math:`p` is *very* close to 1, then the complementary probability :math:`1-p` is close to zero.
This can lead to a significant loss of accuracy when we evaluate the subtraction :math:`1-p` with floating point numbers because :math:`p` and 1 have lots of common digits.
This is called a *loss of accuracy by catastrophic cancellation*, a problem which is common in extreme events.

We can use the :math:`\textrm{expm1}` function, defined by the equation:

.. math::
   \textrm{expm1}(x) = \exp(x)-1,


for any :math:`x\in\mathbb{R}`. This is *not* numerically equivalent to computing `exp` and then subtracting 1.
Indeed, the `expm1` function is more accurate when its argument `x` is close to zero.

The CDF is then:

.. math::
   F(x) = -\textrm{expm1} \left(\left(-\frac{x}{\beta}\right)^\alpha\right),


for any :math:`x\geq 0`.

For the quantile function, we can use the :math:`\textrm{log1p}` function, defined by the equation:

.. math::
   \textrm{log1p}(x) = \log(1+x)


for any :math:`x>-1`.

Therefore, the quantile function is:

.. math::
   x = \beta \left(-\textrm{log1p}(-p)\right)^{\frac{1}{\alpha}}


for :math:`x\geq 0`.

Note that for :math:`\gamma > 0`, the quantile function writes:

.. math::
   x = \gamma + \beta \left(-\textrm{log1p}(-p)\right)^{\frac{1}{\alpha}}


with :math:`x\geq \gamma`.


In the following, we will not use these robust equations and this issue will not be taken into account.

.. GENERATED FROM PYTHON SOURCE LINES 95-97

Generate by inversion: histogram and density
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 99-103

.. code-block:: Python

    import openturns as ot
    import openturns.viewer as otv
    import numpy as np








.. GENERATED FROM PYTHON SOURCE LINES 104-108

The following function defines the quantile function of the :class:`~openturns.WeibullMin` distribution.
(Of course, we could use the `computeQuantile` method of the :class:`~openturns.WeibullMin` class as well.
This would create a simpler, but less interesting example: this is a trade off
that we accept in order to better understand the algorithm.)

.. GENERATED FROM PYTHON SOURCE LINES 108-119

.. code-block:: Python



    def weibullQ(argument):
        """
        WeibullMin quantile function
        """
        p, alpha, beta = argument
        quantile = beta * (-np.log1p(-p)) ** (1 / alpha)
        return [quantile]









.. GENERATED FROM PYTHON SOURCE LINES 120-122

.. code-block:: Python

    quantileFunction = ot.PythonFunction(3, 1, weibullQ)








.. GENERATED FROM PYTHON SOURCE LINES 123-124

We define the parameters of the Weibull distribution and create the parametric function.

.. GENERATED FROM PYTHON SOURCE LINES 126-129

.. code-block:: Python

    alpha = 10.0
    beta = 1.0








.. GENERATED FROM PYTHON SOURCE LINES 130-133

.. code-block:: Python

    quantile = ot.ParametricFunction(quantileFunction, [1, 2], [alpha, beta])
    quantile






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <ul>
      <li> Input dimension = 1  </li>
      <li> Input description = [x0]  </li>
      <li> Output dimension = 1  </li>
      <li> Output description = [y0]  </li>
      <li> Parameter = [x1 : 10, x2 : 1]  </li>
    </ul>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 134-135

In the library, the uniform distribution is by default over the :math:`[-1,1]` interval. To obtain a uniform distribution over :math:`[0,1]`, we need to set the bounds explicitly.

.. GENERATED FROM PYTHON SOURCE LINES 137-139

.. code-block:: Python

    U = ot.Uniform(0.0, 1.0)








.. GENERATED FROM PYTHON SOURCE LINES 140-141

Then we generate a sample of size 1000 from the uniform distribution.

.. GENERATED FROM PYTHON SOURCE LINES 143-146

.. code-block:: Python

    n = 1000
    uniformSample = U.getSample(n)








.. GENERATED FROM PYTHON SOURCE LINES 147-148

To generate the numbers, we evaluate the quantile function on the uniform numbers.

.. GENERATED FROM PYTHON SOURCE LINES 150-152

.. code-block:: Python

    weibullSample = quantile(uniformSample)








.. GENERATED FROM PYTHON SOURCE LINES 153-154

In order to compare the results, we use the :class:`~openturns.WeibullMin` class (using the default value of the location parameter :math:`\gamma=0`).

.. GENERATED FROM PYTHON SOURCE LINES 156-158

.. code-block:: Python

    W = ot.WeibullMin(beta, alpha)








.. GENERATED FROM PYTHON SOURCE LINES 159-167

.. code-block:: Python

    histo = ot.HistogramFactory().build(weibullSample).drawPDF()
    histo.setTitle("Weibull alpha=%s, beta=%s, n=%d" % (alpha, beta, n))
    histo.setLegends(["Sample"])
    wpdf = W.drawPDF()
    wpdf.setLegends(["Weibull"])
    histo.add(wpdf)
    view = otv.View(histo)




.. image-sg:: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_generate_by_inversion_001.svg
   :alt: Weibull alpha=10.0, beta=1.0, n=1000
   :srcset: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_generate_by_inversion_001.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 168-169

We see that the empirical histogram of the generated outcomes is close to the exact density of the Weibull distribution.

.. GENERATED FROM PYTHON SOURCE LINES 171-173

Visualization of the quantiles
------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 175-176

We now want to understand the details of the algorithm. To do this, we need to compare the distribution of the uniform numbers with the distribution of the generated points.

.. GENERATED FROM PYTHON SOURCE LINES 178-181

.. code-block:: Python

    n = 50
    uniformSample = U.getSample(n)








.. GENERATED FROM PYTHON SOURCE LINES 182-184

.. code-block:: Python

    weibullSample = quantile(uniformSample)








.. GENERATED FROM PYTHON SOURCE LINES 185-186

We sort the sample by increasing order.

.. GENERATED FROM PYTHON SOURCE LINES 188-193

.. code-block:: Python

    data = ot.Sample(n, 2)
    data[:, 0] = weibullSample
    data[:, 1] = uniformSample
    data.setDescription(["x", "p"])








.. GENERATED FROM PYTHON SOURCE LINES 194-197

.. code-block:: Python

    sample = ot.Sample(data.sort())
    sample[0:5, :]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <table>
      <tr><td></td><th>x</th><th>p</th></tr>
      <tr><th>0</th><td>0.6159411</td><td>0.007828637</td></tr>
      <tr><th>1</th><td>0.6738735</td><td>0.01912483</td></tr>
      <tr><th>2</th><td>0.7194894</td><td>0.03649194</td></tr>
      <tr><th>3</th><td>0.7368217</td><td>0.04607047</td></tr>
      <tr><th>4</th><td>0.7411487</td><td>0.0487797</td></tr>
    </table>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 198-201

.. code-block:: Python

    weibullSample = sample[:, 0]
    uniformSample = sample[:, 1]








.. GENERATED FROM PYTHON SOURCE LINES 202-217

.. code-block:: Python

    graph = ot.Graph("Weibull alpha=%s, beta=%s, n=%s" % (alpha, beta, n), "x", "U", True)
    # Add the CDF plot
    curve = W.drawCDF()
    graph.add(curve)
    # Plot dashed horizontal & vertical lines
    for i in range(n):
        curve = ot.Curve(
            [0.0, weibullSample[i, 0], weibullSample[i, 0]],
            [uniformSample[i, 0], uniformSample[i, 0], 0.0],
        )
        curve.setColor("red")
        curve.setLineStyle("dashed")
        graph.add(curve)
    view = otv.View(graph)




.. image-sg:: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_generate_by_inversion_002.svg
   :alt: Weibull alpha=10.0, beta=1.0, n=50
   :srcset: /auto_probabilistic_modeling/distributions/images/sphx_glr_plot_generate_by_inversion_002.svg
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 218-219

Show all the graphs.

.. GENERATED FROM PYTHON SOURCE LINES 219-221

.. code-block:: Python

    view.ShowAll()








.. GENERATED FROM PYTHON SOURCE LINES 222-224

This graphics must be read from the `U` axis on the left to the blue curve (representing the CDF), and down to the `X` axis.
We see that the horizontal lines on the `U` axis follow the uniform distribution. On the other hand, the vertical lines (on the `X` axis) follow the Weibull distribution.


.. _sphx_glr_download_auto_probabilistic_modeling_distributions_plot_generate_by_inversion.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_generate_by_inversion.ipynb <plot_generate_by_inversion.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_generate_by_inversion.py <plot_generate_by_inversion.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_generate_by_inversion.zip <plot_generate_by_inversion.zip>`
