<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Compute confidence intervals of a univariate noisy function &#8212; OpenTURNS 1.24 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=649a27d8" />
    <link rel="stylesheet" type="text/css" href="../../_static/openturns.css?v=105494d3" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=4652c2b6" />
    <script src="../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../_static/documentation_options.js?v=eff3c53f"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=35a8b989"></script>
    <script src="../../_static/js/mysearchtools.js?v=a003391d"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Optimization" href="../optimization/index.html" />
    <link rel="prev" title="Compute confidence intervals of a regression model from data" href="plot_regression_interval.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://gitter.im/openturns/community">Chat</a></li>
    <li><a href="https://github.com/openturns/openturns/wiki/Modules">Modules</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../optimization/index.html" title="Optimization"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plot_regression_interval.html" title="Compute confidence intervals of a regression model from data"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.24 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Numerical methods</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" accesskey="U">General methods</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Compute confidence intervals of a univariate noisy function</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Compute confidence intervals of a univariate noisy function</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#compute-the-data">Compute the data</a></li>
<li><a class="reference internal" href="#compute-the-coefficients-of-the-polynomial-decomposition">Compute the coefficients of the polynomial decomposition</a></li>
<li><a class="reference internal" href="#compute-residuals-and-variance">Compute residuals and variance</a></li>
<li><a class="reference internal" href="#compute-confidence-intervals">Compute confidence intervals</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="plot_regression_interval.html"
                          title="previous chapter">Compute confidence intervals of a regression model from data</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="../optimization/index.html"
                          title="next chapter">Optimization</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/auto_numerical_methods/general_methods/plot_regression_sinus.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-numerical-methods-general-methods-plot-regression-sinus-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="compute-confidence-intervals-of-a-univariate-noisy-function">
<span id="sphx-glr-auto-numerical-methods-general-methods-plot-regression-sinus-py"></span><h1>Compute confidence intervals of a univariate noisy function<a class="headerlink" href="#compute-confidence-intervals-of-a-univariate-noisy-function" title="Link to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>In this example, we compute the pointwise confidence interval of the
estimator of the conditional expectation given an input.
We consider noisy observations of the sine function.
Then we perform linear least squares regression to fit an order 4
polynomial.
For a given point x, the code computes the confidence interval
of the prediction y.
This is the confidence interval of the conditional expectation
given the input.
Secondly, we compute the confidence interval of the noisy output observations.
In this advanced example, we use the <a class="reference internal" href="../../user_manual/response_surface/_generated/openturns.QRMethod.html#openturns.QRMethod" title="openturns.QRMethod"><code class="xref py py-class docutils literal notranslate"><span class="pre">QRMethod</span></code></a> low level class.
Another example of this method is presented in
<a class="reference internal" href="plot_regression_interval.html"><span class="doc">Compute confidence intervals of a regression model from data</span></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openturns</span> <span class="k">as</span> <span class="nn">ot</span>
<span class="kn">import</span> <span class="nn">openturns.viewer</span> <span class="k">as</span> <span class="nn">otv</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">palette</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Drawable</span><span class="o">.</span><span class="n">BuildTableauPalette</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">ot</span><span class="o">.</span><span class="n">RandomGenerator</span><span class="o">.</span><span class="n">SetSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="compute-the-data">
<h2>Compute the data<a class="headerlink" href="#compute-the-data" title="Link to this heading">¶</a></h2>
<p>We generate noisy observations from the sine function.
We define the function that we are going to approximate.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SymbolicFunction</span><span class="p">([</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;sin(2 * pi_ * x)&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>We plot the function depending on the input.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">lineStyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">):</span>
    <span class="n">curve</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">getDrawable</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLineStyle</span><span class="p">(</span><span class="s2">&quot;dotted&quot;</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLegend</span><span class="p">(</span><span class="s2">&quot;True&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">curve</span>


<span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="s2">&quot;Polynomial curve fitting&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
<span class="c1"># The &quot;unknown&quot; function</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">otv</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_regression_sinus_001.png" srcset="../../_images/sphx_glr_plot_regression_sinus_001.png" alt="Polynomial curve fitting" class = "sphx-glr-single-img"/><p>This is a nice, smooth function to approximate with polynomials.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linearSample</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">npoints</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a sample created from a regular grid</span>
<span class="sd">    from xmin to xmax with npoints points.&quot;&quot;&quot;</span>
    <span class="n">step</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">npoints</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">rg</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">RegularGrid</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">npoints</span><span class="p">)</span>
    <span class="n">vertices</span> <span class="o">=</span> <span class="n">rg</span><span class="o">.</span><span class="n">getVertices</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">vertices</span>
</pre></div>
</div>
<p>We consider observation points in the interval [0,1].</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">nTrain</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">xTrain</span> <span class="o">=</span> <span class="n">linearSample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nTrain</span><span class="p">)</span>
</pre></div>
</div>
<p>Assume that the observations are noisy and that the noise follows
a Normal distribution with zero mean and small standard deviation.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">noise</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">noiseSample</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">getSample</span><span class="p">(</span><span class="n">nTrain</span><span class="p">)</span>
</pre></div>
</div>
<p>The following code computes the observation as the sum of the
function value and of the noise.
The couple <cite>(xTrain,yTrain)</cite> is the training set: it is used
to compute the coefficients of the polynomial model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">yTrain</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">xTrain</span><span class="p">)</span> <span class="o">+</span> <span class="n">noiseSample</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yTrain</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>    [ y0         ]
0 : [  0.304101  ]
1 : [ -0.569663  ]
2 : [ -0.0925404 ]
3 : [  0.79199   ]
4 : [ -0.839545  ]
</pre></div>
</div>
<p>Then we plot the function and the observations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotData</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">pointStyle</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">):</span>
    <span class="n">cloud</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Cloud</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">setPointStyle</span><span class="p">(</span><span class="n">pointStyle</span><span class="p">)</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">setLegend</span><span class="p">(</span><span class="s2">&quot;Observations&quot;</span><span class="p">)</span>
    <span class="n">cloud</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="n">palette</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">cloud</span>


<span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="s2">&quot;Polynomial curve fitting&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
<span class="c1"># The &quot;unknown&quot; function</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># Training set</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotData</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">otv</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_regression_sinus_002.png" srcset="../../_images/sphx_glr_plot_regression_sinus_002.png" alt="Polynomial curve fitting" class = "sphx-glr-single-img"/><p>We see that the noisy observations of the function are relatively
large compared to the function values.
It may not be obvious that a regression model can fit that data well.</p>
</section>
<section id="compute-the-coefficients-of-the-polynomial-decomposition">
<h2>Compute the coefficients of the polynomial decomposition<a class="headerlink" href="#compute-the-coefficients-of-the-polynomial-decomposition" title="Link to this heading">¶</a></h2>
<p>In order to approximate the function with polynomials up to degree 4,
we create a list of strings containing the associated monomials.
We perform the loop from 0 up to <cite>totalDegree</cite> (but the <cite>range</cite>
function takes <cite>totalDegree + 1</cite> as its second input argument).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">totalDegree</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">polynomialCollection</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;x^</span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">totalDegree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">polynomialCollection</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;x^0&#39;, &#39;x^1&#39;, &#39;x^2&#39;, &#39;x^3&#39;, &#39;x^4&#39;]
</pre></div>
</div>
<p>Given the list of strings, we create a symbolic function which computes the
values of the monomials.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">basisFunction</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">SymbolicFunction</span><span class="p">([</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">polynomialCollection</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">basisFunction</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[x]-&gt;[x^0,x^1,x^2,x^3,x^4]
</pre></div>
</div>
<p>Evaluate the design matrix as the value of the basis functions on the
training sample.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">designSampleTrain</span> <span class="o">=</span> <span class="n">basisFunction</span><span class="p">(</span><span class="n">xTrain</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">designSampleTrain</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>    [ y0          y1          y2          y3          y4          ]
0 : [ 1           0           0           0           0           ]
1 : [ 1           0.010101    0.00010203  1.03061e-06 1.04102e-08 ]
2 : [ 1           0.020202    0.000408122 8.24488e-06 1.66563e-07 ]
3 : [ 1           0.030303    0.000918274 2.78265e-05 8.43226e-07 ]
4 : [ 1           0.040404    0.00163249  6.5959e-05  2.66501e-06 ]
</pre></div>
</div>
<p>Convert the design sample into a design matrix and create
an instance of the <a class="reference internal" href="../../user_manual/response_surface/_generated/openturns.QRMethod.html#openturns.QRMethod" title="openturns.QRMethod"><code class="xref py py-class docutils literal notranslate"><span class="pre">QRMethod</span></code></a> class.
This class has the <a class="reference internal" href="../../user_manual/response_surface/_generated/openturns.QRMethod.html#openturns.QRMethod.getGramInverse" title="openturns.QRMethod.getGramInverse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">getGramInverse()</span></code></a> method that
we need to compute the confidence interval.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">designMatrixTrain</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Matrix</span><span class="p">(</span><span class="n">designSampleTrain</span><span class="p">)</span>
<span class="n">lsqMethod</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">QRMethod</span><span class="p">(</span><span class="n">designMatrixTrain</span><span class="p">)</span>
</pre></div>
</div>
<p>Solve the linear least squares problem and get the vector of coefficients.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">betaHat</span> <span class="o">=</span> <span class="n">lsqMethod</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">yTrain</span><span class="o">.</span><span class="n">asPoint</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">betaHat</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[-0.193699,9.71586,-20.9196,-0.667074,12.5351]
</pre></div>
</div>
</section>
<section id="compute-residuals-and-variance">
<h2>Compute residuals and variance<a class="headerlink" href="#compute-residuals-and-variance" title="Link to this heading">¶</a></h2>
<p>We need to estimate the variance of the residuals.
To do this we evaluate the predictions of the regression model on
the training sample and compute the residuals.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">yHatTrain</span> <span class="o">=</span> <span class="n">designMatrixTrain</span> <span class="o">*</span> <span class="n">betaHat</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">yHatTrain</span> <span class="o">-</span> <span class="n">yTrain</span><span class="o">.</span><span class="n">asPoint</span><span class="p">()</span>
<span class="n">sampleSize</span> <span class="o">=</span> <span class="n">designMatrixTrain</span><span class="o">.</span><span class="n">getNbRows</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sampleSize=&quot;</span><span class="p">,</span> <span class="n">sampleSize</span><span class="p">)</span>
<span class="n">nParameters</span> <span class="o">=</span> <span class="n">designMatrixTrain</span><span class="o">.</span><span class="n">getNbColumns</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nParameters = &quot;</span><span class="p">,</span> <span class="n">nParameters</span><span class="p">)</span>
<span class="n">sigma2Hat</span> <span class="o">=</span> <span class="n">residuals</span><span class="o">.</span><span class="n">normSquare</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">sampleSize</span> <span class="o">-</span> <span class="n">nParameters</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sigma2Hat = &quot;</span><span class="p">,</span> <span class="n">sigma2Hat</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>sampleSize= 100
nParameters =  5
sigma2Hat =  0.25191909002749147
</pre></div>
</div>
<p>The couple <cite>(xTest,yHatTest)</cite> is the set where we want to evaluate the
prediction confidence intervals.
In order to evaluate the predictions from the regression model, multiply
the design matrix evaluated on the test sample with the vector of coefficients.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">nTest</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">xTest</span> <span class="o">=</span> <span class="n">linearSample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nTest</span><span class="p">)</span>
<span class="n">designMatrixTest</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Matrix</span><span class="p">(</span><span class="n">basisFunction</span><span class="p">(</span><span class="n">xTest</span><span class="p">))</span>
<span class="n">yHatTest</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="o">.</span><span class="n">BuildFromPoint</span><span class="p">(</span><span class="n">designMatrixTest</span> <span class="o">*</span> <span class="n">betaHat</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we plot the true function, its noisy observations and the least
squares model of degree 4.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotPredictions</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yHatTest</span><span class="p">,</span> <span class="n">totalDegree</span><span class="p">,</span> <span class="n">color</span><span class="p">):</span>
    <span class="n">curve</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yHatTest</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLegend</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;L.S. degree </span><span class="si">{</span><span class="n">totalDegree</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">curve</span>


<span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="s2">&quot;Polynomial curve fitting&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
<span class="c1"># The &quot;unknown&quot; function</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># Training set</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotData</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1"># Predictions</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotPredictions</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yHatTest</span><span class="p">,</span> <span class="n">totalDegree</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">otv</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_regression_sinus_003.png" srcset="../../_images/sphx_glr_plot_regression_sinus_003.png" alt="Polynomial curve fitting" class = "sphx-glr-single-img"/><p>We see that the least squares polynomial model
is relatively close to the true function.</p>
</section>
<section id="compute-confidence-intervals">
<h2>Compute confidence intervals<a class="headerlink" href="#compute-confidence-intervals" title="Link to this heading">¶</a></h2>
<p>The next function will help to compute confidence intervals.
It is based on regression analysis.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">computeRegressionConfidenceInterval</span><span class="p">(</span>
    <span class="n">lsqMethod</span><span class="p">,</span>
    <span class="n">betaHat</span><span class="p">,</span>
    <span class="n">sigma2Hat</span><span class="p">,</span>
    <span class="n">designSample</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">epsilonSigma</span><span class="o">=</span><span class="mf">1.0e-5</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a confidence interval for the estimate of the mean.</span>

<span class="sd">    Evaluates this confidence interval at points in the design matrix.</span>

<span class="sd">    This code is based on (Rawlings, Pantula &amp; David, 1998)</span>
<span class="sd">    eq. 3.51 and 3.52 page 90.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lsqMethod: ot.LeastSquaresMethod</span>
<span class="sd">        The linear least squares method (e.g. QR or Cholesky).</span>
<span class="sd">    betaHat : ot.Point(parameterDimension)</span>
<span class="sd">        The solution of the least squares problem.</span>
<span class="sd">    sigma2Hat : float &gt; 0.0</span>
<span class="sd">        The estimate of the variance.</span>
<span class="sd">    designSample : ot.Sample(size, parameterDimension)</span>
<span class="sd">        The design matrix of the linear model.</span>
<span class="sd">        This is the value of the functional basis depending on the</span>
<span class="sd">        input sample.</span>
<span class="sd">        Each row represents the input where the confidence interval</span>
<span class="sd">        is to be computed.</span>
<span class="sd">    alpha : float, in [0, 1]</span>
<span class="sd">        The width of the confidence interval.</span>
<span class="sd">    mean : bool</span>
<span class="sd">        If True, then computes the confidence interval of the mean.</span>
<span class="sd">        This interval contains yTrue = E[y|x] with probability alpha.</span>
<span class="sd">        Otherwise, computes a confidence interval of the prediction at point x.</span>
<span class="sd">        This interval contains y|x with probability alpha.</span>
<span class="sd">    epsilonSigma : float &gt; 0.0</span>
<span class="sd">        A relatively small number. The minimal value of variance, which</span>
<span class="sd">        avoids a singular Normal distribution.</span>

<span class="sd">    Reference</span>
<span class="sd">    ---------</span>
<span class="sd">    - O. Rawlings John, G. Pantula Sastry, and A. Dickey David.</span>
<span class="sd">      Applied regression analysis—a research tool. Springer New York, 1998.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    confidenceBounds : ot.Sample(size, 2)</span>
<span class="sd">        The first column contains the lower bound.</span>
<span class="sd">        The second column contains the upper bound.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">inverseGram</span> <span class="o">=</span> <span class="n">lsqMethod</span><span class="o">.</span><span class="n">getGramInverse</span><span class="p">()</span>
    <span class="n">sampleSize</span> <span class="o">=</span> <span class="n">designSample</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
    <span class="n">confidenceBounds</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">sampleSize</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sampleSize</span><span class="p">):</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">designSample</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">meanYHat</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">betaHat</span><span class="p">)</span>
        <span class="n">sigma2YHat</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inverseGram</span> <span class="o">*</span> <span class="n">x0</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma2Hat</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mean</span><span class="p">:</span>
            <span class="n">sigma2YHat</span> <span class="o">+=</span> <span class="n">sigma2Hat</span>
        <span class="n">sigmaYHat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma2YHat</span><span class="p">)</span>
        <span class="n">sigmaYHat</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">epsilonSigma</span><span class="p">,</span> <span class="n">sigmaYHat</span><span class="p">)</span>  <span class="c1"># Prevents a zero s.e.</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">meanYHat</span><span class="p">,</span> <span class="n">sigmaYHat</span><span class="p">)</span>
        <span class="n">interval</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">computeBilateralConfidenceInterval</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">interval</span><span class="o">.</span><span class="n">getLowerBound</span><span class="p">()</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">interval</span><span class="o">.</span><span class="n">getUpperBound</span><span class="p">()</span>
        <span class="n">confidenceBounds</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">confidenceBounds</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">confidenceBounds</span>
</pre></div>
</div>
<p>We evaluate the value of the basis functions on the test sample.
This sample is used to compute the confidence interval.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">designSampleTest</span> <span class="o">=</span> <span class="n">basisFunction</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
</pre></div>
</div>
<p>Compute the confidence interval.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">confidenceIntervalMean</span> <span class="o">=</span> <span class="n">computeRegressionConfidenceInterval</span><span class="p">(</span>
    <span class="n">lsqMethod</span><span class="p">,</span> <span class="n">betaHat</span><span class="p">,</span> <span class="n">sigma2Hat</span><span class="p">,</span> <span class="n">designSampleTest</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
<span class="p">)</span>
</pre></div>
</div>
<p>On output, the <cite>confidenceIntervalMean</cite> variable is a <a class="reference internal" href="../../user_manual/_generated/openturns.Sample.html#openturns.Sample" title="openturns.Sample"><code class="xref py py-class docutils literal notranslate"><span class="pre">Sample</span></code></a>
of size 50 and dimension 2.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">confidenceIntervalMean</span><span class="o">.</span><span class="n">getSize</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>50
</pre></div>
</div>
<p>Plot the confidence interval (C.I.) of the pointwise estimator
of the conditional expectation.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotConfidenceInterval</span><span class="p">(</span>
    <span class="n">xTest</span><span class="p">,</span> <span class="n">confidenceIntervalSample</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">lineStyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;&quot;</span>
<span class="p">):</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="n">curve</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">confidenceIntervalSample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLegend</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLineStyle</span><span class="p">(</span><span class="n">lineStyle</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">curve</span><span class="p">)</span>
    <span class="n">curve</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">confidenceIntervalSample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLegend</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setColor</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
    <span class="n">curve</span><span class="o">.</span><span class="n">setLineStyle</span><span class="p">(</span><span class="n">lineStyle</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">curve</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">graph</span>


<span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="s2">&quot;Polynomial curve fitting&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
<span class="c1"># The &quot;unknown&quot; function</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># Training set</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotData</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1"># Predictions</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotPredictions</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yHatTest</span><span class="p">,</span> <span class="n">totalDegree</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="c1"># Confidence interval of the mean</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">plotConfidenceInterval</span><span class="p">(</span>
        <span class="n">xTest</span><span class="p">,</span>
        <span class="n">confidenceIntervalMean</span><span class="p">,</span>
        <span class="n">palette</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Mean </span><span class="si">%.0f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">otv</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_regression_sinus_004.png" srcset="../../_images/sphx_glr_plot_regression_sinus_004.png" alt="Polynomial curve fitting" class = "sphx-glr-single-img"/><p>We see that the pointwise confidence interval contains the true
model for most points.
For a small set of points, there are points which are not within
the bounds, but are not too far away.
The observations, however, are not contained within these bounds.
This is the goal of the next cell.</p>
<p>Finally, compute a 95% C.I. of the observations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">confidenceIntervalObservations</span> <span class="o">=</span> <span class="n">computeRegressionConfidenceInterval</span><span class="p">(</span>
    <span class="n">lsqMethod</span><span class="p">,</span>
    <span class="n">betaHat</span><span class="p">,</span>
    <span class="n">sigma2Hat</span><span class="p">,</span>
    <span class="n">designSampleTest</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
    <span class="n">mean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Then we plot the function, its least squares approximation, the
C.I. of the mean and the C.I. of the observations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># sphinx_gallery_thumbnail_number = 5</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="s2">&quot;Polynomial curve fitting&quot;</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
<span class="c1"># The &quot;unknown&quot; function</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotFunction</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="c1"># Training set</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotData</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="c1"># Predictions</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">plotPredictions</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yHatTest</span><span class="p">,</span> <span class="n">totalDegree</span><span class="p">,</span> <span class="n">palette</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
<span class="c1"># Confidence interval of the mean</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">plotConfidenceInterval</span><span class="p">(</span>
        <span class="n">xTest</span><span class="p">,</span>
        <span class="n">confidenceIntervalMean</span><span class="p">,</span>
        <span class="n">palette</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Mean </span><span class="si">%.0f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="c1"># Confidence interval of the observations.</span>
<span class="n">graph</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">plotConfidenceInterval</span><span class="p">(</span>
        <span class="n">xTest</span><span class="p">,</span>
        <span class="n">confidenceIntervalObservations</span><span class="p">,</span>
        <span class="n">palette</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Obs. </span><span class="si">%.0f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">otv</span><span class="o">.</span><span class="n">View</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_regression_sinus_005.png" srcset="../../_images/sphx_glr_plot_regression_sinus_005.png" alt="Polynomial curve fitting" class = "sphx-glr-single-img"/><p>We see that the confidence interval of the observations contain
most of the observations.
The confidence interval of the observations is much larger than the
C.I. of the mean, as expected from the statistical model.</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-numerical-methods-general-methods-plot-regression-sinus-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8020f55e41abc997a81bc2f8d56ba790/plot_regression_sinus.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_regression_sinus.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/79f40f027e476c6e060506640c16e472/plot_regression_sinus.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_regression_sinus.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/801fdae2ddbb17a82ef192802e7301a2/plot_regression_sinus.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_regression_sinus.zip</span></code></a></p>
</div>
</div>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../optimization/index.html" title="Optimization"
             >next</a> |</li>
        <li class="right" >
          <a href="plot_regression_interval.html" title="Compute confidence intervals of a regression model from data"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.24 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../../examples/examples.html" >Examples</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../index.html" >Numerical methods</a> &#187;</li>
          <li class="nav-item nav-item-4"><a href="index.html" >General methods</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Compute confidence intervals of a univariate noisy function</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2005-2024 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Nov 25, 2024.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    </div>
  </body>
</html>