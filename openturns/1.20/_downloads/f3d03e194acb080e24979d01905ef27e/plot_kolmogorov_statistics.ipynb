{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Kolmogorov-Smirnov : understand the statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we illustrate how the Kolmogorov-Smirnov statistic is computed.\n\n* We generate a sample from a normal distribution.\n* We create a uniform distribution and estimate its parameters from the sample.\n* Compute the Kolmogorov-Smirnov statistic and plot it on top of the empirical cumulated distribution function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as viewer\nfrom matplotlib import pylab as plt\n\not.Log.Show(ot.Log.NONE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `computeKSStatisticsIndex()` function computes the Kolmogorov-Smirnov\ndistance between the sample and the distribution.\nFurthermore, it returns the index which achieves the maximum distance\nin the sorted sample.\nThe following function is for teaching purposes only: use\n`FittingTest` for real applications.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def computeKSStatisticsIndex(sample, distribution):\n    sample = ot.Sample(sample.sort())\n    print(\"Sorted\")\n    print(sample)\n    n = sample.getSize()\n    D = 0.0\n    index = -1\n    D_previous = 0.0\n    for i in range(n):\n        F = distribution.computeCDF(sample[i])\n        S1 = abs(F - float(i) / n)\n        S2 = abs(float(i + 1) / n - F)\n        print(\n            \"i=%d, x[i]=%.4f, F(x[i])=%.4f, S1=%.4f, S2=%.4f\"\n            % (i, sample[i, 0], F, S1, S2)\n        )\n        D = max(S1, S2, D)\n        if D > D_previous:\n            print(\"D max!\")\n            index = i\n            D_previous = D\n    observation = sample[index]\n    return D, index, observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `drawKSDistance()` function plots the empirical distribution function\nof the sample and the Kolmogorov-Smirnov distance at point x.\nThe empirical CDF is a staircase function and is discontinuous at each observation.\nDenote by $\\hat{F}$ the empirical CDF. For a given observation $x$\nwhich achieves the maximum distance to the candidate distribution CDF,\nlet us denote $\\hat{F}^- = \\lim_{x \\rightarrow x^-} \\hat{F}(x)$ and\n$\\hat{F}^+ = \\lim_{x\\rightarrow x^+} \\hat{F}(x)$.\nThe maximum distance can be achieved either by $\\hat{F}^-$ or $\\hat{F}^+$.\nThe `computeEmpiricalCDF(x)` method computes $\\hat{F}^+=\\mathbb{P}(X \\leq x)$.\nWe compute $\\hat{F}^-$ with the equation $\\hat{F}^- = \\hat{F}^+ - 1/n$\nwhere $n$ is the sample size.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def drawKSDistance(sample, distribution, observation, D, distFactory):\n    graph = ot.Graph(\"KS Distance = %.4f\" % (D), \"X\", \"CDF\", True, \"topleft\")\n    # Thick vertical line at point x\n    ECDF_x_plus = sample.computeEmpiricalCDF(observation)\n    ECDF_x_minus = ECDF_x_plus - 1.0 / sample.getSize()\n    CDF_index = distribution.computeCDF(observation)\n    curve = ot.Curve(\n        [observation[0], observation[0], observation[0]],\n        [ECDF_x_plus, ECDF_x_minus, CDF_index],\n    )\n    curve.setLegend(\"KS Statistics\")\n    curve.setLineWidth(4.0 * curve.getLineWidth())\n    graph.add(curve)\n    # Empirical CDF\n    empiricalCDF = ot.UserDefined(sample).drawCDF()\n    empiricalCDF.setLegends([\"Empirical DF\"])\n    graph.add(empiricalCDF)\n    #\n    distname = distFactory.getClassName()\n    distribution = distFactory.build(sample)\n    cdf = distribution.drawCDF()\n    cdf.setLegends([distname])\n    graph.add(cdf)\n    graph.setColors(ot.Drawable.BuildDefaultPalette(3))\n    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We generate a sample from a standard normal distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = ot.Normal()\nn = 10\nsample = N.getSample(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the index which achieves the maximum Kolmogorov-Smirnov distance.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create a uniform distribution whose parameters are estimated\nfrom the sample.\nThis way, the K.S. distance is large enough to be graphically significant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distFactory = ot.UniformFactory()\ndistribution = distFactory.build(sample)\ndistribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the index which achieves the maximum Kolmogorov-Smirnov distance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "D, index, observation = computeKSStatisticsIndex(sample, distribution)\nprint(\"D=\", D, \", Index=\", index, \", Obs.=\", observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = drawKSDistance(sample, distribution, observation, D, distFactory)\nview = viewer.View(graph)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the K.S. statistics is achieved at the observation where the distance\nbetween the empirical distribution function of the sample and the\ncandidate distribution is largest.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}