{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Calibration without observed inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this example is to present the calibration of a parametric model which\ndoes not have observed inputs.\nWe are going to see how to use the :class:`~openturns.Sample` class\nand create an empty sample.\nIndeed, this is mandatory in order to fit within the calibration\nframework that is used in the library.\nIn this example there are, however, several outputs to be calibrated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nfrom matplotlib import pylab as plt\nimport openturns.viewer as viewer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The vector of parameters is\n$\\boldsymbol{\\theta} = (a, b, c)^T \\in \\mathbb{R}^3$.\nThis model is linear in $\\boldsymbol{\\theta}$ and identifiable.\nIt is derived from the equation:\n\n\\begin{align}y(x) = a + b x + c x^2\\end{align}\n\nat $x=-1.0, -0.6, -0.2, 0.2, 0.6, 1.0$.\nIn the model, however, the abscissas are fixed and constant.\nTherefore, the parametric model has 3 parameters, no input and 6 outputs\n$y_1, ..., y_6$.\nThis produces a set of 5 observations for each output, leading to a total\nof 5 (observations per output) * 6 (outputs) = 30 observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g = ot.SymbolicFunction(\n    [\"a\", \"b\", \"c\"],\n    [\n        \"a +  -1.0  * b +  1.0  * c\",\n        \"a +  -0.6  * b +  0.36  * c\",\n        \"a +  -0.2  * b +  0.04  * c\",\n        \"a +  0.2  * b +  0.04  * c\",\n        \"a +  0.6  * b +  0.36  * c\",\n        \"a +  1.0  * b +  1.0  * c\",\n    ],\n)\noutputDimension = g.getOutputDimension()\nprint(outputDimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the true value of the parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trueParameter = ot.Point([12.0, 7.0, -8.0])\nprint(trueParameter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to generate the observed outputs, we create a distribution\nin dimension 3, with Dirac (i.e. constant) marginals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inputRandomVector = ot.ComposedDistribution(\n    [ot.Dirac(theta) for theta in trueParameter]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The candidate value is chosen to be different from the true parameter value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "candidate = ot.Point([8.0, 9.0, -6.0])\ncalibratedIndices = [0, 1, 2]\nmodel = ot.ParametricFunction(g, calibratedIndices, candidate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider a multivariate gaussian noise with zero mean, standard deviation\nequal to 0.05 and independent copula.\nThe independent copula implies that the errors of the 6 outputs are independent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputObservationNoiseSigma = 1.0\nmeanNoise = ot.Point(outputDimension)\ncovarianceNoise = [outputObservationNoiseSigma] * outputDimension\nR = ot.IdentityMatrix(outputDimension)\nobservationOutputNoise = ot.Normal(meanNoise, covarianceNoise, R)\nprint(observationOutputNoise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we generate the outputs by evaluating the exact outputs of the\nfunction and adding the noise.\nWe use a sample with size equal to 5.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 5\n# Generate exact outputs\ninputSample = inputRandomVector.getSample(size)\noutputStress = g(inputSample)\n# Add noise\nsampleNoise = observationOutputNoise.getSample(size)\noutputObservations = outputStress + sampleNoise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now is the important part of this script: there are no input observations.\nThis is why we create a sample of dimension equal to 0.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inputObservations = ot.Sample(0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to perform the calibration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.LinearLeastSquaresCalibration(\n    model, inputObservations, outputObservations, candidate, \"SVD\"\n)\nalgo.run()\ncalibrationResult = algo.getResult()\nparameterMAP = calibrationResult.getParameterMAP()\nprint(parameterMAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the estimated parameter is relatively close to\nthe true parameter value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(parameterMAP - trueParameter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graphical validation\n\nWe now validate the calculation by drawing the exact function and compare\nit to the function with estimated parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fullModel = ot.SymbolicFunction([\"a\", \"b\", \"c\", \"x\"], [\"a + b * x + c * x^2\"])\nparameterIndices = [0, 1, 2]\ntrueFunction = ot.ParametricFunction(fullModel, parameterIndices, trueParameter)\nprint(trueFunction)\nbeforeCalibrationFunction = ot.ParametricFunction(\n    fullModel, parameterIndices, candidate\n)\nprint(beforeCalibrationFunction)\ncalibratedFunction = ot.ParametricFunction(fullModel, parameterIndices, parameterMAP)\nprint(calibratedFunction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to validate the calibration, we compare the parametric function\nwith true parameters at given abscissas with the parametric function\nwith calibrated parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "abscissas = [-1.0, -0.6, -0.2, 0.2, 0.6, 1.0]\nxmin = min(abscissas)\nxmax = max(abscissas)\n\nnpoints = 50\ngraph = ot.Graph(\"Calibration without observations\", \"x\", \"y\", True, \"bottomright\")\ncurve = trueFunction.draw(xmin, xmax, npoints).getDrawable(0)\ncurve.setLineStyle(\"dashed\")\ncurve.setLegend(\"True model\")\ncurve.setColor(\"darkorange1\")\ngraph.add(curve)\n# Before calibration\ncurve = beforeCalibrationFunction.draw(xmin, xmax, npoints)\ncurve.setLegends([\"Model before calibration\"])\ncurve.setColors([\"red\"])\ngraph.add(curve)\n# After calibration\ncurve = calibratedFunction.draw(xmin, xmax, npoints)\ncurve.setLegends([\"Model after calibration\"])\ncurve.setColors([\"green\"])\ngraph.add(curve)\n# Observations\nfor i in range(outputDimension):\n    cloud = ot.Cloud(ot.Sample([[abscissas[i]]] * size), outputObservations[:, i])\n    cloud.setColor(\"blue\")\n    if i == 0:\n        cloud.setLegend(\"Observations\")\n    graph.add(cloud)\nviewer = viewer.View(graph)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We notice that the calibration produces a good fit to the data.\nStill, we notice a small discrepancy between the true mode and the model\nafter calibration, but this discrepancy is very small.\nSince the model is linear with respect to the parameters $a$, $b$, $c$,\nthe LinearLeastSquares method performs well.\nIf the model were non linear w.r.t. $a$, $b$, $c$, then the linear least\nsquares method would not work that well and the parameters would be estimated\nwith less accuracy.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}