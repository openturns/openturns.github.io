.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py:


Compare unconditional and conditional histograms
================================================

In this example, we compare unconditional and conditional histograms for a simulation. We consider the flooding model. Let :math:`g` be a function which takes four inputs :math:`Q`, :math:`K_s`, :math:`Z_v` and :math:`Z_m` and returns one output :math:`H`. 

We first consider the (unconditional) distribution of the input :math:`Q`. 

Let :math:`t` be a given threshold on the output :math:`H`: we consider the event :math:`H>t`. Then we consider the conditional distribution of the input :math:`Q` given that :math:`H>t` : :math:`Q|H>t`. 

If these two distributions are significantly different, we conclude that the input :math:`Q` has an impact on the event :math:`H>t`. 

In order to approximate the distribution of the output :math:`H`, we perform a Monte-Carlo simulation with size 500. The threshold :math:`t` is chosen as the 90% quantile of the empirical distribution of :math:`H`. In this example, the distribution is aproximated by its empirical histogram (but this could be done with another distribution approximation as well, such as kernel smoothing for example).


.. code-block:: default

    import openturns as ot
    import openturns.viewer as viewer
    from matplotlib import pylab as plt
    ot.Log.Show(ot.Log.NONE)








Create the marginal distributions of the parameters.


.. code-block:: default

    dist_Q = ot.TruncatedDistribution(ot.Gumbel(558., 1013.), 0, ot.TruncatedDistribution.LOWER)
    dist_Ks = ot.TruncatedDistribution(ot.Normal(30.0, 7.5), 0, ot.TruncatedDistribution.LOWER)
    dist_Zv = ot.Uniform(49.0, 51.0)
    dist_Zm = ot.Uniform(54.0, 56.0)
    marginals = [dist_Q, dist_Ks, dist_Zv, dist_Zm]








Create the joint probability distribution.


.. code-block:: default

    distribution = ot.ComposedDistribution(marginals)
    distribution.setDescription(['Q', 'Ks', 'Zv', 'Zm'])








Create the model.


.. code-block:: default

    model = ot.SymbolicFunction(['Q', 'Ks', 'Zv', 'Zm'],
                                ['(Q/(Ks*300.*sqrt((Zm-Zv)/5000)))^(3.0/5.0)'])








Create a sample.


.. code-block:: default

    size = 500
    inputSample = distribution.getSample(size)
    outputSample = model(inputSample)








Merge the input and output samples into a single sample.


.. code-block:: default

    sample = ot.Sample(size,5)
    sample[:,0:4] = inputSample
    sample[:,4] = outputSample
    sample[0:5,:]






.. raw:: html

    <TABLE><TR><TD></TD><TH>v0</TH><TH>v1</TH><TH>v2</TH><TH>v3</TH><TH>v4</TH></TR>
    <TR><TH>0</TH><TD>1323.962</TD><TD>26.57518</TD><TD>49.74106</TD><TD>54.58294</TD><TD>2.731202</TD></TR>
    <TR><TH>1</TH><TD>1497.5</TD><TD>13.19199</TD><TD>50.07319</TD><TD>55.33205</TD><TD>4.367017</TD></TR>
    <TR><TH>2</TH><TD>2321.892</TD><TD>25.42722</TD><TD>50.70245</TD><TD>54.64148</TD><TD>4.179532</TD></TR>
    <TR><TH>3</TH><TD>2573.957</TD><TD>33.68394</TD><TD>50.29902</TD><TD>55.59993</TD><TD>3.435739</TD></TR>
    <TR><TH>4</TH><TD>991.2017</TD><TD>26.94119</TD><TD>49.19637</TD><TD>54.44174</TD><TD>2.222965</TD></TR>
    </TABLE>
    <br />
    <br />

Extract the first column of `inputSample` into the sample of the flowrates :math:`Q`.


.. code-block:: default

    sampleQ = inputSample[:,0]









.. code-block:: default

    import numpy as np

    def computeConditionnedSample(sample, alpha = 0.9, criteriaComponent = None, selectedComponent = 0):
        '''
        Return values from the selectedComponent-th component of the sample. 
        Selects the values according to the alpha-level quantile of 
        the criteriaComponent-th component of the sample.
        '''
        dim = sample.getDimension()
        if criteriaComponent is None:
            criteriaComponent = dim - 1
        sortedSample = sample.sortAccordingToAComponent(criteriaComponent)   
        quantiles = sortedSample.computeQuantilePerComponent(alpha)
        quantileValue = quantiles[criteriaComponent]
        sortedSampleCriteria = sortedSample[:,criteriaComponent]
        indices = np.where(np.array(sortedSampleCriteria.asPoint())>quantileValue)[0]
        conditionnedSortedSample = sortedSample[int(indices[0]):,selectedComponent]
        return conditionnedSortedSample









Create an histogram for the unconditional flowrates.


.. code-block:: default

    numberOfBins = 10
    histogram = ot.HistogramFactory().buildAsHistogram(sampleQ,numberOfBins)








Extract the sub-sample of the input flowrates Q which leads to large values of the output H.


.. code-block:: default

    alpha = 0.9
    criteriaComponent = 4
    selectedComponent = 0
    conditionnedSampleQ = computeConditionnedSample(sample,alpha,criteriaComponent,selectedComponent)








We could as well use:
```
conditionnedHistogram = ot.HistogramFactory().buildAsHistogram(conditionnedSampleQ)
```
but this creates an histogram with new classes, corresponding 
to `conditionnedSampleQ`.
We want to use exactly the same classes as the full sample, 
so that the two histograms match.


.. code-block:: default

    first = histogram.getFirst()
    width = histogram.getWidth()
    conditionnedHistogram = ot.HistogramFactory().buildAsHistogram(conditionnedSampleQ,first,width)








Then creates a graphics with the unconditional and the conditional histograms.


.. code-block:: default

    graph = histogram.drawPDF()
    graph.setLegends(["Q"])
    #
    graphConditionnalQ = conditionnedHistogram.drawPDF()
    graphConditionnalQ.setColors(["blue"])
    graphConditionnalQ.setLegends(["Q|H>H_%s" % (alpha)])
    graph.add(graphConditionnalQ)
    view = viewer.View(graph)

    plt.show()



.. image:: /auto_data_analysis/sample_analysis/images/sphx_glr_plot_compare_unconditional_conditional_histograms_001.png
    :alt: Q PDF
    :class: sphx-glr-single-img





We see that the two histograms are very different. The high values of the input :math:`Q` seem to often lead to a high value of the output :math:`H`. 

We could explore this situation further by comparing the unconditional distribution of :math:`Q` (which is known in this case) with the conditonal distribution of :math:`Q|H>t`, estimated by kernel smoothing. This would have the advantage of accuracy, since the kernel smoothing is a more accurate approximation of a distribution than the histogram. 


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.096 seconds)


.. _sphx_glr_download_auto_data_analysis_sample_analysis_plot_compare_unconditional_conditional_histograms.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_compare_unconditional_conditional_histograms.py <plot_compare_unconditional_conditional_histograms.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_compare_unconditional_conditional_histograms.ipynb <plot_compare_unconditional_conditional_histograms.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
