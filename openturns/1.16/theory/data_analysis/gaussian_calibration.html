
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gaussian calibration &#8212; OpenTURNS 1.16rc1 documentation</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/openturns.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/js/mysearchtools.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="The Metropolis-Hastings Algorithm" href="metropolis_hastings.html" />
    <link rel="prev" title="Code calibration" href="code_calibration.html" />
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,700'
          rel='stylesheet' type='text/css' />
 

  </head><body>
<div class="pageheader">
  <ul>
    <li><a href="http://www.openturns.org/">Home</a></li>
    <li><a href="../../install.html">Get it</a></li>
    <li><a href="../../contents.html">Doc</a></li>
    <li><a href="https://openturns.discourse.group/">Forum</a></li>
    <li><a href="https://gitter.im/openturns/community">Chat</a></li>
    <li><a href="https://github.com/openturns">Code</a></li>
    <li><a href="https://github.com/openturns/openturns/issues">Bugs</a></li>
  </ul>
  <a href="../../index.html">
    <h1>
      <img src="../../_static/logo-openturns-wo-bg.png" alt="" width=100px height=100px />
      OpenTURNS
    </h1>
    <h2> An Open source initiative for the Treatment of Uncertainties, Risks'N Statistics</h2>
  </a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="metropolis_hastings.html" title="The Metropolis-Hastings Algorithm"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="code_calibration.html" title="Code calibration"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.16rc1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="data_analysis.html" accesskey="U">Data analysis</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Gaussian calibration</a></li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Gaussian calibration</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#bayesian-calibration">Bayesian calibration</a></li>
<li><a class="reference internal" href="#posterior-distribution">Posterior distribution</a></li>
<li><a class="reference internal" href="#map-estimator">MAP estimator</a></li>
<li><a class="reference internal" href="#regularity-of-solutions-of-the-gaussian-calibration">Regularity of solutions of the Gaussian Calibration</a></li>
<li><a class="reference internal" href="#non-linear-gaussian-calibration-3dvar">Non Linear Gaussian Calibration : 3DVAR</a></li>
<li><a class="reference internal" href="#solving-the-non-linear-gaussian-calibration-problem">Solving the Non Linear Gaussian Calibration Problem</a></li>
<li><a class="reference internal" href="#linear-gaussian-calibration-bayesian-blue">Linear Gaussian Calibration : bayesian BLUE</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="code_calibration.html"
                        title="previous chapter">Code calibration</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="metropolis_hastings.html"
                        title="next chapter">The Metropolis-Hastings Algorithm</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/theory/data_analysis/gaussian_calibration.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="gaussian-calibration">
<span id="id1"></span><h1>Gaussian calibration<a class="headerlink" href="#gaussian-calibration" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>We consider a computer model <img class="math" src="../../_images/math/7d315384fec037fcfc27ae0d493990634c221380.svg" alt="\vect{h}"/> (i.e. a deterministic function)
to calibrate:</p>
<div class="math">
<p><img src="../../_images/math/0180bd6b9b2f68ac2afaca596e8c7b17747685fe.svg" alt="\vect{z} = \vect{h}(\vect{x}, \vect{\theta}),"/></p>
</div><p>where</p>
<ul class="simple">
<li><p><img class="math" src="../../_images/math/5f8d085ff7a94633b66509c2458ae39062c7a075.svg" alt="\vect{x} \in \Rset^{d_x}"/> is the input vector;</p></li>
<li><p><img class="math" src="../../_images/math/86f4207749a44bc61ce51b9b5c8013308f3e0a7c.svg" alt="\vect{z} \in \Rset^{d_z}"/> is the output vector;</p></li>
<li><p><img class="math" src="../../_images/math/7aeabd95eb7199f7b641aefd553b3223bf865650.svg" alt="\vect{\theta} \in \Rset^{d_h}"/> are the unknown parameters of
<img class="math" src="../../_images/math/7d315384fec037fcfc27ae0d493990634c221380.svg" alt="\vect{h}"/> to calibrate.</p></li>
</ul>
<p>Let <img class="math" src="../../_images/math/c991210f5683933d37af4267d643d132c2e98fdb.svg" alt="n \in \Nset"/> be the number of observations.
The standard hypothesis of the probabilistic calibration is:</p>
<div class="math">
<p><img src="../../_images/math/108a3b2545e837061d123033304b179d27136046.svg" alt="\vect{y}^i = \vect{z}^i + \vect{\varepsilon}^i,"/></p>
</div><p>for <img class="math" src="../../_images/math/f547f9b5b4447a6ea60f75e19838225adb8f96e6.svg" alt="i=1,...,n"/> where <img class="math" src="../../_images/math/3c98ec731fa32e9afabcb0c477b07d3a0b98fe1d.svg" alt="\vect{\varepsilon}^i"/> is a random measurement error.</p>
<p>The goal of gaussian calibration is to estimate <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>, based on
observations of <img class="math" src="../../_images/math/80b394abd4fb264a3879675f92f191c3e346c3a0.svg" alt="n"/> inputs <img class="math" src="../../_images/math/6f014500414fb8861bf67896b369604174a1dced.svg" alt="(\vect{x}^1, \ldots, \vect{x}^n)"/>
and the associated <img class="math" src="../../_images/math/80b394abd4fb264a3879675f92f191c3e346c3a0.svg" alt="n"/> observations of the output
<img class="math" src="../../_images/math/aaab746da739cf1afe5dd4ff217d26da10323542.svg" alt="(\vect{y}^1, \ldots, \vect{y}^n)"/>.
In other words, the calibration process reduces the discrepancy between
the observations <img class="math" src="../../_images/math/aaab746da739cf1afe5dd4ff217d26da10323542.svg" alt="(\vect{y}^1, \ldots, \vect{y}^n)"/> and the
predictions <img class="math" src="../../_images/math/3dc2d03c8e412516e89418351b021735980a7918.svg" alt="\vect{h}(\vect{\theta})"/>.
Given that <img class="math" src="../../_images/math/aaab746da739cf1afe5dd4ff217d26da10323542.svg" alt="(\vect{y}^1, \ldots, \vect{y}^n)"/> are realizations of a
random variable, the estimate of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>, denoted by
<img class="math" src="../../_images/math/93b453baae5c5dfdfa54beec40ded96b04643493.svg" alt="\hat{\vect{\theta}}"/>, is also a random variable.
Hence, the secondary goal of calibration is to estimate the distribution of
<img class="math" src="../../_images/math/93b453baae5c5dfdfa54beec40ded96b04643493.svg" alt="\hat{\vect{\theta}}"/> representing the uncertainty of the calibration
process.</p>
<p>In the remaining of this section, the input <img class="math" src="../../_images/math/8b7ee9a80df5460444f07ca8491ea7ca3ae29f33.svg" alt="\vect{x}"/> is not involved
anymore in the equations.
This is why we simplify the equation into:</p>
<div class="math">
<p><img src="../../_images/math/0dac1931898f565fa279cc02cce82834c764bf47.svg" alt="\vect{z} = \vect{h}(\vect{\theta})."/></p>
</div></div>
<div class="section" id="bayesian-calibration">
<h2>Bayesian calibration<a class="headerlink" href="#bayesian-calibration" title="Permalink to this headline">¶</a></h2>
<p>The bayesian calibration framework is based on two hypotheses.</p>
<p>The first hypothesis is that the parameter <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> has
a known distribution, called the <em>prior</em> distribution, and denoted by <img class="math" src="../../_images/math/d3a5f6129fe2a9b710d49e83d39ce87af7014852.svg" alt="p(\vect{\theta})"/>.</p>
<p>The second hypothesis is that the output observations <img class="math" src="../../_images/math/aaab746da739cf1afe5dd4ff217d26da10323542.svg" alt="(\vect{y}^1, \ldots, \vect{y}^n)"/>
are sampled from a known conditional distribution denoted by <img class="math" src="../../_images/math/e575499bf9b9179831fe2193797acf141022c6ab.svg" alt="p(\vect{y} | \vect{\theta})"/>.</p>
<p>For any <img class="math" src="../../_images/math/6197d7f28504100393cdf912cc57852188d8eba3.svg" alt="\vect{y}\in\Rset^{d_z}"/> such that <img class="math" src="../../_images/math/68e8e89248f9dd1c08c28f3b056e83bf8e5ebc1f.svg" alt="p(\vect{y})&gt;0"/>, the Bayes theorem implies
that the conditional distribution of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> given <img class="math" src="../../_images/math/a003da8172b7e5e0d51eb80984b45e02aa9742c7.svg" alt="\vect{y}"/> is:</p>
<div class="math">
<p><img src="../../_images/math/9f25c7d6f80043779564840769a16200bb13189f.svg" alt="p(\vect{\theta} | \vect{y}) = \frac{p(\vect{y} | \vect{\theta}) p(\vect{\theta})}{p(\vect{y})}"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>The denominator of the previous Bayes fraction is independent of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>, so that
the posterior distribution is proportional to the numerator:</p>
<div class="math">
<p><img src="../../_images/math/4cc588dc73b3b0a7dbc5d5b33b4ab507c696e41d.svg" alt="p(\vect{\theta} | \vect{y}) \propto  p(\vect{y} | \vect{\theta}) p(\vect{\theta})."/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>In the gaussian calibration, the two previous distributions are assumed to be gaussian.</p>
<p>More precisely, we make the hypothesis that the parameter <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>
has the gaussian distribution:</p>
<div class="math">
<p><img src="../../_images/math/459cbaec948ac816ae296eb821c2c352122b6fc6.svg" alt="\vect{\theta} \sim \mathcal{N}(\vect{\mu}, B),"/></p>
</div><p>where <img class="math" src="../../_images/math/b38af8545cb9dca9c7403a4898d427cbfc139c45.svg" alt="\vect{\mu}\in\Rset^{d_h}"/> is the mean of the gaussian prior distribution,
which is named the <em>background</em> and <img class="math" src="../../_images/math/7e7a572636f6b51c6989521c52ba798f7753fcaf.svg" alt="B\in\Rset^{d_h \times d_h}"/> is the covariance
matrix of the parameter.</p>
<p>Secondly, we make the hypothesis that the output observations have the conditional gaussian distribution:</p>
<div class="math">
<p><img src="../../_images/math/ce503c38300551ffc37446d563f7b25277c1fd7e.svg" alt="\vect{y} | \vect{\theta} \sim \mathcal{N}(\vect{h}(\vect{\theta}), R),"/></p>
</div><p>where <img class="math" src="../../_images/math/bc943040843c7d104f3171d246627ad063577f7e.svg" alt="R\in\Rset^{d_z \times d_z}"/> is the covariance
matrix of the output observations.</p>
</div>
<div class="section" id="posterior-distribution">
<h2>Posterior distribution<a class="headerlink" href="#posterior-distribution" title="Permalink to this headline">¶</a></h2>
<p>Denote by <img class="math" src="../../_images/math/aede47674b75c7f5757cde1f527212fca6a89631.svg" alt="\|\cdot\|_B"/> the Mahalanobis distance associated with the matrix
<img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/> :</p>
<div class="math">
<p><img src="../../_images/math/19238b0cb945eb3bd4917ec7ced70978e16b0b14.svg" alt="\|\vect{\theta}-\vect{\mu} \|^2_B = (\vect{\theta}-\vect{\mu} )^T B^{-1} (\vect{\theta}-\vect{\mu} ),"/></p>
</div><p>for any <img class="math" src="../../_images/math/4363774f316b928d468b956569c5898af2db0a7e.svg" alt="\vect{\theta},\vect{\mu} \in \Rset^{d_h}"/>.
Denote by <img class="math" src="../../_images/math/dcc73669da10ec43090a8f11abc1a7e7ebe74f67.svg" alt="\|\cdot\|_R"/> the Mahalanobis distance associated with the matrix
<img class="math" src="../../_images/math/ddc35335d91f00501b1be972e341ffcba6893269.svg" alt="R"/> :</p>
<div class="math">
<p><img src="../../_images/math/04e7e37ff3b3fdd65fa5b9470638172755c7cfb8.svg" alt="\|\vect{y}-H(\vect{\theta})\|^2_R = (\vect{y}-H(\vect{\theta}))^T R^{-1} (\vect{y}-H(\vect{\theta}))."/></p>
</div><p>for any <img class="math" src="../../_images/math/7aeabd95eb7199f7b641aefd553b3223bf865650.svg" alt="\vect{\theta} \in \Rset^{d_h}"/> and any <img class="math" src="../../_images/math/c23efaff98f2d7941a5a911744aaba6a68de6c87.svg" alt="\vect{y} \in \Rset^{d_z}"/>.
Therefore, the posterior distribution of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> given the observations <img class="math" src="../../_images/math/a003da8172b7e5e0d51eb80984b45e02aa9742c7.svg" alt="\vect{y}"/> is :</p>
<div class="math">
<p><img src="../../_images/math/53b5bf63f16f65e716dac851450164d5f79d9f03.svg" alt="p(\vect{\theta}|\vect{y}) \propto \exp\left( -\frac{1}{2} \left( \|\vect{y}-H(\vect{\theta})\|^2_R
+ \|\vect{\theta}-\vect{\mu} \|^2_B \right) \right)"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
</div>
<div class="section" id="map-estimator">
<h2>MAP estimator<a class="headerlink" href="#map-estimator" title="Permalink to this headline">¶</a></h2>
<p>The maximum of the posterior distribution of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> given the observations <img class="math" src="../../_images/math/a003da8172b7e5e0d51eb80984b45e02aa9742c7.svg" alt="\vect{y}"/> is
reached at :</p>
<div class="math">
<p><img src="../../_images/math/a87373fc370d45e92cd92d7101a80963599c87c3.svg" alt="\hat{\vect{\theta}} = arg min_{\vect{\theta}\in\Rset^{d_h}} \frac{1}{2} \left( \|\vect{y} - H(\vect{\theta})\|^2_R
+ \|\vect{\theta}-\vect{\mu} \|^2_B \right)."/></p>
</div><p>It is called the <em>maximum a posteriori posterior</em> estimator or
<em>MAP</em> estimator.</p>
</div>
<div class="section" id="regularity-of-solutions-of-the-gaussian-calibration">
<h2>Regularity of solutions of the Gaussian Calibration<a class="headerlink" href="#regularity-of-solutions-of-the-gaussian-calibration" title="Permalink to this headline">¶</a></h2>
<p>The gaussian calibration is a tradeoff, so that the
second expression acts as a <em>spring</em> which pulls the parameter
<img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> closer to the background <img class="math" src="../../_images/math/c3c1d698a41f95f7391a7e8153cadab64fae08a0.svg" alt="\vect{\mu}"/>
(depending on the “spring constant” <img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/>)
meanwhile getting as close a possible to the observations.
Depending on the matrix <img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/>, the computation may have
better regularity properties than the plain non linear least squares problem.</p>
</div>
<div class="section" id="non-linear-gaussian-calibration-3dvar">
<h2>Non Linear Gaussian Calibration : 3DVAR<a class="headerlink" href="#non-linear-gaussian-calibration-3dvar" title="Permalink to this headline">¶</a></h2>
<p>The cost function of the gaussian nonlinear calibration problem is :</p>
<div class="math">
<p><img src="../../_images/math/0c897180cf058e0b65f0e2646f129d8699a9cf7c.svg" alt="C(\vect{\theta}) = \frac{1}{2}\|\vect{y}-H(\vect{\theta})\|^2_R
+ \frac{1}{2}\|\vect{\theta}-\vect{\mu} \|^2_B"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>The goal of the non linear gaussian calibration is to find the
value of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> which minimizes the cost function <img class="math" src="../../_images/math/3b3be2405d41848960032b917a9b3d6e64e3ea81.svg" alt="C"/>.
In general, this involves using a nonlinear unconstrained optimization solver.</p>
<p>Let <img class="math" src="../../_images/math/72be4fc4609c321492c69563bef7d3e1eb1c61e7.svg" alt="J \in \Rset^{n \times d_h}"/> be the Jacobian matrix made of the
partial derivatives of <img class="math" src="../../_images/math/7d315384fec037fcfc27ae0d493990634c221380.svg" alt="\vect{h}"/> with respect to <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>:</p>
<div class="math">
<p><img src="../../_images/math/2c9c060f87e8550c305b8548bee5873648b5776e.svg" alt="J(\vect{\theta}) = \frac{\partial \vect{h}}{\partial \vect{\theta}}."/></p>
</div><p>The Jacobian matrix of the cost function <img class="math" src="../../_images/math/3b3be2405d41848960032b917a9b3d6e64e3ea81.svg" alt="C"/> can be expressed
depending on the matrices <img class="math" src="../../_images/math/ddc35335d91f00501b1be972e341ffcba6893269.svg" alt="R"/> and <img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/> and the Jacobian matrix
of the function <img class="math" src="../../_images/math/92cb4c95b7fc9b99a0b22cb07c90a732064db084.svg" alt="h"/>:</p>
<div class="math">
<p><img src="../../_images/math/9e7e3b97d4eb4dbae151e5fc5fb817493ab2ed6c.svg" alt="\frac{d }{d\vect{\theta}} C(\vect{\theta})
= B^{-1} (\vect{\theta}-\vect{\mu}) + J(\vect{\theta})^T R^{-1} (H(\vect{\theta}) - \vect{y})"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>The Hessian matrix of the cost function is</p>
<div class="math">
<p><img src="../../_images/math/39cb7a8215879901864e59e5d3c6b06c1af22c48.svg" alt="\frac{d^2 }{d\vect{\theta}^2} C(\vect{\theta})
= B^{-1}  + J(\vect{\theta})^T R^{-1} J(\vect{\theta})"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>If the covariance matrix <img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/> is positive definite,
then the Hessian matrix of the cost function is positive definite.
Under this hypothesis, the solution of the nonlinear gaussian calibration is unique.</p>
</div>
<div class="section" id="solving-the-non-linear-gaussian-calibration-problem">
<h2>Solving the Non Linear Gaussian Calibration Problem<a class="headerlink" href="#solving-the-non-linear-gaussian-calibration-problem" title="Permalink to this headline">¶</a></h2>
<p>The implementation of the resolution of the gaussian non linear calibration
problem involves the Cholesky decomposition of the covariance matrices <img class="math" src="../../_images/math/1d71b653f93c4f2b685a484d3080693edd6815ce.svg" alt="B"/>
and <img class="math" src="../../_images/math/ddc35335d91f00501b1be972e341ffcba6893269.svg" alt="R"/>.
This allows to transform the sum of two Mahalanobis distances into a single
euclidian norm.
This leads to a classical non linear least squares problem.</p>
</div>
<div class="section" id="linear-gaussian-calibration-bayesian-blue">
<h2>Linear Gaussian Calibration : bayesian BLUE<a class="headerlink" href="#linear-gaussian-calibration-bayesian-blue" title="Permalink to this headline">¶</a></h2>
<p>We make the hypothesis that <img class="math" src="../../_images/math/92cb4c95b7fc9b99a0b22cb07c90a732064db084.svg" alt="h"/> is linear with respect to <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/>,
i.e., for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>, we have:</p>
<div class="math">
<p><img src="../../_images/math/154ac24687309f5bf723f402984a25d7e1e33abc.svg" alt="h(\vect{\theta}) = h(\vect{\mu}) + J(\vect{\theta}-\vect{\mu} ),"/></p>
</div><p>where <img class="math" src="../../_images/math/d071d98281e6567114c0cdedc83b8b308820f3c8.svg" alt="J"/> is the constant Jacobian matrix of <img class="math" src="../../_images/math/92cb4c95b7fc9b99a0b22cb07c90a732064db084.svg" alt="h"/>.</p>
<p>Let <img class="math" src="../../_images/math/d190d025ba7be8d090786f8f258dff51a02fc296.svg" alt="A"/> be the matrix:</p>
<div class="math">
<p><img src="../../_images/math/5e3366ba9a43a624538d7c168094ebe19cd04b7a.svg" alt="A^{-1} = B^{-1} + J^T R^{-1} J."/></p>
</div><p>We denote by <img class="math" src="../../_images/math/c55b41eac82c4e5a8d7c5ae98795f4beb74baad1.svg" alt="K"/> the Kalman matrix:</p>
<div class="math">
<p><img src="../../_images/math/c86e58a5e57e8e9f0df97b99ce13a75217c15d2d.svg" alt="K = A J^T R^{-1}."/></p>
</div><p>The maximum of the posterior distribution of <img class="math" src="../../_images/math/5d535616eeb941f4cf5f21fee2588427aaece1ed.svg" alt="\vect{\theta}"/> given the
observations <img class="math" src="../../_images/math/a003da8172b7e5e0d51eb80984b45e02aa9742c7.svg" alt="\vect{y}"/> is:</p>
<div class="math">
<p><img src="../../_images/math/3115ef2696717deee1f54ba5ff13d279e5b7c87b.svg" alt="\hat{\vect{\theta}} = \vect{\mu} + K (\vect{y} - H(\vect{\mu}))."/></p>
</div><p>It can be proved that:</p>
<div class="math">
<p><img src="../../_images/math/3a5aa4fe33454c06c5b6b06d89bd80fe7632390f.svg" alt="p(\vect{\theta} | \vect{y}) \propto
\exp\left(\frac{1}{2} (\vect{\theta} - \hat{\vect{\theta}})^T A^{-1} (\vect{\theta} - \hat{\vect{\theta}}) \right)"/></p>
</div><p>for any <img class="math" src="../../_images/math/4f9025e95e31132c2e82e916c4be50303cfa421d.svg" alt="\vect{\theta}\in\Rset^{d_h}"/>.</p>
<p>This implies:</p>
<div class="math">
<p><img src="../../_images/math/95c6716a8ecd72aec0ef9e4ec8e66faaabe4db9d.svg" alt="\hat{\vect{\theta}} \sim \mathcal{N}(\vect{\theta},A)"/></p>
</div><div class="topic">
<p class="topic-title">API:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../user_manual/_generated/openturns.GaussianLinearCalibration.html#openturns.GaussianLinearCalibration" title="openturns.GaussianLinearCalibration"><code class="xref py py-class docutils literal notranslate"><span class="pre">GaussianLinearCalibration</span></code></a></p></li>
<li><p>See <a class="reference internal" href="../../user_manual/_generated/openturns.GaussianNonLinearCalibration.html#openturns.GaussianNonLinearCalibration" title="openturns.GaussianNonLinearCalibration"><code class="xref py py-class docutils literal notranslate"><span class="pre">GaussianNonLinearCalibration</span></code></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Examples:</p>
<ul class="simple">
<li><p>See <a class="reference internal" href="../../auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_flooding.html"><span class="doc">Calibration of the flooding model</span></a></p></li>
<li><p>See <a class="reference internal" href="../../auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_chaboche.html"><span class="doc">Calibration of the Chaboche mechanical model</span></a></p></li>
<li><p>See <a class="reference internal" href="../../auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_deflection_tube.html"><span class="doc">Calibration of the deflection of a tube</span></a></p></li>
<li><p>See <a class="reference internal" href="../../auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_logistic.html"><span class="doc">Calibration of the logistic model</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">References:</p>
<ul class="simple">
<li><ol class="upperalpha simple" start="14">
<li><ol class="upperalpha simple" start="8">
<li><p>Bingham and John M. Fry (2010). <em>Regression, Linear Models in Statistics</em>, Springer Undergraduate Mathematics Series. Springer.</p></li>
</ol>
</li>
</ol>
</li>
<li><ol class="upperalpha simple" start="19">
<li><p>Huet, A. Bouvier, M.A. Poursat, and E. Jolivet (2004). <em>Statistical Tools for Nonlinear Regression</em>, Springer.</p></li>
</ol>
</li>
<li><ol class="upperalpha simple" start="3">
<li><ol class="upperalpha simple" start="5">
<li><p>Rasmussen and C. K. I. Williams (2006), <em>Gaussian Processes for Machine Learning</em>, The MIT Press.</p></li>
</ol>
</li>
</ol>
</li>
</ul>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="metropolis_hastings.html" title="The Metropolis-Hastings Algorithm"
             >next</a> |</li>
        <li class="right" >
          <a href="code_calibration.html" title="Code calibration"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OpenTURNS 1.16rc1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../contents.html" >Contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../theory.html" >Theory</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="data_analysis.html" >Data analysis</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Gaussian calibration</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2020 Airbus-EDF-IMACS-ONERA-Phimeca.
      Last updated on Nov 13, 2020.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.4.0+.
    </div>
  </body>
</html>