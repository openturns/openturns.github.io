{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fit a non parametric distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we are going to estimate a non parametric distribution using the kernel smoothing method.\nAfter a short introductory example we focus on a few basic features of the API:\n\n- kernel selection\n- bandwidth estimation\n- an advanced feature such as boundary corrections\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as otv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## An introductory example\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create the data from a :class:`~openturns.Gamma` distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distribution = ot.Gamma(6.0, 1.0)\nsample = distribution.getSample(800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the kernel smoother and build the smoothed estimate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel = ot.KernelSmoothing()\nestimated = kernel.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can draw the original distribution vs the kernel smoothing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = distribution.drawPDF()\ngraph.setTitle(\"Kernel smoothing vs original\")\nkernel_plot = estimated.drawPDF().getDrawable(0)\ngraph.add(kernel_plot)\ngraph.setLegends([\"original\", \"KS\"])\ngraph.setLegendPosition(\"upper right\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can obtain the bandwdth parameter :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(kernel.getBandwidth())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compute a better bandwitdh with the Silverman rule.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bandwidth = kernel.computeSilvermanBandwidth(sample)\nprint(bandwidth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The new bandwidth is used to regenerate another fitted distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimated = kernel.build(sample, bandwidth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = distribution.drawPDF()\ngraph.setTitle(\"Kernel smoothing vs original\")\nkernel_plot = estimated.drawPDF().getDrawable(0)\ngraph.add(kernel_plot)\ngraph.setLegends([\"original\", \"KS-Silverman\"])\ngraph.setLegendPosition(\"upper right\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Silverman rule of thumb to estimate the bandwidth provides a better estimate for the distribution. We can also study the impact of the kernel selection.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choosing a kernel\n\nWe experiment with several kernels to perform the smoothing :\n\n- the standard Normal kernel\n- the triangular kernel\n- the Epanechnikov kernel\n- the uniform kernel\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first create the data from a Gamma distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distribution = ot.Gamma(6.0, 1.0)\nsample = distribution.getSample(800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The definition of the Normal kernel :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelNormal = ot.KernelSmoothing(ot.Normal())\nestimatedNormal = kernelNormal.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The definition of the Triangular kernel :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelTriangular = ot.KernelSmoothing(ot.Triangular())\nestimatedTriangular = kernelTriangular.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The definition of the Epanechnikov kernel :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelEpanechnikov = ot.KernelSmoothing(ot.Epanechnikov())\nestimatedEpanechnikov = kernelEpanechnikov.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The definition of the Uniform kernel :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelUniform = ot.KernelSmoothing(ot.Uniform())\nestimatedUniform = kernelUniform.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We finally compare all the distributions :\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = distribution.drawPDF()\ngraph.setTitle(\"Different kernel smoothings vs original distribution\")\ngraph.setGrid(True)\n\nkernel_estimatedNormal_plot = estimatedNormal.drawPDF().getDrawable(0)\ngraph.add(kernel_estimatedNormal_plot)\n\nkernel_estimatedTriangular_plot = estimatedTriangular.drawPDF().getDrawable(0)\ngraph.add(kernel_estimatedTriangular_plot)\n\nkernel_estimatedEpanechnikov_plot = estimatedEpanechnikov.drawPDF().getDrawable(0)\ngraph.add(kernel_estimatedEpanechnikov_plot)\n\nkernel_estimatedUniform_plot = estimatedUniform.drawPDF().getDrawable(0)\nkernel_estimatedUniform_plot.setLineStyle(\"dashed\")\ngraph.add(kernel_estimatedUniform_plot)\n\ngraph.setLegends(\n    [\"original\", \"KS-Normal\", \"KS-Triangular\", \"KS-Epanechnikov\", \"KS-Uniform\"]\n)\n\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that all the kernels produce very similar results in practice.\nThe Uniform kernel may be seen as the worst of them all while the Epanechnikov one is said to be a good theoritical choice. In practice the standard Normal kernel is a fine choice.\nThe most important aspect of kernel smoothing is the choice of the bandwidth.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bandwidth selection\n\nWe reproduce a classical example of the literature : the fitting of a bimodal distribution.\nWe will show the result of a kernel smoothing with different bandwidth computation :\n\n- the Silverman rule\n- the Plugin bandwidth\n- the Mixed bandwidth\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the bimodal distribution and generate a sample out of it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X1 = ot.Normal(10.0, 1.0)\nX2 = ot.Normal(-10.0, 1.0)\nmyDist = ot.Mixture([X1, X2])\nsample = myDist.getSample(2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compare the fitted distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = myDist.drawPDF()\ngraph.setTitle(\"Kernel smoothing vs original\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the Silverman rule :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelSB = ot.KernelSmoothing()\nbandwidthSB = kernelSB.computeSilvermanBandwidth(sample)\nestimatedSB = kernelSB.build(sample, bandwidthSB)\nkernelSB_plot = estimatedSB.drawPDF().getDrawable(0)\ngraph.add(kernelSB_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the Plugin bandwidth :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelPB = ot.KernelSmoothing()\nbandwidthPB = kernelPB.computePluginBandwidth(sample)\nestimatedPB = kernelPB.build(sample, bandwidthPB)\nkernelPB_plot = estimatedPB.drawPDF().getDrawable(0)\ngraph.add(kernelPB_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the Mixed bandwidth :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernelMB = ot.KernelSmoothing()\nbandwidthMB = kernelMB.computeMixedBandwidth(sample)\nestimatedMB = kernelMB.build(sample, bandwidthMB)\nkernelMB_plot = estimatedMB.drawPDF().getDrawable(0)\nkernelMB_plot.setLineStyle(\"dashed\")\ngraph.add(kernelMB_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph.setLegends([\"original\", \"KS-Silverman\", \"KS-Plugin\", \"KS-Mixed\"])\ngraph.setLegendPosition(\"upper right\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected the Silverman seriously overfit the data and the other rules are more to the point.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Boundary corrections\n\nWe detail here an advanced feature of the kernel smoothing, the boundary corrections.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider a Weibull distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "myDist = ot.WeibullMin(2.0, 1.5, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We generate a sample from the defined distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample = myDist.getSample(2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We draw the exact Weibull distribution :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = myDist.drawPDF()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use two different kernels :\n\n- a standard Normal kernel\n- the same kernel with a boundary correction\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first kernel without the boundary corrections.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel1 = ot.KernelSmoothing()\nestimated1 = kernel1.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second kernel with the boundary corrections.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel2 = ot.KernelSmoothing()\nkernel2.setBoundaryCorrection(True)\nestimated2 = kernel2.build(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compare the estimated PDFs :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph.setTitle(\"Kernel smoothing vs original\")\n\nkernel1_plot = estimated1.drawPDF().getDrawable(0)\ngraph.add(kernel1_plot)\n\nkernel2_plot = estimated2.drawPDF().getDrawable(0)\ngraph.add(kernel2_plot)\n\n\ngraph.setLegends([\"original\", \"KS\", \"KS with boundary correction\"])\ngraph.setLegendPosition(\"upper right\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The boundary correction made has a remarkable impact on the quality of the estimate for the small values.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log-transform treatment\n\nWe finish this example on another advanced feature of the kernel smoothing: the log-transform treatment.\nThis treatment is highly suited to skewed distributions, which are all challenging for kernel smoothing.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider several distributions which have significant skewness:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distCollection = [\n    ot.LogNormal(0.0, 2.5),\n    ot.Beta(20000.5, 2.5, 0.0, 1.0),\n    ot.Exponential(),\n    ot.WeibullMax(1.0, 0.9, 0.0),\n    ot.Mixture([ot.Normal(-1.0, 0.5), ot.Normal(1.0, 1.0)], [0.4, 0.6]),\n    ot.Mixture(\n        [ot.LogNormal(-1.0, 1.0, -1.0), ot.LogNormal(1.0, 1.0, 1.0)], [0.2, 0.8]\n    ),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each distribution, we do the following steps:\n\n- we generate a sample of size 5000,\n- we fit a kernel smoothing distribution without the log-transform treatment,\n- we fit a kernel smoothing distribution with the log-transform treatment,\n- we plot the real distribution and both non parametric estimations.\n\nOther transformations could be used, but the Log-transform one is quite effective. If the skewness is moderate,\nthere is almost no change wrt simple kernel smoothing. But if the skewness is large, the transformation performs\nvery well. Note that, in addition, this transformation performs an automatic boundary correction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = ot.GridLayout(2, 3)\not.RandomGenerator.SetSeed(0)\nfor i, distribution in enumerate(distCollection):\n    sample = distribution.getSample(5000)\n\n    # We draw the real distribution\n    graph = distribution.drawPDF()\n    graph.setLegends([distribution.getClassName()])\n    # We choose the default kernel\n    kernel = ot.KernelSmoothing()\n\n    # We activate no particular treatment\n    fitted = kernel.build(sample)\n    curve = fitted.drawPDF()\n    curve.setLegends([\"Fitted\"])\n    graph.add(curve)\n\n    # We activate the log-transform treatment\n    kernel.setUseLogTransform(True)\n    fitted = kernel.build(sample)\n    curve = fitted.drawPDF()\n    curve.setLegends([\"Fitted LogTransform\"])\n    curve = curve.getDrawable(0)\n    curve.setLineStyle(\"dashed\")\n\n    graph.add(curve)\n    grid.setGraph(i // 3, i % 3, graph)\n\nview = otv.View(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}