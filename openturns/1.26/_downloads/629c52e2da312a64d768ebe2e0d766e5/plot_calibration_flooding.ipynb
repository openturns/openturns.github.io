{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Calibration of the flooding model\n\nIn this example we are interested in the calibration of the `flooding model <use-case-flood-model>`.\nWe calibrate the parameters of a flooding model where only the difference between the\ndownstream and upstream riverbed levels can be calibrated.\nThis example shows how to manage the lack of identifiability in a calibration problem.\n\nThis example use least squares to calibrate the parametric\nmodel.\nPlease read `code_calibration` for more details on code calibration and least squares.\nThis study is relatively complicated: please read the :doc:`calibration of the Chaboche mechanical model\n</auto_calibration/least_squares_and_gaussian_calibration/plot_calibration_chaboche>` first if this is not already done.\nThe observations that we use in this study are simulated with the script\n:doc:`Generate flooding model observations\n</auto_calibration/least_squares_and_gaussian_calibration/plot_generate_flooding>`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters to calibrate and observations\n\nThe variables of the model are:\n\n- $Q$ : Input. Observed.\n- $K_s$, $Z_v$, $Z_m$ : Input. Calibrated.\n- $H$: Output. Observed.\n\nThe vector of parameters to calibrate is:\n\n\\begin{align}\\theta = (K_s,Z_v,Z_m).\\end{align}\n\nIn the description of the `flooding model<use-case-flood-model>`,\nwe see that only one parameter can be identified.\nHence, calibrating this model requires some regularization.\nWe return to this topic when analyzing the singular values of\nthe Jacobian matrix.\n\nWe consider a sample size equal to:\n\n\\begin{align}n = 10.\\end{align}\n\n\nThe observations are the couples $\\{(Q_i,H_i)\\}_{i=1,...,n}$, i.e. each observation is a\ncouple made of the flowrate and the corresponding river height.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from openturns.usecases import flood_model\nfrom matplotlib import pyplot as plt\nimport openturns.viewer as otv\nimport numpy as np\nimport openturns as ot\n\not.ResourceMap.SetAsUnsignedInteger(\"Normal-SmallDimension\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the observations\nIn practice, we generally use a data set which has been obtained from\nmeasurements.\nThis data set can be loaded using e.g. :meth:`~openturns.Sample.ImportFromCSVFile`.\nHere we import the data from the\n:class:`~openturns.usecases.flood_model.FloodModel`\nclass.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fm = flood_model.FloodModel()\nQobs = fm.data[:, 0]\nHobs = fm.data[:, 1]\nnbobs = fm.data.getSize()\nfm.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the physical model\nWe define the model $g$ which has 4 inputs and one output H.\n\nThe nonlinear least squares algorithm does not take into account for bounds\nin the parameters.\nTherefore, we ensure that the output is computed whatever the inputs.\nThe model fails into two situations:\n\n* if $K_s<0$,\n* if $Z_v-Z_m<0$.\n\nIn these cases, we return an infinite number, so that the optimization\nalgorithm does not get trapped.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def functionFlooding(X):\n    L = 5.0e3\n    B = 300.0\n    Q, K_s, Z_v, Z_m = X\n    alpha = (Z_m - Z_v) / L\n    if alpha < 0.0 or K_s <= 0.0:\n        H = np.inf\n    else:\n        H = (Q / (K_s * B * np.sqrt(alpha))) ** (3.0 / 5.0)\n    return [H]\n\n\ng = ot.PythonFunction(4, 1, functionFlooding)\ng = ot.MemoizeFunction(g)\ng.setInputDescription([\"Q ($m^3/s$)\", \"Ks ($m^{1/3}/s$)\", \"Zv (m)\", \"Zm (m)\"])\ng.setOutputDescription([\"H (m)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting the calibration parameters\nDefine the value of the reference values of the $\\theta$ parameter.\nIn the Bayesian framework, this is called the mean of the *prior* normal\ndistribution.\nIn the data assimilation framework, this is called the *background*.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "KsInitial = 20.0\nZvInitial = 49.0\nZmInitial = 51.0\nthetaPrior = [KsInitial, ZvInitial, ZmInitial]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the parametric function\nIn the physical model, the inputs and parameters are ordered as\npresented in the next table.\nNotice that there are no parameters in the physical model.\n\n+-------+----------------+\n| Index | Input variable |\n+=======+================+\n| 0     | Q              |\n+-------+----------------+\n| 1     | Ks             |\n+-------+----------------+\n| 2     | Zv             |\n+-------+----------------+\n| 3     | Zm             |\n+-------+----------------+\n\n+-------+-----------+\n| Index | Parameter |\n+=======+===========+\n| \u2205     | \u2205         |\n+-------+-----------+\n\n**Table 1.** Indices and names of the inputs and parameters of the physical model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Physical Model Inputs:\", g.getInputDescription())\nprint(\"Physical Model Parameters:\", g.getParameterDescription())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to perform calibration, we have to define a parametric model,\nwith observed inputs and parameters to calibrate.\nIn order to do this, we create a :class:`~openturns.ParametricFunction`\nwhere the parameters are `Ks`, `Zv` and `Zm` which have the indices 1, 2\nand 3 in the physical model.\n\n+-------+----------------+\n| Index | Input variable |\n+=======+================+\n| 0     | Q              |\n+-------+----------------+\n\n+-------+-----------+\n| Index | Parameter |\n+=======+===========+\n| 0     | Ks        |\n+-------+-----------+\n| 1     | Zv        |\n+-------+-----------+\n| 2     | Zm        |\n+-------+-----------+\n\n**Table 2.** Indices and names of the inputs and parameters of the parametric model.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following statement creates the calibrated function from the model.\nThe calibrated parameters $K_s$, $Z_v$, $Z_m$ are at\nindices 1, 2, 3 in the inputs arguments of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calibratedIndices = [1, 2, 3]\nmycf = ot.ParametricFunction(g, calibratedIndices, thetaPrior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the Y observations versus the X observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = ot.Graph(\"Observations\", \"Q ($m^3/s$)\", \"H (m)\", True)\n# Plot the model before calibration\ncurve = mycf.draw(100.0, 4000.0).getDrawable(0)\ncurve.setLegend(\"Model, before calibration\")\ncurve.setLineStyle(ot.ResourceMap.GetAsString(\"CalibrationResult-ObservationLineStyle\"))\ngraph.add(curve)\n# Plot the noisy observations\ncloud = ot.Cloud(Qobs, Hobs)\ncloud.setLegend(\"Observations\")\ncloud.setPointStyle(\n    ot.ResourceMap.GetAsString(\"CalibrationResult-ObservationPointStyle\")\n)\ngraph.add(cloud)\n#\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the model does not fit to the data.\nThe goal of calibration is to find which parameter best fit to the\nobservations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calibration with linear least squares\nThe :class:`~openturns.LinearLeastSquaresCalibration` class performs the linear\nleast squares calibration by linearizing the model in the neighbourhood of\nthe reference point.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.LinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior, \"SVD\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.LinearLeastSquaresCalibration.run` method computes the\nsolution of the problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()\ncalibrationResult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the\nmaximum of the posterior distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetaMAP = calibrationResult.getParameterMAP()\nprint(\"theta After = \", thetaMAP)\nprint(\"theta Before = \", thetaPrior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the true values of the parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"True theta\")\nprint(\"  Ks = \", fm.trueKs)\nprint(\"  Zv = \", fm.trueZv)\nprint(\"  Zm = \", fm.trueZm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, we see that there seems to be a great distance from the\nreference value of $\\theta$ to the optimum: the values seem too large in magnitude.\nAs we are going to see, there is an identification problem because the\nJacobian matrix is rank-degenerate.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnostic of the identification issue\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we show how to diagnose the identification problem.\n\nThe :meth:`~openturns.CalibrationResult.getParameterPosterior` method returns\nthe posterior normal distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distributionPosterior = calibrationResult.getParameterPosterior()\nprint(distributionPosterior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there is a large covariance matrix diagonal.\n\nLet us compute a 95% confidence interval for the solution $\\theta^\\star$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(\n        0.95\n    )[0]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The confidence interval is *very* large.\nIn order to clarify the situation, we compute the Jacobian matrix of the\nmodel at the candidate point.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mycf.setParameter(thetaPrior)\nthetaDim = len(thetaPrior)\njacobianMatrix = ot.Matrix(nbobs, thetaDim)\nfor i in range(nbobs):\n    jacobianMatrix[i, :] = mycf.parameterGradient(Qobs[i]).transpose()\nprint(jacobianMatrix[0:5, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rank of the problem can be seen from the singular values of the Jacobian\nmatrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(jacobianMatrix.computeSingularValues())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there are two singular values which are relatively close to zero.\n\nThis explains why the Jacobian matrix is close to being rank-degenerate.\n\nMoreover, this allows one to compute the actual dimensionality of the problem.\nThe algorithm we use computes the singular values in descending order.\nMoreover, by definition, the singular values are nonnegative.\nWe see that the first singular value is close to $10$\nand the others are very close to $0$ in comparison.\nThis implies that the (numerical) rank of the Jacobian matrix is 1,\neven if there are 3 parameters.\n\nHence, only one parameter can be identified, be it $K_s$, $Z_v$\nor $Z_m$.\nThe choice of the particular parameter to identify is free.\nHowever, in hydraulic studies, the parameter $K_s$ is classically\ncalibrated while $Z_v$ and $Z_m$ are left constant.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion of the linear least squares calibration\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are several methods to solve the problem.\n\n* Given that the problem is not identifiable, we can use some regularization\n  method. Two methods are provided in the library: the Gaussian linear least\n  squares `GaussianLinearCalibration` and the Gaussian non linear least\n  squares `GaussianNonlinearCalibration`.\n* We can change the problem, replacing it with a problem which is identifiable.\n  In the flooding model, we can view $Z_v$ and $Z_m$ as\n  constants and calibrate $K_s$ only.\n\nIn this example, we do not change the problem and see how the different\nmethods perform.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calibration with non linear least squares\nThe :class:`~openturns.NonLinearLeastSquaresCalibration` class performs the\nnon linear least squares calibration by minimizing the squared Euclidian norm\nbetween the predictions and the observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.NonLinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaPrior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.NonLinearLeastSquaresCalibration.run` method computes\nthe solution of the problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()\ncalibrationResult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the results\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the\nmaximum of the posterior distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetaMAP = calibrationResult.getParameterMAP()\nprint(thetaMAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute a 95% confidence interval of the parameter $\\theta^\\star$.\n\nThis confidence interval is based on bootstrap, based on a sample size equal\nto 100 (as long as the value of the :class:`~openturns.ResourceMap` key\n\"NonLinearLeastSquaresCalibration-BootstrapSize\" is unchanged).\nThis confidence interval reflects the sensitivity of the optimum\nto the variability in the observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    ot.ResourceMap.GetAsUnsignedInteger(\n        \"NonLinearLeastSquaresCalibration-BootstrapSize\"\n    )\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetaPosterior = calibrationResult.getParameterPosterior()\nprint(thetaPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the values of the parameters are quite accurately\ncomputed.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increase the default number of points in the plots.\nThis produces smoother spiky distributions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ot.ResourceMap.SetAsUnsignedInteger(\"Distribution-DefaultPointNumber\", 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsInputs()\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there is a good fit after calibration, since the predictions after calibration\nare close to the observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsPredictions()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there is a much better fit after calibration, since the\npredictions are close to the diagonal of the graphics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observationError = calibrationResult.getObservationsError()\nprint(observationError)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the observation error has a sample mean close to zero and a\nsample standard deviation approximately equal to 0.11.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 5\ngraph = calibrationResult.drawResiduals()\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The analysis of the residuals shows that the distribution is centered on\nzero and symmetric.\nThis indicates that the calibration performed well.\nMoreover, the distribution of the residuals is close to being Gaussian.\nThis is an important hypothesis of the least squares method so that\nchecking that this hypothesis occurs in the study is an important\nverification.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawParameterDistributions()\nview = otv.View(\n    graph,\n    figure_kw={\"figsize\": (8.0, 3.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.8, bottom=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plotDistributionGridPDF(distribution):\n    \"\"\"\n    Plot the marginal and bi-dimensional iso-PDF on a grid.\n\n    Parameters\n    ----------\n    distribution : ot.Distribution\n        The distribution.\n\n    Returns\n    -------\n    grid : ot.GridLayout(dimension, dimension)\n        The grid of plots.\n\n    \"\"\"\n    dimension = distribution.getDimension()\n    grid = ot.GridLayout(dimension, dimension)\n    for i in range(dimension):\n        for j in range(dimension):\n            if i == j:\n                distributionI = distribution.getMarginal([i])\n                graph = distributionI.drawPDF()\n            else:\n                distributionJI = distribution.getMarginal([j, i])\n                graph = distributionJI.drawPDF()\n            graph.setLegends([\"\"])\n            graph.setTitle(\"\")\n            if i < dimension - 1:\n                graph.setXTitle(\"\")\n            if j > 0:\n                graph.setYTitle(\"\")\n            grid.setGraph(i, j, graph)\n    grid.setTitle(\"Iso-PDF values\")\n    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF values of the distribution of the optimum parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = plotDistributionGridPDF(thetaPosterior)\nview = otv.View(\n    grid,\n    figure_kw={\"figsize\": (9.0, 6.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(wspace=1.0, hspace=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gaussian linear calibration\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The standard deviation of the observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigmaH = 0.5  # (m^2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the covariance matrix of the output Y of the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "errorCovariance = ot.CovarianceMatrix(1)\nerrorCovariance[0, 0] = sigmaH**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the covariance matrix of the parameters $\\theta$ to calibrate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigmaKs = 5.0\nsigmaZv = 1.0\nsigmaZm = 1.0\n#\nsigma = ot.CovarianceMatrix(3)\nsigma[0, 0] = sigmaKs**2\nsigma[1, 1] = sigmaZv**2\nsigma[2, 2] = sigmaZm**2\nprint(sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :class:`~openturns.GaussianLinearCalibration` class performs Gaussian\nlinear calibration by linearizing the model in the neighbourhood of the prior.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.GaussianLinearCalibration(\n    mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance, \"SVD\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianLinearCalibration.run` method computes\nthe solution of the problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()\ncalibrationResult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the results\nThe :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the\nmaximum of the posterior distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetaMAP = calibrationResult.getParameterMAP()\nprint(thetaMAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsInputs()\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the output of the model after calibration is closer to the\nobservations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsPredictions()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the fit is satisfactory after calibration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawResiduals()\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the distribution of the residual is centered on zero after\ncalibration.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.CalibrationResult.getParameterPosterior` method\nreturns the posterior normal distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distributionPosterior = calibrationResult.getParameterPosterior()\nprint(distributionPosterior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute a 95% credibility interval of the parameter $\\theta^\\star$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(\n        0.95\n    )[0]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there is a large uncertainty on the value of the parameter\n$K_s$ which can be as small as $14$ and as large as $34$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare the prior and posterior distributions of the marginals of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawParameterDistributions()\nview = otv.View(\n    graph,\n    figure_kw={\"figsize\": (8.0, 3.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.8, bottom=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two distributions are different, which shows that the calibration is\nsensitive to the observations (if the observations were not sensitive, the\ntwo distributions were superimposed).\nMoreover, the two distributions are quite close, which implies that the prior\ndistribution has played a role in the calibration (otherwise the two\ndistributions would be completely different,\nindicating that only the observations were taken into account).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF values of the distribution of the optimum parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = plotDistributionGridPDF(thetaPosterior)\nview = otv.View(\n    grid,\n    figure_kw={\"figsize\": (9.0, 6.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(wspace=1.0, hspace=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gaussian nonlinear calibration\nThe :class:`~openturns.GaussianNonLinearCalibration` class performs Gaussian\nnonlinear calibration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo = ot.GaussianNonLinearCalibration(\n    mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.GaussianNonLinearCalibration.run` method computes the\nsolution of the problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo.run()\ncalibrationResult = algo.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the results\nThe :meth:`~openturns.CalibrationResult.getParameterMAP` method returns the\nmaximum of the posterior distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetaMAP = calibrationResult.getParameterMAP()\nprint(thetaMAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsInputs()\ngraph.setLegendPosition(\"upper left\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the output of the model after calibration is in the middle of the\nobservations: the calibration seems correct.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawObservationsVsPredictions()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit is excellent after calibration. Indeed, the cloud of points after calibration is on the diagonal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawResiduals()\nview = otv.View(\n    graph,\n    figure_kw={\"figsize\": (8.0, 4.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the distribution of the residual is centered on zero.\nThis is a proof that the calibration did perform correctly.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.CalibrationResult.getParameterPosterior` method\nreturns the posterior normal distribution of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distributionPosterior = calibrationResult.getParameterPosterior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute a 95% credibility interval of the parameter $\\theta^\\star$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(\n        0.95\n    )[0]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there is a small uncertainty on the value of all parameters.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare the prior and posterior distributions of the marginals of $\\theta$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = calibrationResult.drawParameterDistributions()\nview = otv.View(\n    graph,\n    figure_kw={\"figsize\": (8.0, 3.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.8, bottom=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two distributions are very different, with a spiky posterior distribution.\nThis shows that the calibration is very sensitive to the observations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF values of the distribution of the optimum parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = plotDistributionGridPDF(thetaPosterior)\nview = otv.View(\n    grid,\n    figure_kw={\"figsize\": (9.0, 6.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(wspace=1.0, hspace=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning the posterior distribution estimation\n\nThe \"GaussianNonLinearCalibration-BootstrapSize\" key of the\n:class:`~openturns.ResourceMap` controls the posterior distribution estimation.\n\n* If \"GaussianNonLinearCalibration-BootstrapSize\" > 0 (by default it is equal to 100),\n  then a bootstrap resample algorithm is used to see the dispersion of the MAP estimator.\n  This allows one to see the variability of the estimator with respect to\n  the finite noisy observation sample.\n* If \"GaussianNonLinearCalibration-BootstrapSize\" is zero, then the\n  Gaussian linear calibration estimator is used (i.e. the :class:`~openturns.GaussianLinearCalibration`\n  class) at the optimum. This is called the Laplace approximation.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The default value of the key is nonzero, meaning that bootstrap is used.\nThis can be costly in some cases, because it requires to repeat the\noptimization several times.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(ot.ResourceMap.GetAsUnsignedInteger(\"GaussianNonLinearCalibration-BootstrapSize\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We must configure the key before creating the object (otherwise changing\nthe parameter does not change the result).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ot.ResourceMap.SetAsUnsignedInteger(\"GaussianNonLinearCalibration-BootstrapSize\", 0)\nalgo = ot.GaussianNonLinearCalibration(\n    mycf, Qobs, Hobs, thetaPrior, sigma, errorCovariance\n)\nalgo.run()\ncalibrationResult = algo.getResult()\ngraph = calibrationResult.drawParameterDistributions()\nview = otv.View(\n    graph,\n    figure_kw={\"figsize\": (8.0, 3.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(right=0.8, bottom=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, this does not change much the posterior distribution, which remains spiky.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the PDF values of the distribution of the optimum parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = plotDistributionGridPDF(thetaPosterior)\nview = otv.View(\n    grid,\n    figure_kw={\"figsize\": (9.0, 6.0)},\n    legend_kw={\"bbox_to_anchor\": (1.0, 1.0), \"loc\": \"upper left\"},\n)\nplt.subplots_adjust(wspace=1.0, hspace=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}