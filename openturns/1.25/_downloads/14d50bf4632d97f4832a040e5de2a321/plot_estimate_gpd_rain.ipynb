{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Estimate a GPD on the daily rainfall data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we illustrate various techniques of extreme value modeling applied\nto the daily rainfall accumulations in south-west England, over the period 1914-1962.\nReaders should refer to [coles2001]_ to get more details.\n\nWe illustrate techniques to:\n\n- estimate a stationary and a non stationary GPD,\n- estimate a return level,\n\nusing:\n\n- the log-likelihood function,\n- the profile log-likelihood function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.experimental as otexp\nimport openturns.viewer as otv\nfrom openturns.usecases import coles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the Rain dataset. We start by looking at it through time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataRain = coles.Coles().rain\nprint(dataRain[:10])\ngraph = ot.Graph(\n    \"Daily rainfall accumulations SW England\", \"day\", \"level (mm)\", True, \"\"\n)\ndays = ot.Sample([[i] for i in range(len(dataRain))])\ncloud = ot.Cloud(days, dataRain)\ncloud.setColor(\"red\")\ncloud.setPointStyle(\",\")\ngraph.add(cloud)\ngraph.setIntegerXTick(True)\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to select a threshold upon which the GPD model will be fitted, we draw\nthe mean residual life plot with approximate $95\\%$ confidence interval.\nIt appears that the graph is linear from the threshold around\n$u=30$. Then, it decays sharply although with a linear trend. We\nshould be tempted to choose $u=60$ but there are only 6\nexceedances of the threshold $u=60$. So it is not enough\nto make meaningful inferences. Moreover, the graph is not reliable\nfor large values of $u$ due to the limited amount of data on\nwhich the estimate and the confidence interval are based.\nFor all these reasons, it appears preferable to chose $u=30$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "factory = ot.GeneralizedParetoFactory()\ngraph = factory.drawMeanResidualLife(dataRain)\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To support that choice, we draw the parameter stability plots.\nWe see that the perturbations appear small relatively to sampling errors.\nWe can see that the change in pattern observed in the mean\nresidual life plot is still apparent here for high thresholds.\nHence, we choose the threshold $u=30$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "u_range = ot.Interval(0.5, 50.0)\ngraph = factory.drawParameterThresholdStability(dataRain, u_range)\nview = otv.View(graph, figure_kw={\"figsize\": (6.0, 6.0)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Stationary GPD modeling via the log-likelihood function**\n\nWe first assume that the dependence through time is negligible, so we first model the data as\nindependent observations over the observation period.\n\nWe consider the model  $\\mathcal{M}_0$ defined by:\n\n\\begin{align}:nowrap:\n\n    \\begin{align*}\n      \\sigma(t) & = \\sigma\\\\\n      \\xi(t) & = \\xi\n    \\end{align*}\\end{align}\n\nWe estimate the parameters of the GPD distribution by maximizing\nthe log-likelihood of the data for the selecte threshold $u=30$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "u = 30\nresult_LL = factory.buildMethodOfLikelihoodMaximizationEstimator(dataRain, u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the fitted GPD and its parameters of $(\\hat{\\sigma}, \\hat{\\xi}, u)$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fitted_GPD = result_LL.getDistribution()\ndesc = fitted_GPD.getParameterDescription()\nparam = fitted_GPD.getParameter()\nprint(\", \".join([f\"{p}: {value:.3f}\" for p, value in zip(desc, param)]))\nprint(\"log-likelihood = \", result_LL.getLogLikelihood())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the asymptotic distribution of the estimator $(\\hat{\\mu}, \\hat{\\sigma}, \\hat{\\xi})$.\nIn that case, the asymptotic distribution is normal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameterEstimate = result_LL.getParameterDistribution()\nprint(\"Asymptotic distribution of the estimator : \")\nprint(parameterEstimate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the covariance matrix and the standard deviation of $(\\hat{\\sigma}, \\hat{\\xi}, \\hat{\\xi})$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Cov matrix = \\n\", parameterEstimate.getCovariance())\nprint(\"Standard dev = \", parameterEstimate.getStandardDeviation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the marginal confidence intervals of order 0.95.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "order = 0.95\nfor i in range(2):  # exclude u parameter (fixed)\n    ci = parameterEstimate.getMarginal(i).computeBilateralConfidenceInterval(order)\n    print(desc[i] + \":\", ci)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At last, we can validate the inference result thanks to the 4 usual diagnostic plots:\n\n- the probability-probability pot,\n- the quantile-quantile pot,\n- the return level plot,\n- the data histogram and the density of the fitted model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "validation = otexp.GeneralizedParetoValidation(result_LL, dataRain)\ngraph = validation.drawDiagnosticPlot()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Stationary GPD modeling via the profile log-likelihood function**\n\nNow, we use the profile log-likehood function with respect\nto the $\\xi$ parameter rather than log-likehood function\nto estimate the parameters of the GPD.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_PLL = factory.buildMethodOfXiProfileLikelihoodEstimator(dataRain, u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following graph allows one to get the profile log-likelihood plot.\nIt also indicates the optimal value of $\\xi$, the maximum profile log-likelihood and\nthe confidence interval for $\\xi$ of order 0.95 (which is the default value).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "order = 0.95\nresult_PLL.setConfidenceLevel(order)\nview = otv.View(result_PLL.drawProfileLikelihoodFunction())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can get the numerical values of the confidence interval: it appears to be a bit smaller\nwith the interval obtained from the profile log-likelihood function than with the log-likelihood\nfunction.\nNote that if the order requested is too high, the confidence interval might not be calculated because\none of its bound is out of the definition domain of the log-likelihood function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    print(\"Confidence interval for xi = \", result_PLL.getParameterConfidenceInterval())\nexcept Exception as ex:\n    print(type(ex))\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Return level estimate from the estimated stationary GPD**\n\nWe evaluate the $T$-year return level which corresponds to the\n$m$-observation return level, where $m = T*n_y$ with $n_y$\nthe number of observations per year. Here, we have daily observations, hence\n$n_y = 365$. As we assumed that the observations were independent, the extremal index is $\\theta=1$ which is the default value.\n\nThe method also provides the asymptotic distribution of the estimator $\\hat{z}_m$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ny = 365\nT10 = 10\nzm_10 = factory.buildReturnLevelEstimator(result_LL, dataRain, T10 * ny)\nreturn_level_10 = zm_10.getMean()\nprint(\"Maximum log-likelihood function : \")\nprint(f\"10-year return level = {return_level_10}\")\nreturn_level_ci10 = zm_10.computeBilateralConfidenceInterval(0.95)\nprint(f\"CI = {return_level_ci10}\")\n\nT100 = 100\nzm_100 = factory.buildReturnLevelEstimator(result_LL, dataRain, T100 * ny)\nreturn_level_100 = zm_100.getMean()\nprint(f\"100-year return level = {return_level_100}\")\nreturn_level_ci100 = zm_100.computeBilateralConfidenceInterval(0.95)\nprint(f\"CI = {return_level_ci100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Return level estimate via the profile log-likelihood function of a stationary GPD**\n\nWe can estimate the $m$-observation return level $z_m$ directly from the data using the profile\nlikelihood with respect to $z_m$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_zm_100_PLL = factory.buildReturnLevelProfileLikelihoodEstimator(\n    dataRain, u, T100 * ny\n)\nzm_100_PLL = result_zm_100_PLL.getParameter()\nprint(f\"100-year return level (profile) = {zm_100_PLL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can get the confidence interval of $z_m$: once more, it appears to be a bit smaller\nthan the interval obtained from the log-likelihood function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_zm_100_PLL.setConfidenceLevel(0.95)\nreturn_level_ci100 = result_zm_100_PLL.getParameterConfidenceInterval()\nprint(\"Maximum profile log-likelihood function : \")\nprint(f\"CI={return_level_ci100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the profile log-likelihood function and get the confidence interval, the optimal value\nof $z_m$ and its confidence interval.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view = otv.View(result_zm_100_PLL.drawProfileLikelihoodFunction())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Non stationary GPD modeling via the log-likelihood function**\n\nNow, we want to check whether it is necessary to model the time dependency over\nthe observation period.\n\nWe have to define the functional basis for each parameter of the GPD model. Even if we have\nthe possibility to affect a time-varying model to each of the 2 parameters\n$(\\sigma, \\xi)$,\nit is strongly recommended not to vary the shape parameter $\\xi$.\n\nWe suppose that $\\sigma$ is linear with time, and that the other parameters remain constant.\n\nFor numerical reasons, it is strongly recommended to normalize all the data as follows:\n\n\\begin{align}\\tau(t) = \\dfrac{t-c}{d}\\end{align}\n\nwhere:\n\n- the *CenterReduce* method where $c = \\dfrac{1}{n} \\sum_{i=1}^n t_i$ is the mean time stamps\n  and $d = \\sqrt{\\dfrac{1}{n} \\sum_{i=1}^n (t_i-c)^2}$ is the standard deviation of the time stamps;\n- the *MinMax* method where $c = t_1$ is the initial time and $d = t_n-t_1$ the final time. This method is the default one;\n- the *None* method where $c = 0$ and $d = 1$: in that case, data are not normalized.\n\nWe consider the model  $\\mathcal{M}_1$ defined by:\n\n\\begin{align}:nowrap:\n\n    \\begin{align*}\n      \\sigma(t) & = \\beta_1 + \\beta_2\\tau(t) \\\\\n      \\xi(t) & = \\beta_3\n    \\end{align*}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "constant = ot.SymbolicFunction([\"t\"], [\"1.0\"])\nbasis = ot.Basis([ot.SymbolicFunction([\"t\"], [\"t\"]), constant])\n# basis for mu, sigma, xi\nsigmaIndices = [0, 1]  # linear\nxiIndices = [1]  # stationary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to get the time stamps (in days here).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timeStamps = ot.Sample([[i + 1] for i in range(len(dataRain))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now estimate the list of coefficients $\\vect{\\beta} = (\\beta_1, \\beta_2, \\beta_3)$ using\nthe log-likelihood of the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_NonStatLL = factory.buildTimeVarying(\n    dataRain, u, timeStamps, basis, sigmaIndices, xiIndices\n)\nbeta = result_NonStatLL.getOptimalParameter()\nprint(f\"beta = {beta}\")\nprint(f\"sigma(t) = {beta[1]:.4f} * tau(t) + {beta[0]:.4f}\")\nprint(f\"xi = {beta[2]:.4f}\")\nprint(f\"Max log-likelihood = {result_NonStatLL.getLogLikelihood()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the asymptotic distribution of $\\vect{\\beta}$ to compute some confidence intervals of\nthe estimates, for example of order $p = 0.95$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dist_beta = result_NonStatLL.getParameterDistribution()\nconfidence_level = 0.95\nfor i in range(beta.getSize()):\n    lower_bound = dist_beta.getMarginal(i).computeQuantile((1 - confidence_level) / 2)[\n        0\n    ]\n    upper_bound = dist_beta.getMarginal(i).computeQuantile((1 + confidence_level) / 2)[\n        0\n    ]\n    print(\n        \"Conf interval for beta_\"\n        + str(i + 1)\n        + \" = [\"\n        + str(lower_bound)\n        + \"; \"\n        + str(upper_bound)\n        + \"]\"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can get the expression of the normalizing function $t \\mapsto \\tau(t)$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "normFunc = result_NonStatLL.getNormalizationFunction()\nprint(\"Function tau(t): \", normFunc)\nprint(\"c = \", normFunc.getEvaluation().getImplementation().getCenter()[0])\nprint(\"1/d = \", normFunc.getEvaluation().getImplementation().getLinear()[0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can get the function $t \\mapsto \\vect{\\theta}(t)$ where\n$\\vect{\\theta}(t) = (\\sigma(t), \\xi(t))$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "functionTheta = result_NonStatLL.getParameterFunction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to compare different modelings, we get the optimal log-likelihood of the data for both stationary\nand non stationary models. The difference seems to be non significant enough, which means that the non\nstationary model does not really improve the quality of the modeling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Max log-likelihood: \")\nprint(\"Stationary model =  \", result_LL.getLogLikelihood())\nprint(\"Non stationary linear sigma(t) model =  \", result_NonStatLL.getLogLikelihood())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to draw some diagnostic plots similar to those drawn in the stationary case, we refer to the\nfollowing result: if $Y_t$ is a non stationary GPD model parametrized by $(\\sigma(t), \\xi(t), u)$,\nthen the standardized variables $\\hat{Y}_t$ defined by:\n\n\\begin{align}\\hat{Y}_t = \\dfrac{1}{\\xi(t)} \\log \\left[1+ \\xi(t)\\left( \\dfrac{Y_t-u}{\\sigma(t)} \\right)\\right]\\end{align}\n\nhave the Exponential distribution which is the GPD model with $(\\sigma, \\xi, u) = (1, 0, 0)$.\n\nAs a result, we can validate the inference result thanks the 4 usual diagnostic plots:\n\n- the probability-probability pot,\n- the quantile-quantile pot,\n- the return level plot,\n- the data histogram and the density of the fitted model.\n\nusing the transformed data compared to the Exponential model. We can see that the adequation seems similar to the graph\nof the stationary model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = result_NonStatLL.drawDiagnosticPlot()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can draw the mean function $t \\mapsto \\Expect{\\mbox{GPD}(t)}$, defined for $\\xi <1$ only:\n\n\\begin{align}\\Expect{\\mbox{GPD}(t)} = u + \\dfrac{\\sigma(t)}{1 - \\xi(t)}\\end{align}\n\nWe can also draw the function $t \\mapsto q_p(t)$ where $q_p(t)$ is the quantile of\norder $p$ of the GPD distribution at time $t$.\nHere, $\\sigma(t)$ is a linear function and the other parameters are constant, so the mean and the quantile\nfunctions are also linear functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph = ot.Graph(\n    r\"Maximum rain - Linear $\\sigma(t)$\",\n    \"day\",\n    \"level (mm)\",\n    True,\n    \"\",\n)\ngraph.setIntegerXTick(True)\n# data\ncloud = ot.Cloud(timeStamps, dataRain)\ncloud.setColor(\"red\")\ngraph.add(cloud)\n# mean function\nmeandata = [\n    result_NonStatLL.getDistribution(t).getMean()[0] for t in timeStamps.asPoint()\n]\ncurve_meanPoints = ot.Curve(timeStamps.asPoint(), meandata)\ngraph.add(curve_meanPoints)\n# quantile function\ngraphQuantile = result_NonStatLL.drawQuantileFunction(0.95)\ndrawQuant = graphQuantile.getDrawable(0)\ndrawQuant = graphQuantile.getDrawable(0)\ndrawQuant.setLineStyle(\"dashed\")\ngraph.add(drawQuant)\ngraph.setLegends([\"data\", \"mean function\", \"quantile 0.95 function\"])\ngraph.setLegendPosition(\"lower right\")\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At last, we can test the validity of the stationary model $\\mathcal{M}_0$\nrelative to the model with time varying parameters  $\\mathcal{M}_1$. The\nmodel $\\mathcal{M}_0$ is parametrized\nby $(\\beta_1, \\beta_3)$ and the model $\\mathcal{M}_1$ is parametrized\nby $(\\beta_1, \\beta_2, \\beta_3)$: so we have $\\mathcal{M}_0 \\subset \\mathcal{M}_1$.\n\nWe use the Likelihood Ratio test. The null hypothesis is the stationary model $\\mathcal{M}_0$.\nThe Type I error $\\alpha$ is taken equal to 0.05.\n\nThis test confirms that there is no evidence of a linear trend for $\\mu$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "llh_LL = result_LL.getLogLikelihood()\nllh_NonStatLL = result_NonStatLL.getLogLikelihood()\nmodelM0_Nb_param = 2\nmodelM1_Nb_param = 3\nresultLikRatioTest = ot.HypothesisTest.LikelihoodRatioTest(\n    modelM0_Nb_param, llh_LL, modelM1_Nb_param, llh_NonStatLL, 0.05\n)\naccepted = resultLikRatioTest.getBinaryQualityMeasure()\nprint(\n    f\"Hypothesis H0 (stationary model) vs H1 (linear mu(t) model):  accepted ? = {accepted}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We detail the statistics of the Likelihood Ratio test: the deviance statistics\n$\\mathcal{D}_p$ follows a $\\chi^2_1$ distribution.\nThe model $\\mathcal{M}_0$ is rejected if the deviance statistics estimated on the data is greater than\nthe threshold $c_{\\alpha}$ or if the p-value is less than the Type I error  $\\alpha = 0.05$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Dp={resultLikRatioTest.getStatistic():.2f}\")\nprint(f\"alpha={resultLikRatioTest.getThreshold():.2f}\")\nprint(f\"p-value={resultLikRatioTest.getPValue():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can test a linear trend in the log-scale parameter for $\\sigma(t)$:\n\n\\begin{align}:nowrap:\n\n    \\begin{align*}\n      \\sigma(t) & = exp(\\beta_1 + \\beta_2\\tau(t)) \\\\\n      \\xi(t) & = \\beta_3\n    \\end{align*}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sigmaLink = ot.SymbolicFunction(\"x\", \"exp(x)\")\nresult_NonStatLL_Link = factory.buildTimeVarying(\n    dataRain, u, timeStamps, basis, sigmaIndices, xiIndices, sigmaLink\n)\nbeta = result_NonStatLL_Link.getOptimalParameter()\nprint(f\"beta = {beta}\")\nprint(f\"sigma(t) = exp({beta[1]:.4f} * tau(t) + {beta[0]:.4f})\")\nprint(f\"xi = {beta[2]:.4f}\")\nprint(f\"Max log-likelihood = {result_NonStatLL.getLogLikelihood()}\")\n\n# %\n# The maximized log-likelihood we obtain with the log-linear model is very similar\n# to the one we obtained with the linear model. Hence, there is no evidence of a time trend.\n# We draw the diagnostic plots which are similar to the previous ones.\ngraph = result_NonStatLL_Link.drawDiagnosticPlot()\nview = otv.View(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}