{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gaussian Process Regression: choose a polynomial trend on the beam model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we consider the `cantilever beam <use-case-cantilever-beam>` and we build a metamodel using a\nGaussian process regression whose trend is estimated on the\ngiven data set. We illustrate the impact of the choice of the trend function basis on the metamodel.\nThis example focuses on three polynomial trends:\n\n* :class:`~openturns.ConstantBasisFactory`;\n* :class:`~openturns.LinearBasisFactory`;\n* :class:`~openturns.QuadraticBasisFactory`.\n\nIn the :doc:`/auto_meta_modeling/kriging_metamodel/plot_gpr_choose_trend` example,\nwe give another example of this procedure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from openturns.usecases import cantilever_beam\nimport openturns as ot\nimport openturns.experimental as otexp\nimport openturns.viewer as otv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of the model\n\nWe load the use case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cb = cantilever_beam.CantileverBeam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the function which evaluates the output depending on the inputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = cb.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the distribution of the input random vector.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dimension = cb.dim  # number of inputs\ninput_dist = cb.distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the design of experiments\n\nWe consider a simple Monte-Carlo sampling as a design of experiments.\nThis is why we generate an input sample using the :meth:`~openturns.Distribution.getSample` method of the distribution.\nThen we evaluate the output using the `model` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_train = 10\nX_train = input_dist.getSample(sampleSize_train)\nY_train = model(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constant basis\n\nIn this paragraph we choose a basis constant for the estimation of the trend.\nThe basis is built with the :class:`~openturns.ConstantBasisFactory` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basis = ot.ConstantBasisFactory(dimension).build()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to create the Gaussian Process Regression metamodel, we use a squared exponential covariance kernel.\nThe :class:`~openturns.SquaredExponential` kernel has one amplitude coefficient and 4 scale coefficients.\nThis is because this covariance kernel is anisotropic : each of the 4 input variables is associated with its own scale coefficient.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covariance_model = ot.SquaredExponential(dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The optimization algorithm is quite good at setting optimization bounds. In this case, however, the range of the input domain is extreme,\nas we can see below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Lower and upper bounds of X_train:\")\nprint(X_train.getMin(), X_train.getMax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, we need to manually define sensible optimization bounds.\nNote that since the amplitude parameter is computed analytically (this is possible when the output dimension is 1),\nwe only need to set bounds on the scale parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scaleOptimizationBounds = ot.Interval(\n    [1.0, 1.0, 1.0, 1.0e-10], [1.0e11, 1.0e3, 1.0e1, 1.0e-5]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create the Gaussian Process Regression metamodel, we first build the $Y(\\omega, x)$ Gaussian process with the class\n:class:`~openturns.experimental.GaussianProcessFitter`. It requires a training sample, a covariance kernel and a\ntrend basis as input arguments.\n\nWe need to set the initial scale parameter for the optimization. The upper bound of the input domain is a sensitive choice here.\nWe must not forget to actually set the optimization bounds defined above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covariance_model.setScale(X_train.getMax())\nalgo_fit = otexp.GaussianProcessFitter(X_train, Y_train, covariance_model, basis)\nalgo_fit.setOptimizationBounds(scaleOptimizationBounds)\nalgo_fit.run()\nfit_result = algo_fit.getResult()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we condition the process $Y(\\omega, x)$ to the data set with the class\n:class:`~openturns.experimental.GaussianProcessRegression`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algo_gpr = otexp.GaussianProcessRegression(fit_result)\nalgo_gpr.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the Gaussian Process Regression metamodel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gpr_result_cst = algo_gpr.getResult()\nmetamodel_cst = gpr_result_cst.getMetaModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :meth:`~openturns.experimental.GaussianProcessRegressionResult.getTrendCoefficients` method returns the coefficients of the trend.\nThe constant trend always has only one coefficient (if there is one single output).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gpr_result_cst.getTrendCoefficients())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check the estimated covariance model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gpr_result_cst.getCovarianceModel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear basis\n\nIn this paragraph we choose a linear basis for the estimation of the trend.\nThe basis is built with the :class:`~openturns.LinearBasisFactory` class. The same methodology is followed:\nwe do not detail it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basis = ot.LinearBasisFactory(dimension).build()\nalgo_fit = otexp.GaussianProcessFitter(X_train, Y_train, covariance_model, basis)\nalgo_fit.setOptimizationBounds(scaleOptimizationBounds)\nalgo_fit.run()\nfit_result = algo_fit.getResult()\nalgo_gpr = otexp.GaussianProcessRegression(fit_result)\nalgo_gpr.run()\ngpr_result_lin = algo_gpr.getResult()\nmetamodel_lin = gpr_result_lin.getMetaModel()\nprint(gpr_result_lin.getTrendCoefficients())\nprint(gpr_result_lin.getCovarianceModel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of coefficients in the linear and quadratic trends depends on the number of inputs, which is\nequal to\n\n\\begin{align}dim = 4\\end{align}\n\n\nin the cantilever beam case.\n\nWe observe that the number of coefficients in the trend is 5, which corresponds to:\n\n* 1 coefficient for the constant part,\n* dim = 4 coefficients for the linear part.\n\n\n## Quadratic basis\n\nIn this paragraph we choose a quadratic basis for the estimation of the trend.\nThe basis is built with the :class:`~openturns.QuadraticBasisFactory` class. The same methodology is followed:\nwe do not detail it.\n\nHowever we can see that the default optimization algorithm which is :class:`~openturns.Cobyla` does not manage to converge.\nThus, we can either:\n\n* change the default optimization algorithm and select for example the :class:`~openturns.TNC`\n  algorithm (Truncated Newton Constrained) using the entry of :class:`~openturns.ResourceMap` called\n  *GaussianProcessFitter-DefaultOptimizationAlgorithm*: *ot.ResourceMap.SetAsString(\"GaussianProcessFitter-\n  DefaultOptimizationAlgorithm\", \"TNC\")*,\n* or keep the default optimization algorithm but change the default maximum constrainte error value which is equal to\n  $10^{-5}$. We move it to $10^{-6}$  using the entry of :class:`~openturns.ResourceMap` called\n  *OptimizationAlgorithm-DefaultMaximumConstraintError*: *ot.ResourceMap.SetAsScalar(\"OptimizationAlgorithm\n  -DefaultMaximumConstraintError\", 1e-6)*.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ot.ResourceMap.SetAsScalar(\"OptimizationAlgorithm-DefaultMaximumConstraintError\", 1e-6)\nbasis = ot.QuadraticBasisFactory(dimension).build()\nalgo_fit = otexp.GaussianProcessFitter(X_train, Y_train, covariance_model, basis)\nalgo_fit.setOptimizationBounds(scaleOptimizationBounds)\nalgo_fit.run()\nfit_result = algo_fit.getResult()\nalgo_gpr = otexp.GaussianProcessRegression(fit_result)\nalgo_gpr.run()\ngpr_result_quad = algo_gpr.getResult()\nmetamodel_quad = gpr_result_quad.getMetaModel()\nprint(gpr_result_quad.getTrendCoefficients())\nprint(gpr_result_quad.getCovarianceModel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time, the trend has 15 coefficients:\n\n* 1 coefficient for the constant part,\n* 4 coefficients for the linear part,\n* 10 coefficients for the quadratic part.\n\nThis is because the number of coefficients in the quadratic part has\n\n\\begin{align}\\frac{dim \\times (dim+1)}{2}=\\frac{4\\times 5}{2}=10\\end{align}\n\n\ncoefficients, associated with the symmetric matrix of the quadratic function.\n\n## Validate the metamodel\n\nWe finally want to validate the Gaussian Process Regression metamodel. This is why we generate a validation sample\nwith size 100 and we evaluate the output of the model on this sample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSize_test = 100\nX_test = input_dist.getSample(sampleSize_test)\nY_test = model(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a function to easily draw the QQ-plot graphs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def drawMetaModelValidation(X_test, Y_test, metamodel_gpr, title):\n    metamodel_predictions = metamodel_gpr(X_test)\n    val = ot.MetaModelValidation(Y_test, metamodel_predictions)\n    r2Score = val.computeR2Score()[0]\n    graph = val.drawValidation().getGraph(0, 0)\n    graph.setLegends([\"\"])\n    graph.setLegends([\"%s, R2 = %.2f%%\" % (title, 100 * r2Score), \"\"])\n    graph.setLegendPosition(\"upper left\")\n    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot here the validation graph for each metamodel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = ot.GridLayout(1, 3)\ngrid.setTitle(\"Different trends\")\ngraphConstant = drawMetaModelValidation(X_test, Y_test, metamodel_cst, \"Constant\")\ngraphLinear = drawMetaModelValidation(X_test, Y_test, metamodel_lin, \"Linear\")\ngraphQuadratic = drawMetaModelValidation(X_test, Y_test, metamodel_quad, \"Quadratic\")\ngrid.setGraph(0, 0, graphConstant)\ngrid.setGraph(0, 1, graphLinear)\ngrid.setGraph(0, 2, graphQuadratic)\nview = otv.View(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the three trends perform very well in this case.\nWith more coefficients, the Gaussian Process Regression metamodel is more flexibile and can adjust better to the training sample.\nThis does not mean, however, that the trend coefficients will provide a good fit for the validation sample.\n\nThe number of parameters in each Gaussian Process Regression metamodel is the following :\n\n* with the constant trend, we have 6 coefficients to estimate: 5 coefficients for the covariance matrix and 1 coefficient for the trend,\n* with the  linear trend, we have 10 coefficients to estimate: 5 coefficients for the covariance matrix and 5 coefficients for the trend,\n* with the quadratic trend, we have 20 coefficients to estimate: 5 coefficients for the covariance matrix and 15 coefficients for the trend.\n\nIn the cantilever beam example, fitting the metamodel to a training sample with only 10 points is made much easier because the function to approximate is almost linear.\nIn this case, a quadratic trend is not advisable because it can interpolate all points in the training sample.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display figures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}