{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Convergence of Monte-Carlo to estimate the probability in a reliability problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this document is to present the convergence of the Monte-Carlo algorithm\nto the exact probability when the sample size increases.\nThis convergence is expressed in terms of absolute error.\nWe show that the rate of convergence is $O(\\sqrt{n})$,\nwhere $n$ is the sample size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import openturns as ot\nimport openturns.viewer as otv\nimport numpy as np\nimport otbenchmark as otb\nimport time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = otb.RminusSReliability()\nprint(problem)\n\n\ndef ComputeProbabilityFromMonteCarlo(\n    problem, coefficientOfVariation=0.1, maximumOuterSampling=1000, blockSize=2\n):\n    event = problem.getEvent()\n    g = event.getFunction()\n    # Create the Monte-Carlo algorithm\n    algoProb = ot.ProbabilitySimulationAlgorithm(event)\n    algoProb.setMaximumOuterSampling(maximumOuterSampling)\n    algoProb.setBlockSize(blockSize)\n    algoProb.setMaximumCoefficientOfVariation(coefficientOfVariation)\n    initialNumberOfFunctionEvaluations = g.getEvaluationCallsNumber()\n    algoProb.run()\n    # Get the results\n    resultAlgo = algoProb.getResult()\n    numberOfFunctionEvaluations = (\n        g.getEvaluationCallsNumber() - initialNumberOfFunctionEvaluations\n    )\n    pf = resultAlgo.getProbabilityEstimate()\n    level = 0.95\n    c95 = resultAlgo.getConfidenceLength(level)\n    pmin = pf - 0.5 * c95\n    pmax = pf + 0.5 * c95\n    print(\n        \"Number of function calls = %d\" % (numberOfFunctionEvaluations),\n        \", Pf = %.4f\" % (pf),\n        \", %.1f %% confidence interval :[%.4f,%.4f] \" % (level * 100, pmin, pmax),\n    )\n    absoluteError = abs(pf - problem.getProbability())\n    result = {\n        \"numberOfFunctionEvaluations\": numberOfFunctionEvaluations,\n        \"pf\": pf,\n        \"pmin\": pmin,\n        \"pmax\": pmax,\n        \"absoluteError\": absoluteError,\n    }\n    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = ComputeProbabilityFromMonteCarlo(problem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numberOfPoints = 15  # Number of atomic experiments\nnumberOfRepetitions = 10  # Number of repetitions of each experiment\nsampleSizeAbsoluteErrorTable = ot.Sample(numberOfPoints * numberOfRepetitions, 2)\nsampleSizeAbsoluteErrorTable.setDescription([\"Sample size\", \"Absolute error\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cov = 0.0\nstartTime = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maximumOuterSampling = 1\nindex = 0\nfor i in range(numberOfPoints):\n    maximumOuterSampling *= 2\n    for j in range(numberOfRepetitions):\n        result = ComputeProbabilityFromMonteCarlo(\n            problem,\n            coefficientOfVariation=cov,\n            maximumOuterSampling=maximumOuterSampling,\n        )\n        sampleSizeAbsoluteErrorTable[index, 0] = result[\"numberOfFunctionEvaluations\"]\n        sampleSizeAbsoluteErrorTable[index, 1] = result[\"absoluteError\"]\n        index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "elapsedTime = time.time() - startTime\nprint(\"Elapsed = %.2f (s)\" % (elapsedTime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampleSizeArray = [int(n) for n in np.logspace(0.0, 5.0)]\nexpectedConvergence = [1.0 / np.sqrt(n) for n in sampleSizeArray]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "title = \"Convergence of Monte-Carlo method - problem = %s\" % (problem.getName())\ngraph = ot.Graph(title, \"Sample size\", \"Absolute error\", True, \"topright\")\ncurve = ot.Cloud(sampleSizeAbsoluteErrorTable, \"blue\", \"fsquare\", \"\")\ncurve.setLegend(\"Monte-Carlo\")\ngraph.add(curve)\ncurve = ot.Curve(sampleSizeArray, expectedConvergence)\ncurve.setLegend(r\"$1/\\sqrt{n}$\")\ngraph.add(curve)\ngraph.setLogScale(ot.GraphImplementation.LOGXY)\ngraph.setColors([\"dodgerblue3\", \"darkorange1\"])\n_ = otv.View(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "otv.View.ShowAll()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}