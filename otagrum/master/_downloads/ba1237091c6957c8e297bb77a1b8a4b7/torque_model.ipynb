{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Torque model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#\n# This example studies the causes of leakage of a mechanical model.\n#\n# It has several parameters: Torque (T), Joint (J), Angle (A), Vibration (V) and Leak (L).\n\n\nimport pyAgrum as gum\nimport openturns as ot\nimport otagrum\nimport numpy as np\nfrom openturns.viewer import View\nfrom matplotlib import pylab as plt\nimport sys\n\nfrom pyAgrum.lib.explain import showInformation\nfrom pyAgrum.lib.notebook import showInference\n\ngum.config[\"notebook\", \"histogram_discretized_visualisation\"] = \"bar\"\n\n# **Probabilistic model**\n\n# Marginal distributions\nTorque = ot.LogNormal(0.0, 0.25)\nAngle = ot.TruncatedNormal(0.0, 2.0, -8.0, 8.0)\nJoint = ot.Uniform(1.8, 2.2)\n\n# Dependence\nrho = 0.5\nTorqueAngleCopula = ot.NormalCopula(ot.CorrelationMatrix(2, [1.0, rho, rho, 1.0]))\ncopula = ot.BlockIndependentCopula([TorqueAngleCopula, ot.IndependentCopula(1)])\n\n# Joint distribution if needed\nTorqueAngle = ot.ComposedDistribution([Torque, Angle], TorqueAngleCopula)\nfullDistribution = ot.ComposedDistribution([Torque, Angle, Joint], copula)\n\n# Leakage angle (rd)\nangleMax = 5.0\n\n# Leakage joint (mm)\njointMin = 2.0\njointSpread = 0.1\n\n# Vibration torque (kN.m)\ntorqueSpread = 2.0\n\n\n# **(Discrete) Graphical model**\n\nn_ticks = 100\nnodes = 16\n\n\ndef completeTicks(rnge, ticks):\n    if rnge is None:\n        return [-sys.float_info.max] + ticks + [sys.float_info.max]\n    else:\n        return [rnge.getLowerBound()[0]] + ticks + [rnge.getUpperBound()[0]]\n\n\ntorque_ticks = [\n    (n_ticks - i) * Torque.getRange().getLowerBound()[0] / (n_ticks + 1)\n    + (i + 1.0) * Torque.getRange().getUpperBound()[0] / (n_ticks + 1)\n    for i in range(n_ticks)\n]\n\nangle_ticks = [\n    (n_ticks - i) * Angle.getRange().getLowerBound()[0] / (n_ticks + 1)\n    + (i + 1.0) * Angle.getRange().getUpperBound()[0] / (n_ticks + 1)\n    for i in range(n_ticks)\n]\n\njoint_ticks = [\n    (n_ticks - i) * Joint.getRange().getLowerBound()[0] / (n_ticks + 1)\n    + (i + 1.0) * Joint.getRange().getUpperBound()[0] / (n_ticks + 1)\n    for i in range(n_ticks)\n]\n\nvibration_ticks = [-1.0, -0.5, 0.0, 0.5, 1.0]\n\nbn = gum.BayesNet()\nbn.add(\n    gum.DiscretizedVariable(\n        \"T\", \"Torque\", completeTicks(Torque.getRange(), torque_ticks)\n    )\n)\nbn.add(\n    gum.DiscretizedVariable(\"A\", \"Angle\", completeTicks(Angle.getRange(), angle_ticks))\n)\nbn.add(\n    gum.DiscretizedVariable(\"J\", \"Joint\", completeTicks(Joint.getRange(), joint_ticks))\n)\n\nbn.add(gum.DiscretizedVariable(\"V\", \"Vibration\", completeTicks(None, vibration_ticks)))\nbn.add(gum.LabelizedVariable(\"L\", \"Leak\", [\"False\", \"True\"]))\n\nbn.addArc(\"T\", \"V\")\nbn.addArc(\"T\", \"A\")\nbn.addArc(\"J\", \"V\")\nbn.addArc(\"J\", \"L\")\nbn.addArc(\"A\", \"L\")\nbn\n\n\n# **Discretizations**\n\n\n# This function allows one to discretize a conditional distribution of X_d\n# knowing X_1,...,X_{d-1} from a joint distribution of (X_1,...,X_d)\n# and a discretization grid.\ndef discretizeFromJoint(fullDistribution, ticks):\n    fullDimension = fullDistribution.getDimension()\n    conditioningDistribution = fullDistribution.getMarginal(\n        [i for i in range(fullDimension - 1)]\n    )\n    # Add the range bounds to the given ticks\n    lower = fullDistribution.getRange().getLowerBound()\n    upper = fullDistribution.getRange().getUpperBound()\n    expandedTicks = [0] * len(ticks)\n    for i in range(fullDimension):\n        expandedTicks[i] = [lower[i]] + ticks[i] + [upper[i]]\n    # Now perform the full discretization\n    lengths = [(len(t) - 1) for t in expandedTicks]\n    tuples = ot.Tuples(lengths).generate()\n    probabilities = ot.Point(len(tuples))\n    for i in range(len(tuples)):\n        tuple = tuples[i]\n        aFull = [expandedTicks[j][tuple[j]] for j in range(fullDimension)]\n        bFull = [expandedTicks[j][tuple[j] + 1] for j in range(fullDimension)]\n        aConditioning = [expandedTicks[j][tuple[j]] for j in range(fullDimension - 1)]\n        bConditioning = [\n            expandedTicks[j][tuple[j] + 1] for j in range(fullDimension - 1)\n        ]\n        den = conditioningDistribution.computeProbability(\n            ot.Interval(aConditioning, bConditioning)\n        )\n        if den > 0.0:\n            num = fullDistribution.computeProbability(ot.Interval(aFull, bFull))\n            probabilities[i] = num / den\n    return probabilities\n\n\n# This function allows one to discretize a conditional distribution knowing its\n# conditional density function given as a Function, its conditioning\n# distribution and a discretization grid.\n# WARNING: The result is NOT normalized\ndef discretizeFromConditionalDensity(\n    conditionalDensity,\n    conditioningDistribution,\n    ticks,\n    useSlowIntegration=True,\n    nodesNumber=32,\n):\n    fullDimension = conditioningDistribution.getDimension() + 1\n    if useSlowIntegration:\n        # Accurate but slow\n        integrator = ot.IteratedQuadrature()\n    else:\n        # Less accurate for non-smooth integrand but fast\n        ot.ResourceMap.SetAsUnsignedInteger(\n            \"GaussLegendre-DefaultMarginalIntegrationPointsNumber\", nodesNumber\n        )\n        integrator = ot.GaussLegendre(fullDimension)\n    # Add the range bounds to the given ticks\n    lower = list(conditioningDistribution.getRange().getLowerBound())\n    upper = list(conditioningDistribution.getRange().getUpperBound())\n    # For the conditioned variable it has to be estimated. We assume that the given\n    # tick range is a correct margin to get the lower and upper bounds\n    conditionedMin = min(ticks[fullDimension - 1])\n    conditionedMax = max(ticks[fullDimension - 1])\n    delta = conditionedMax - conditionedMin\n    lower = lower + [conditionedMin - delta]\n    upper = upper + [conditionedMax + delta]\n    expandedTicks = [0] * fullDimension\n    for i in range(fullDimension):\n        expandedTicks[i] = [lower[i]] + ticks[i] + [upper[i]]\n    # Now perform the full discretization\n    lengths = [(len(t) - 1) for t in expandedTicks]\n    tuples = ot.Tuples(lengths).generate()\n    probabilities = ot.Point(len(tuples))\n\n    def kernel(x):\n        x = np.array(x)\n        return conditionalDensity(x) * np.array(\n            conditioningDistribution.computePDF(x[:, 0: fullDimension - 1])\n        )\n\n    for i in range(len(tuples)):\n        tuple = tuples[i]\n        aFull = [expandedTicks[j][tuple[j]] for j in range(fullDimension)]\n        bFull = [expandedTicks[j][tuple[j] + 1] for j in range(fullDimension)]\n        num = integrator.integrate(\n            ot.PythonFunction(fullDimension, 1, func_sample=kernel),\n            ot.Interval(aFull, bFull),\n        )[0]\n        probabilities[i] = num\n    return probabilities\n\n\n# This function allows one to discretize a conditional Bernoulli distribution\n# knowing its conditional probability function given as a Function,\n# its conditioning distribution and a conditional discretization grid.\ndef discretizeBernoulliFromConditionalProbability(\n    conditionalProbability,\n    conditioningDistribution,\n    ticks,\n    useSlowIntegration=True,\n    nodesNumber=32,\n):\n    conditioningDimension = conditioningDistribution.getDimension()\n    if useSlowIntegration:\n        # Accurate but slow\n        integrator = ot.IteratedQuadrature()\n    else:\n        # Less accurate for non-smooth integrand but fast\n        ot.ResourceMap.SetAsUnsignedInteger(\n            \"GaussLegendre-DefaultMarginalIntegrationPointsNumber\", nodesNumber\n        )\n        integrator = ot.GaussLegendre(conditioningDimension)\n\n    # Add the range bounds to the given ticks\n    lower = list(conditioningDistribution.getRange().getLowerBound())\n    upper = list(conditioningDistribution.getRange().getUpperBound())\n    # Add the range bounds to the given ticks\n    lower = conditioningDistribution.getRange().getLowerBound()\n    upper = conditioningDistribution.getRange().getUpperBound()\n    expandedTicks = [0] * len(ticks)\n    for i in range(conditioningDimension):\n        expandedTicks[i] = [lower[i]] + ticks[i] + [upper[i]]\n    # Now perform the full discretization\n    lengths = [(len(t) - 1) for t in expandedTicks]\n    tuples = ot.Tuples(lengths).generate()\n    probabilitiesTrue = [0] * len(tuples)\n\n    def kernel(x):\n        x = np.array(x)\n        return conditionalProbability(x) * np.array(\n            conditioningDistribution.computePDF(x[:, 0:conditioningDimension])\n        )\n\n    for i in range(len(tuples)):\n        tuple = tuples[i]\n        aConditioning = [\n            expandedTicks[j][tuple[j]] for j in range(conditioningDimension)\n        ]\n        bConditioning = [\n            expandedTicks[j][tuple[j] + 1] for j in range(conditioningDimension)\n        ]\n        den = conditioningDistribution.computeProbability(\n            ot.Interval(aConditioning, bConditioning)\n        )\n        if den > 0.0:\n            num = integrator.integrate(\n                ot.PythonFunction(conditioningDimension, 1, func_sample=kernel),\n                ot.Interval(aConditioning, bConditioning),\n            )[0]\n            probabilitiesTrue[i] = min(1.0, num / den)\n        probabilities = ot.Point(\n            [1.0 - p for p in probabilitiesTrue] + probabilitiesTrue\n        )\n    return probabilities\n\n\n# In[ ]:\n\n\n# Discretization of everything\n\n\n# Compute P(Leakage = True | Angle = angle, Joint = joint)\ndef P_LeakageKnowingAngleAndJoint(x):\n    x = np.array(x)\n    angle = x[:, 0]\n    joint = x[:, 1]\n    s = (1, x.shape[0])\n    sp = (x.shape[0], 1)\n    one = np.ones(s)\n    return (\n        np.minimum(np.abs(angle / angleMax), one)\n        * np.minimum(one, np.exp(-(joint - jointMin) / jointSpread))\n    ).reshape(sp)\n\n\n# Compute K.p(Vibration = v | Torque = torque, Joint = joint) where K is unknown\ndef f_VibrationKnowingTorqueAndJoint(x):\n    x = np.array(x)\n    joint = x[:, 0]\n    torque = x[:, 1]\n    jointRed = joint / jointSpread\n    torqueRed = torque / torqueSpread\n    return ((1.0 + jointRed**2 + torqueRed**2) ** (-4.0)).reshape(x.shape[0], 1)\n\n\nAngleKnowingTorque = discretizeFromJoint(TorqueAngle, [torque_ticks, angle_ticks])\n\nLeakageKnowingAngleAndJoint = discretizeBernoulliFromConditionalProbability(\n    P_LeakageKnowingAngleAndJoint,\n    ot.ComposedDistribution([Angle, Joint]),\n    [angle_ticks, joint_ticks],\n    False,\n    nodes,\n)\n\nVibrationKnowingTorqueAndJoint = discretizeFromConditionalDensity(\n    f_VibrationKnowingTorqueAndJoint,\n    ot.ComposedDistribution([Torque, Joint]),\n    [torque_ticks, joint_ticks, vibration_ticks],\n    False,\n    nodes,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discretized Parameters for the BN\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bn.cpt(\"J\").fillWith(\n    otagrum.Utils.Discretize(Joint, bn.variable(\"J\").asDiscretizedVar())\n)\nbn.cpt(\"T\").fillWith(\n    otagrum.Utils.Discretize(Torque, bn.variable(\"T\").asDiscretizedVar())\n)\nbn.cpt(\"A\").fillWith(list(AngleKnowingTorque)).normalizeAsCPT()\n\np = gum.Potential().add(bn.variable(\"J\")).add(bn.variable(\"A\")).add(bn.variable(\"L\"))\np.fillWith(list(LeakageKnowingAngleAndJoint))\ns = bn.cpt(\"L\").names\np.reorganize(s)\nbn.cpt(\"L\").fillWith(p)\n\n\np = gum.Potential().add(bn.variable(\"J\")).add(bn.variable(\"T\")).add(bn.variable(\"V\"))\np.fillWith(list(VibrationKnowingTorqueAndJoint))\ns = bn.cpt(\"V\").names\np.reorganize(s)\nbn.cpt(\"V\").fillWith(p).normalizeAsCPT()\nshowInformation(bn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "showInference(bn, size=\"20\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "showInference(bn, evs={\"L\": True}, size=\"20\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "showInference(bn, evs={\"L\": False, \"A\": \"0.2\"}, size=\"20\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ie = gum.LazyPropagation(bn)\nie.addJointTarget(set([\"T\", \"J\"]))\nie.setEvidence({\"L\": True})\nie.makeInference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distrib = otagrum.Utils.FromPotential(ie.jointPosterior({\"T\", \"J\"}))\ndistrib.drawPDF()\nView(distrib.drawPDF())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ie = gum.LazyPropagation(bn)\nie.addJointTarget(set([\"T\", \"J\"]))\nie.setEvidence({\"L\": False})\nie.makeInference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distrib = otagrum.Utils.FromPotential(ie.jointPosterior({\"T\", \"J\"}))\nView(distrib.drawPDF())\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}